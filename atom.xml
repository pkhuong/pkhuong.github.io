<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Paul Khuong: some Lisp]]></title>
  <link href="https://www.pvk.ca/atom.xml" rel="self"/>
  <link href="https://www.pvk.ca/"/>
  <updated>2020-07-06T18:35:40-04:00</updated>
  <id>https://www.pvk.ca/</id>
  <author>
    <name><![CDATA[Paul Khuong]]></name>
    <email><![CDATA[pvk@pvk.ca]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Flatter wait-free hazard pointers]]></title>
    <link href="https://www.pvk.ca/Blog/2020/07/06/flatter-wait-free-hazard-pointers/"/>
    <updated>2020-07-06T12:54:17-04:00</updated>
    <id>https://www.pvk.ca/Blog/2020/07/06/flatter-wait-free-hazard-pointers</id>
    <content type="html"><![CDATA[<p>Back in February 2020, Blelloch and Wei submitted this cool preprint: <a href="https://arxiv.org/abs/2002.07053">Concurrent Reference Counting and Resource Management in Wait-free Constant Time</a>.
Their work mostly caught my attention because they propose a wait-free implementation of hazard pointers for safe memory reclamation:<sup id="fnref:but-also"><a href="#fn:but-also" class="footnote">1</a></sup>
<a href="">safe memory reclamation</a> is a key component for lock-free synchronisation when garbage collection isn’t an option,<sup id="fnref:it-is-gc"><a href="#fn:it-is-gc" class="footnote">2</a></sup>
and <a href="">hazard pointers</a> let us bound resource leaks much more tightly than, e.g., <a href="">epoch reclamation</a>,
but classically has a <em>loop</em> in its <a href="https://www.iecc.com/gclist/GC-algorithms.html">read barriers (in the managed language sense)</a>,
which can be annoying for code generation and isn’t good for worst-case time bounds.</p>

<p>Blelloch’s and Wei’s wait-free proposal eliminates that loop… with a construction that stacks <a href="https://arxiv.org/abs/1911.09671">two emulated primitives—atomic copy, itself implemented with strong LL/SC—</a>on top of what hardware usually offers.
I see the real value of the proposal in showing that wait-freedom is achievable,
and that the key is atomic memory-memory copies;
in this post, I’ll share the engineering work to make their construction practical,
and come up with wait-free alternatives to the usual lock-free hazard pointers
that are also competitive in the best case.
The insight that hazard pointers can be made wait-free as long as we have a wait-free atomic memory-memory copy lets us improve the worst case
without impacting the best case!</p>

<p>But first, what are hazard pointers?</p>

<h2 id="hazard-pointers-and-the-safe-memory-reclamation-problem">Hazard pointers, and the safe memory reclamation problem</h2>

<p>Hazard pointers were introduced by <a href="https://dblp.uni-trier.de/pers/m/Michael:Maged_M=.html">Maged Michael</a>
in <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.395.378&amp;rep=rep1&amp;type=pdf">Hazard Pointers: Safe Memory Reclamation for Lock-Free Objects (2005, PDF)</a>,
as the first solution to reclaim races in lock-free code.
The introduction also has a concise explanation of the safe memory reclamation (SMR) problem.</p>

<blockquote>
  <p>When a thread removes a node, it is possible that some other contending thread—in the course of its lock-free operation—has earlier read a reference to that node, and is about to access its contents. If the removing thread were to reclaim the removed node for arbitrary reuse, the contending thread might corrupt the object or some other object that happens to occupy the space of the freed node, return the wrong result, or suffer an access error by dereferencing an invalid pointer value. […] Simply put, the memory reclamation problem is how to allow the memory of removed nodes to be freed (i.e., reused arbitrarily or returned to the OS), while guaranteeing that no thread accesses free memory, and how to do so in a lock-free manner.</p>
</blockquote>

<p>In other words, a solution to the SMR problem lets us know when it’s safe to
<em>physically release</em> resources that used to be owned by a linked data structure,
once all links to these resources have been removed from that data structure (after “logical deletion”).
The problem makes intuitive sense for dynamically managed memory,
but it applies equally well to any resource (e.g., file descriptors),
and its solutions can even be seen as extremely read-optimised reader/writer locks.</p>

<p>The basic idea behind Hazard Pointers is to have
each thread publish to permanently allocated<sup id="fnref:stable-alloc"><a href="#fn:stable-alloc" class="footnote">3</a></sup> hazard pointer records (HP records) the set of resources (pointers) it’s temporarily borrowing from a lock-free data structure.
That’s enough information for a background thread to snapshot the current limbo list of resources that have been logically deleted but not yet physically released,
scan all records for all threads,
and physically release all resources in the snapshot that aren’t in any hazard pointer record.</p>

<p>With just enough batching of the limbo list, this scheme can be practical:
in practice, lock-free algorithms only need to pin a few (often one or two) nodes at a time to ensure memory safety.  As long as we can avoid running arbitrary code while holding hazardous references, we can bound the number of records each thread may need at any one time.
Scanning the records thus takes time roughly linear in the number of active threads, and we can amortise that to constant time per deleted item by waiting until the size of the limbo list is proportional to a multiple of the number of active threads.<sup id="fnref:even-with-pinned-nodes"><a href="#fn:even-with-pinned-nodes" class="footnote">4</a></sup></p>

<p>The tricky bit is figuring out how to reliably publish to a HP record without locking.
Hazard pointers simplify that challenge with three observations:</p>
<ol>
  <li>It’s OK to have arbitrary garbage in a record (let’s disregard language-level<sup id="fnref:or-hw-level"><a href="#fn:or-hw-level" class="footnote">5</a></sup> undefined behaviour), since it’s only ever subtracted from the limbo list: a garbage record simply doesn’t protect anything.</li>
  <li>It’s also OK to leave a false positive in a record: our leakage bounds assume each record keeps a different node (resource) alive.</li>
  <li>1 and 2 mean it doesn’t matter what pinned value we read in a record whose last update was started after we snapshotted the limbo list: resources in the limbo list are unreachable, so freshly pinned resources can’t refer to anything in the snapshot.</li>
</ol>

<p>This is where the clever bit of hazard pointers comes in:
we must make sure that any resource (pointer to a node, etc.) we borrow from a lock-free data structure is immediately protected by a HP record.
We can’t make two things happen atomically without locking, so
we’ll instead <em>guess</em> what resource we will borrow,
publish that,
and then actually borrow the resource.
If we guessed correctly, we can immediately use the borrowed resource;
if we were wrong, we simply try again.</p>

<p>On an ideal machine with a <a href="https://en.wikipedia.org/wiki/Sequential_consistency">sequential consistency memory model</a>,
the pseudocode looks like the following.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span>hp_read_sc.py </span></figcaption>
<div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
</pre></td><td class="code"><pre><code class="py"><span class="line"><span></span><span class="k">def</span> <span class="nf">hp_read_sc</span><span class="p">(</span><span class="n">cell</span><span class="p">,</span> <span class="n">record</span><span class="p">):</span>
</span><span class="line">    <span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
</span><span class="line">        <span class="n">guess</span> <span class="o">=</span> <span class="n">cell</span><span class="o">.</span><span class="n">load</span><span class="p">()</span>
</span><span class="line">        <span class="n">record</span><span class="o">.</span><span class="n">pin</span> <span class="o">=</span> <span class="n">guess</span>
</span><span class="line">        <span class="k">if</span> <span class="n">guess</span> <span class="o">==</span> <span class="n">cell</span><span class="o">.</span><span class="n">load</span><span class="p">():</span>
</span><span class="line">            <span class="k">return</span> <span class="n">guess</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>In practice, we must make sure that our write to <code>record.pin</code> is visible before re-reading the cell’s value, and we should also make sure the pointer read is ordered with respect to the rest of the calling read-side code.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span>hp_read_explicit.py </span></figcaption>
<div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
</pre></td><td class="code"><pre><code class="py"><span class="line"><span></span><span class="k">def</span> <span class="nf">hp_read_explicit</span><span class="p">(</span><span class="n">cell</span><span class="p">,</span> <span class="n">record</span><span class="p">):</span>
</span><span class="line">    <span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
</span><span class="line">        <span class="n">guess</span> <span class="o">=</span> <span class="n">cell</span><span class="o">.</span><span class="n">load_relaxed</span><span class="p">()</span>
</span><span class="line">        <span class="n">record</span><span class="o">.</span><span class="n">pin</span><span class="o">.</span><span class="n">store_relaxed</span><span class="p">(</span><span class="n">guess</span><span class="p">)</span>
</span><span class="line">        <span class="n">fence_store_load</span><span class="p">()</span>  <span class="c1"># R1</span>
</span><span class="line">        <span class="k">if</span> <span class="n">guess</span> <span class="o">==</span> <span class="n">cell</span><span class="o">.</span><span class="n">load_acquire</span><span class="p">():</span> <span class="c1"># R2</span>
</span><span class="line">            <span class="k">return</span> <span class="n">guess</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>We need a store/load fence in <code>R1</code> to make sure the store to the record is visible before the second read in <code>R2</code>.  Under the <a href="https://www.cl.cam.ac.uk/~pes20/weakmemory/x86tso-paper.tphols.pdf">TSO memory model used by x86 chips (PDF)</a>,
this fence also happens to be the only one that isn’t implicitly satisfied by the hardware memory model.
It also happens that fences are best implemented with atomic operations
on x86oids (instructions with a LOCK prefix),
so we can obviate the need for fencing in <code>R1</code>
by implementing the store just before <code>R1</code> with an atomic exchange (fetch-and-set).</p>

<p>The slow cleanup path has its own fence that matches <code>R1</code> (the one in <code>R2</code>
would match mutators’ writes to <code>cell</code>):</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span>hp_cleanup_explicit.py </span></figcaption>
<div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
</pre></td><td class="code"><pre><code class="py"><span class="line"><span></span><span class="k">def</span> <span class="nf">hp_cleanup_explicit</span><span class="p">(</span><span class="n">limbo</span><span class="p">,</span> <span class="n">records</span><span class="p">):</span>
</span><span class="line">    <span class="n">to_reclaim</span> <span class="o">=</span> <span class="n">limbo</span><span class="o">.</span><span class="n">consume_snapshot_acquire</span><span class="p">()</span>  <span class="c1"># C1</span>
</span><span class="line">    <span class="n">pinned</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
</span><span class="line">    <span class="k">for</span> <span class="n">record</span> <span class="ow">in</span> <span class="n">records</span><span class="p">:</span>
</span><span class="line">        <span class="n">pinned</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">record</span><span class="o">.</span><span class="n">pin</span><span class="o">.</span><span class="n">load_relaxed</span><span class="p">())</span>  <span class="c1"># C2</span>
</span><span class="line">    <span class="k">for</span> <span class="n">resource</span> <span class="ow">in</span> <span class="n">to_reclaim</span><span class="p">:</span>
</span><span class="line">        <span class="k">if</span> <span class="n">resource</span> <span class="ow">in</span> <span class="n">pinned</span><span class="p">:</span>
</span><span class="line">            <span class="n">limbo</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">resource</span><span class="p">)</span>
</span><span class="line">        <span class="k">else</span><span class="p">:</span>
</span><span class="line">            <span class="n">resource</span><span class="o">.</span><span class="n">destroy</span><span class="p">()</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>We must make sure all the values in the limbo list we grab in <code>C1</code>
were added to the list (and thus logically deleted) before we read any
of the records in <code>C2</code>, with the  acquire read in <code>C1</code>
matching the store-load fence in <code>R1</code>.</p>

<p>The following sequence diagrams shows how the fencing guarantees that any
iteration of <code>hp_read_explicit</code> will fail if it starts before <code>C1</code>
and observes a stale value.
If the read succeeds, the ordering between <code>R1</code> and <code>C1</code> instead
guarantees that the cleanup loop will observed the pinned value
when it reads the record in <code>C2</code>.</p>

<p><a href="https://sequencediagram.org/index.html#initialData=C4S2BsFMAIDFIHYGNIBNoAsCGAvLAndABwHsQFhJ8Aoaog0JEei6AJUi1SutS2CwAjLAGcYAWUgBbEvgCedBiCYtg0AOr4wVAPQBhKFgQBXIrU3b8+wyaIBaAHySZ8gFzQAqkT6VoKcODQAG5Y4MaQAPzUHFxUADx2zrJy7gDi4SIifpABwaHh0Zzc+I5JbtAACsaC4CAiGNBE5Aho0ADmGVnAJND4kEiyqNQWlFYGnLal0snuXj4w-oEhYZHUZXKOI7rjRqZp+ELQtVKCPbUiwNQAvFfwyDBsAIzQOtB6jzeFsfgJ6+4A8oIxPgggscoFTPMADS9SDAeTQEgIaCoEAAMzRa2m8k2WlG1gme2ggOBoOIzVaywKQA">
    <img src="/images/2020-07-06-flatter-wait-free-hazard-pointers/fenced-hp.png" />
</a></p>

<p>This all works, but it’s slow:<sup id="fnref:travis-says-its-fine"><a href="#fn:travis-says-its-fine" class="footnote">6</a></sup> we added an <em>atomic</em> write instruction (or worse, a fence) to a read-only operation.  We can do better with a little help from our operating system.</p>

<h2 id="injecting-fences-with-os-support">Injecting fences with OS support</h2>

<p>When we use fences or atomic instructions correctly, there should be
an implicit pairing between fences or atomics: we use fencing to
enforce an ordering (one must fully execute before or after another,
overlap is forbidden) between pairs of instructions in different
threads.  For example, the pseudocode for hazard pointers with
explicit fencing and memory ordering paired the store-load fence in
<code>R1</code> with the acquisition of the limbo list in <code>C1</code>.</p>

<p>We only need that pairing very rarely, when we actually enter the
cleanup function.  The amortisation strategy guarantees doesn’t happen too
quickly, and we can always increase the amortisation factor if we’re
generating tiny amounts of garbage very quickly.</p>

<p>It kind of sucks that we have to incur a full fence on the fast read
path, when it only matches reads in the cleanup loop maybe as rarely
as once a second.  If we wait long enough on the slow path, we can
<a href="https://pvk.ca/Blog/2019/01/09/preemption-is-gc-for-memory-reordering">rely on events like preemption or other interrupts to insert a barrier</a>
in all threads that are executing the read-side.</p>

<p>How long is “enough?”
Linux has the <a href="https://man7.org/linux/man-pages/man2/membarrier.2.html"><code>membarrier</code> syscall</a>
to block the calling thread until (more than) long enough has elapsed,
Window has <a href="https://docs.microsoft.com/en-us/windows/win32/api/processthreadsapi/nf-processthreadsapi-flushprocesswritebuffers">the similar <code>FlushProcessWriteBuffers</code></a>, and
on other operating systems, we can probably <a href="https://github.com/pkhuong/barrierd">do something useful with scheduler statistics</a> or ask for a new syscall.</p>

<p>Armed with these new (heavy) system calls, we can replace the store-load fence in <code>R1</code> with a compiler barrier, and execute a slow <code>membarrier</code>/<code>FlushProcessWriteBuffers</code> after <code>C1</code>.
The cleanup function will then wait long enough to ensure that any
read-side operation that had executed before <code>R1</code> at the time we read the limbo list in <code>C1</code> will be visible (e.g., because the operating system knows a preemption interrupt executed at least once on each core).
The pseudocode for this asymmetric strategy follows.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span>hp_read_membarrier.py </span></figcaption>
<div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
</pre></td><td class="code"><pre><code class="py"><span class="line"><span></span><span class="k">def</span> <span class="nf">hp_read_membarrier</span><span class="p">(</span><span class="n">cell</span><span class="p">,</span> <span class="n">record</span><span class="p">):</span>
</span><span class="line">    <span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
</span><span class="line">        <span class="n">guess</span> <span class="o">=</span> <span class="n">cell</span><span class="o">.</span><span class="n">load_relaxed</span><span class="p">()</span>
</span><span class="line">        <span class="n">record</span><span class="o">.</span><span class="n">pin</span><span class="o">.</span><span class="n">store_relaxed</span><span class="p">(</span><span class="n">guess</span><span class="p">)</span>
</span><span class="line">        <span class="n">compiler_barrier</span><span class="p">()</span>  <span class="c1"># R1</span>
</span><span class="line">        <span class="k">if</span> <span class="n">guess</span> <span class="o">==</span> <span class="n">cell</span><span class="o">.</span><span class="n">load_acquire</span><span class="p">():</span> <span class="c1"># R2</span>
</span><span class="line">            <span class="k">return</span> <span class="n">guess</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span>hp_cleanup_membarrier.py </span></figcaption>
<div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
</pre></td><td class="code"><pre><code class="py"><span class="line"><span></span><span class="k">def</span> <span class="nf">hp_cleanup_membarrier</span><span class="p">(</span><span class="n">limbo</span><span class="p">,</span> <span class="n">records</span><span class="p">):</span>
</span><span class="line">    <span class="n">to_reclaim</span> <span class="o">=</span> <span class="n">limbo</span><span class="o">.</span><span class="n">consume_snapshot_acquire</span><span class="p">()</span>
</span><span class="line">    <span class="n">os</span><span class="o">.</span><span class="n">membarrier</span><span class="p">()</span>  <span class="c1"># C1</span>
</span><span class="line">    <span class="n">pinned</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
</span><span class="line">    <span class="k">for</span> <span class="n">record</span> <span class="ow">in</span> <span class="n">records</span><span class="p">:</span>
</span><span class="line">        <span class="n">pinned</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">record</span><span class="o">.</span><span class="n">pin</span><span class="o">.</span><span class="n">load_relaxed</span><span class="p">())</span>  <span class="c1"># C2</span>
</span><span class="line">    <span class="k">for</span> <span class="n">resource</span> <span class="ow">in</span> <span class="n">to_reclaim</span><span class="p">:</span>
</span><span class="line">        <span class="k">if</span> <span class="n">resource</span> <span class="ow">in</span> <span class="n">pinned</span><span class="p">:</span>
</span><span class="line">            <span class="n">limbo</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">resource</span><span class="p">)</span>
</span><span class="line">        <span class="k">else</span><span class="p">:</span>
</span><span class="line">            <span class="n">resource</span><span class="o">.</span><span class="n">destroy</span><span class="p">()</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>We’ve replaced a fence on the fast read path with a compiler barrier, at the expense of executing a heavy syscall on the slow path.  That’s usually a good trade-off, and is the <a href="https://github.com/facebook/folly/blob/master/folly/synchronization/Hazptr.h">preferred implementation strategy for Folly’s hazard ointers</a>.</p>

<p>The freedom to pair mere <em>compiler</em> barriers with <code>membarrier</code>
syscalls opens the door for many more “atomic enough” operations, not
just the fenced stores and loads we used until now:
similarly to the key idea in <a href="https://github.com/concurrencykit/ck/blob/master/include/ck_ec.h">Concurrency Kit’s atomic-free SPMC event count</a>,
we can use non-interlocked read-modify-write instructions,
since any interrupt (please don’t mention imprecise interrupts) will execute before or after any such instruction,
and never in the middle of an instruction.</p>

<h2 id="wait-free-hazard-pointers-with-interrupt-atomic-instructions">Wait-free hazard pointers with interrupt-atomic instructions</h2>

<p>The key insight <a href="https://arxiv.org/abs/2002.07053">Blelloch and Wei</a>
had to achieve wait-freedom in hazard pointer is that the combination
of publishing a guess and confirming that the guess is correct in <code>hp_read</code>
emulates an atomic memory-memory copy.  Assuming we have such an atomic copy primitive, the read-side becomes trivial.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span>hp_read_blelloch_wei.py </span></figcaption>
<div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
</pre></td><td class="code"><pre><code class="py"><span class="line"><span></span><span class="k">def</span> <span class="nf">hp_read_membarrier</span><span class="p">(</span><span class="n">cell</span><span class="p">,</span> <span class="n">record</span><span class="p">):</span>
</span><span class="line">    <span class="n">cell</span><span class="o">.</span><span class="n">atomic_copy</span><span class="p">(</span><span class="n">record</span><span class="o">.</span><span class="n">pin</span><span class="p">)</span>
</span><span class="line">    <span class="k">return</span> <span class="n">record</span><span class="o">.</span><span class="n">pin</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>The “only” issue is that atomic memory-memory copies don’t exist in contemporary hardware.</p>

<p>However, we’ve already noted that syscalls like <code>membarrier</code> mean we can lower our requirements to interrupt atomicity, i.e., any individual instruction works since we’re assuming precise interrupts… and it just happens that <code>x86</code> and <code>amd64</code> do have single-instruction memory-memory copies!</p>

<p>The <a href="https://www.felixcloutier.com/x86/movs:movsb:movsw:movsd:movsq"><code>MOVS</code> instructions</a> are typically only used with a <code>rep</code> prefix.  However, they can also be executed without any prefix, to execute one iteration of the copy loop.  Executing a <code>REP</code>-free <code>MOVSQ</code> instruction copies one quadword (64 bits) from <code>[RSI]</code> to <code>[RDI</code>], and increment both registers, and all this stuff happens in one instructions, so will never be split by an interrupt.
That’s an <em>interrupt</em>-atomic copy, so we can simply slot that in place
of the software atomic copy in Blelloch and Wei’s proposal!</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span>hp_read_movs.py </span></figcaption>
<div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
</pre></td><td class="code"><pre><code class="py"><span class="line"><span></span><span class="k">def</span> <span class="nf">hp_read_movs</span><span class="p">(</span><span class="n">cell</span><span class="p">,</span> <span class="n">record</span><span class="p">):</span>
</span><span class="line">    <span class="n">x86</span><span class="o">.</span><span class="n">movs</span><span class="p">(</span><span class="n">record</span><span class="o">.</span><span class="n">pin</span><span class="p">,</span> <span class="n">cell</span><span class="p">)</span>  <span class="c1"># R1</span>
</span><span class="line">    <span class="k">return</span> <span class="n">record</span><span class="o">.</span><span class="n">pin</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Again, the <code>MOVS</code> instruction is not atomic, but will be ordered with
respect to the <code>membarrier</code> syscall in <code>hp_cleanup_membarrier</code>: either
it fully executes before the <code>membarrier</code> in <code>C1</code>, in which case the
pinned value will be visible to the cleanup loop, or it executes after
the <code>membarrier</code>, which guarantees it will not observe a stale value
that’s waiting in the limbo list.</p>

<p>That’s just one instruction, but instructions aren’t all created
equal. <a href="https://uops.info/html-instr/MOVSQ.html"><code>MOVS</code> is on the heavy side</a>: in order to read from memory, write to memory, and increment two registers,
a modern Intel chip has to execute 5 micro-ops in at least ~5 cycles.
That’s not exactly fast; definitely better than an atomic (<code>LOCK</code>ed)
instruction, but not fast.</p>

<p>We can improve that with a trick from classic hazard pointers, and
preserve wait-freedom.  We can usually guess what value we’ll find in
<code>record.pin</code>, simply by reading <code>cell</code> with a regular relaxed load.
Unless we’re extremely unlucky (realistically, as long as the reader
thread isn’t interrupted), <code>MOVSQ</code> will copy the same value we just
guessed.  That’s enough to exploit branch prediction and turn a data
dependency on <code>MOVSQ</code> (a high latency instruction) into a data
dependency on a regular load <code>MOV</code> (low latency), and a highly
predictable control dependency.  In very low level pseudo code, this
“speculative” version of the <code>MOVS</code> read-side might look like:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span>hp_read_movs_spec.py </span></figcaption>
<div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
</pre></td><td class="code"><pre><code class="py"><span class="line"><span></span><span class="k">def</span> <span class="nf">hp_read_movs_spec</span><span class="p">(</span><span class="n">cell</span><span class="p">,</span> <span class="n">record</span><span class="p">):</span>
</span><span class="line">    <span class="n">guess</span> <span class="o">=</span> <span class="n">cell</span><span class="o">.</span><span class="n">load_relaxed</span><span class="p">()</span>
</span><span class="line">    <span class="n">x86</span><span class="o">.</span><span class="n">movs</span><span class="p">(</span><span class="n">record</span><span class="o">.</span><span class="n">pin</span><span class="p">,</span> <span class="n">cell</span><span class="p">)</span>  <span class="c1"># R1</span>
</span><span class="line">    <span class="k">if</span> <span class="n">guess</span> <span class="o">==</span> <span class="n">record</span><span class="o">.</span><span class="n">pin</span><span class="p">:</span>
</span><span class="line">        <span class="k">return</span> <span class="n">guess</span>
</span><span class="line">    <span class="k">return</span> <span class="n">record</span><span class="o">.</span><span class="n">pin</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>At this point though, we might as well just read assembly.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span>hp_read_movs_spec.s </span></figcaption>
<div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
</pre></td><td class="code"><pre><code class="s"><span class="line"><span></span>    <span class="c1"># rsi: cell, rdi: record.pin</span>
</span><span class="line">    <span class="c1"># rax: guess</span>
</span><span class="line">    mov    <span class="p">(</span><span class="o">%rsi),%</span>rax            <span class="c1"># guess = cell.load_relaxed()</span>
</span><span class="line">    movsq  <span class="o">%ds:(%</span>rsi<span class="p">),</span><span class="o">%es:(%</span>rdi<span class="p">)</span>  <span class="c1"># MOVS cell -&gt; record.pin</span>
</span><span class="line">    cmp    <span class="o">%rax,-0x8(%</span>rdi<span class="p">)</span>        <span class="c1"># guess == record.pin ?</span>
</span><span class="line">    jne    slow                   <span class="c1"># if !=, goto slow</span>
</span><span class="line">    retq                          <span class="c1"># return guess</span>
</span><span class="line">slow<span class="o">:</span>
</span><span class="line">    mov    <span class="m">-0</span>x8<span class="p">(</span><span class="o">%rdi),%</span>rax        <span class="c1"># ret = record.pin</span>
</span><span class="line">    retq                          <span class="c1"># return ret</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>I’ll show at the end that, in reasonable circumstances, this wait-free
code sequence is faster than the usual membarrier-based lock-free
read side.  But first, let’s see how we can also recover wait-freedom
on less CISCy architectures, with an asymmetric “helping” scheme.</p>

<h2 id="interrupt-atomic-copy-with-some-help">Interrupt-atomic copy, with some help</h2>

<p>Blelloch’s and Wei’s wait-free atomic copy primitive builds on the
usual trick for wait-free algorithms: when a thread would wait for an
operation that’s half-way done, it helps that operation complete
instead of blocking.</p>

<p>This strategy has the marked advantage of working.  However, it’s
also symmetric between the common case (the thread that initiated
the operation quickly completes it), and the worst case (another
thread notices the initiating thread got stuck and moves the
operation along).  We pessimised the common case in order to eliminate blocking in the worst case, a frequent pattern in wait-free algorithms.</p>

<p>The source of the symmetry is our specification of an atomic copy
from one source field to exactly one destination field, which must
be written exactly once by either the thread that initiated the copy
(the hazard pointer reader), and any concurrent helper (the cleanup loop).</p>

<p>We can relax that requirement, since we know that the hazard pointer
scanning loop can handle spurious or garbage pinned values.  Rather
than forcing both the fast path and the slow path to write to the same
pinned field, we will give each HP record <em>two</em> pinned fields: a
single-writer one for the fast path, and a multi-writer one for all
helpers.</p>

<p>Until now a hazard pointer record has only had one field, the “pinned”
value.  We have to add some complexity to make this asymmetric helping
scheme work: in order for helpers to be able to help, we must publish
the cell we are reading, and we need somewhere for helpers to write
the pinned value they read.  We also need some sort of ABA protection
to make sure slow helpers don’t overwrite a fresher pinned value
with a stale one, when the <em>helper</em> gets stuck (preempted).</p>

<p>Concretely, the HP record still has a <code>pinned</code> field, which is only
written by the reader that owns the record, and read by cleanup
threads.  The <code>help</code> subrecord is written by both the owner of the
record and any reclaimer that might want to move a reader along.  The
reader will first write the address of the pointer it wants to read
and protect in <code>cell</code>, generate a new generation id by incrementing
<code>gen_sequence</code>, and write that to <code>pinned_or_gen</code>.  We’ll tell
generation ids apart from pinned addresses by their sign: negative
values are generation ids, positive ones are addresses.</p>

<p>At this point, any reclaimer should be able to notice that the
<code>help.pin_or_gen</code> is a generation value, and find a valid cell
address in <code>help.cell</code>.  That’s enough to read the cell’s value, and
update to the address is just read with a compare-and-swap (CAS) of
<code>pinned_or_gen</code>: if the CAS fails, another helper got there first, or
the reader has already moved on to a new target cell.  In the latter
case, any in-flight hazard pointer read sequence started before we
started reclaiming the limbo list, and we can thus ignore the record.</p>

<p>Having populated the <code>help</code> subrecord, a reader can now publish a
value in <code>pinned</code>, and then look for a pinned value in
<code>help.pin_or_gen</code>: if a helper published a pinned value there, the
reader must use it, and not a potentially staler (already destroyed)
value the reader wrote to <code>pinned</code>.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span>hp_record_wf.c </span></figcaption>
<div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
</pre></td><td class="code"><pre><code class="c"><span class="line"><span></span><span class="kt">intptr_t</span> <span class="n">gen_sequence</span> <span class="o">=</span> <span class="n">INTPTR_MIN</span><span class="p">;</span>
</span><span class="line">
</span><span class="line"><span class="k">struct</span> <span class="n">hp_record_wf</span> <span class="p">{</span>
</span><span class="line">        <span class="kt">void</span> <span class="o">*</span><span class="n">pinned</span><span class="p">;</span>
</span><span class="line">        <span class="k">struct</span> <span class="p">{</span>
</span><span class="line">                <span class="kt">void</span> <span class="o">**</span><span class="k">volatile</span> <span class="n">cell</span><span class="p">;</span>
</span><span class="line">                <span class="k">volatile</span> <span class="kt">intptr_t</span> <span class="n">pinned_or_gen</span><span class="p">;</span>
</span><span class="line">        <span class="p">}</span> <span class="n">help</span><span class="p">;</span>
</span><span class="line"><span class="p">};</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>On the read side, we can rely on two compiler barriers to let
membarriers guarantee writes to the <code>help</code> subrecord are visible
before we start reading from the target cell, and to guarantee
that any helper’s write to <code>record.help.pin_or_gen</code> are visible
before we compare it against <code>gen</code>:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span>hp_read_wf.py </span></figcaption>
<div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
</pre></td><td class="code"><pre><code class="py"><span class="line"><span></span><span class="k">def</span> <span class="nf">hp_read_wf</span><span class="p">(</span><span class="n">cell</span><span class="p">,</span> <span class="n">record</span><span class="p">):</span>
</span><span class="line">    <span class="n">gen</span> <span class="o">=</span> <span class="n">gen_sequence</span>
</span><span class="line">    <span class="n">gen_sequence</span> <span class="o">+=</span> <span class="mi">1</span>
</span><span class="line">    <span class="n">record</span><span class="o">.</span><span class="n">help</span><span class="o">.</span><span class="n">cell</span><span class="o">.</span><span class="n">store_relaxed</span><span class="p">(</span><span class="n">cell</span><span class="p">)</span>
</span><span class="line">    <span class="n">record</span><span class="o">.</span><span class="n">help</span><span class="o">.</span><span class="n">pin_or_gen</span><span class="o">.</span><span class="n">store_release</span><span class="p">(</span><span class="n">gen</span><span class="p">)</span>
</span><span class="line">    <span class="n">compiler_barrier</span><span class="p">()</span>  <span class="c1"># RA</span>
</span><span class="line">    <span class="n">guess</span> <span class="o">=</span> <span class="n">cell</span><span class="o">.</span><span class="n">load_acquire</span><span class="p">()</span>  <span class="c1"># R2</span>
</span><span class="line">    <span class="n">record</span><span class="o">.</span><span class="n">pin</span><span class="o">.</span><span class="n">store_relaxed</span><span class="p">(</span><span class="n">guess</span><span class="p">)</span>
</span><span class="line">    <span class="n">compiler_barrier</span><span class="p">()</span>  <span class="c1"># RB</span>
</span><span class="line">    <span class="k">if</span> <span class="n">record</span><span class="o">.</span><span class="n">help</span><span class="o">.</span><span class="n">pin_or_gen</span> <span class="o">!=</span> <span class="n">gen</span><span class="p">:</span>
</span><span class="line">        <span class="n">guess</span> <span class="o">=</span> <span class="n">record</span><span class="o">.</span><span class="n">help</span><span class="o">.</span><span class="n">pin_or_gen</span><span class="o">.</span><span class="n">load_acquire</span><span class="p">()</span><span class="o">.</span><span class="n">as_ptr</span><span class="p">()</span>
</span><span class="line">    <span class="k">return</span> <span class="n">guess</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>On the cleanup side, we will consume the limbo list, issue a
membarrier to catch any read-side critical section that wrote to
<code>pinned_or_gen</code> before we consumed the list, help these sections
along, issue another membarrier to guarantee that either the readers’
writes to <code>record.pin</code> are visible, or our writes to
<code>record.help.pin_or_gen</code> visible to readers, and finally scan the
records while remembering to pin the union of <code>record.pin</code> and
<code>record.help.pin_or_gen</code> if it holds a pinned value.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span>hp_cleanup_wf.py </span></figcaption>
<div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
<span class="line-number">18</span>
<span class="line-number">19</span>
<span class="line-number">20</span>
<span class="line-number">21</span>
</pre></td><td class="code"><pre><code class="py"><span class="line"><span></span><span class="k">def</span> <span class="nf">hp_cleanup_wf</span><span class="p">(</span><span class="n">limbo</span><span class="p">,</span> <span class="n">records</span><span class="p">):</span>
</span><span class="line">    <span class="n">to_reclaim</span> <span class="o">=</span> <span class="n">limbo</span><span class="o">.</span><span class="n">consume_snapshot_acquire</span><span class="p">()</span>
</span><span class="line">    <span class="n">os</span><span class="o">.</span><span class="n">membarrier</span><span class="p">()</span>  <span class="c1"># C1</span>
</span><span class="line">    <span class="k">for</span> <span class="n">record</span> <span class="ow">in</span> <span class="n">records</span><span class="p">:</span>
</span><span class="line">        <span class="n">gen</span> <span class="o">=</span> <span class="n">record</span><span class="o">.</span><span class="n">help</span><span class="o">.</span><span class="n">pin_or_gen</span><span class="o">.</span><span class="n">load_acquire</span><span class="p">()</span>
</span><span class="line">        <span class="k">if</span> <span class="n">gen</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
</span><span class="line">            <span class="c1"># XXX: How do we know this is safe?!</span>
</span><span class="line">            <span class="n">value</span> <span class="o">=</span> <span class="n">record</span><span class="o">.</span><span class="n">help</span><span class="o">.</span><span class="n">cell</span><span class="o">.</span><span class="n">load_relaxed</span><span class="p">()</span><span class="o">.</span><span class="n">load_acquire</span><span class="p">()</span>
</span><span class="line">            <span class="n">record</span><span class="o">.</span><span class="n">help</span><span class="o">.</span><span class="n">pin_or_gen</span><span class="o">.</span><span class="n">compare_exchange</span><span class="p">(</span><span class="n">gen</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>
</span><span class="line">    <span class="n">os</span><span class="o">.</span><span class="n">membarrier</span><span class="p">()</span>  <span class="c1"># C2</span>
</span><span class="line">    <span class="n">pinned</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
</span><span class="line">    <span class="k">for</span> <span class="n">record</span> <span class="ow">in</span> <span class="n">records</span><span class="p">:</span>
</span><span class="line">        <span class="n">helped</span> <span class="o">=</span> <span class="n">record</span><span class="o">.</span><span class="n">help</span><span class="o">.</span><span class="n">pin_or_gen</span><span class="o">.</span><span class="n">load_relaxed</span><span class="p">()</span>
</span><span class="line">        <span class="k">if</span> <span class="n">helped</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
</span><span class="line">            <span class="n">pinned</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">helped</span><span class="o">.</span><span class="n">as_ptr</span><span class="p">())</span>
</span><span class="line">        <span class="n">pinned</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">record</span><span class="o">.</span><span class="n">pin</span><span class="o">.</span><span class="n">load_relaxed</span><span class="p">())</span>
</span><span class="line">    <span class="k">for</span> <span class="n">resource</span> <span class="ow">in</span> <span class="n">to_reclaim</span><span class="p">:</span>
</span><span class="line">        <span class="k">if</span> <span class="n">resource</span> <span class="ow">in</span> <span class="n">pinned</span><span class="p">:</span>
</span><span class="line">            <span class="n">limbo</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">resource</span><span class="p">)</span>
</span><span class="line">        <span class="k">else</span><span class="p">:</span>
</span><span class="line">            <span class="n">resource</span><span class="o">.</span><span class="n">destroy</span><span class="p">()</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>The membarrier in <code>C1</code> matches the compiler barrier in <code>RA</code>: if a
read-side section executed <code>R2</code> before we consumed the limbo list, its
writes to <code>record.help</code> must be visible.  The second membarrier in
<code>C2</code> matches the compiler barrier in <code>RB</code>: if the read-side section
has written to <code>record.pin</code>, that write must be visible, otherwise,
the helper’s write to <code>help.pin_or_gen</code> must be visible to the reader.
Finally, when scanning for pinned values, we can’t determine whether
the reader used its own value, or the one we published, so we must
conservatively add both to the pinned set.</p>

<p>That’s a couple more instructions on the read-side that the
speculative <code>MOVSQ</code> implementation.  However, the instructions are
simpler, and the portable wait-free implementation benefits even more
from speculative execution: the final branch is equally predicatble,
and now depends only on a read of <code>record.help.pin_or_gen</code>, which can
be satisfied by forwarding the reader’s own write to that same field.</p>

<p>The end result is that, in my microbenchmarks, this portable wait-free
implementation does slightly <em>better</em> than the speculative <code>MOVSQ</code> code.</p>

<p>We can still do better, by further specialising the code.  The cleanup
path is already slow, what if we also assumed mutual exclusion, so that
for each record, only one cleanup call could be in flight at any one time?</p>

<h2 id="interrupt-atomic-copy-with-at-most-one-helper">Interrupt-atomic copy, with at most one helper</h2>

<p>Once we may assume mutual exclusion between cleanup loops, we don’t
have to worry about ABA protection anymore.  Hazard pointer records
become simpler:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span>hp_record_swf.c </span></figcaption>
<div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
</pre></td><td class="code"><pre><code class="c"><span class="line"><span></span><span class="k">struct</span> <span class="n">hp_record_swf</span> <span class="p">{</span>
</span><span class="line">        <span class="kt">void</span> <span class="o">*</span><span class="n">pinned</span><span class="p">;</span>
</span><span class="line">        <span class="k">struct</span> <span class="p">{</span>
</span><span class="line">                <span class="k">volatile</span> <span class="kt">intptr_t</span> <span class="n">cell_or_pin</span><span class="p">;</span>
</span><span class="line">        <span class="p">}</span> <span class="n">help</span><span class="p">;</span>
</span><span class="line"><span class="p">};</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>We’ll also use tagging with negative of positive values, this time to
distinguish target cell addresses (positive) from pinned values
(negative).  Now that the read side doesn’t have to update a
generation counter to obtain unique sequence values, it’s even simpler:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span>hp_read_swf.py </span></figcaption>
<div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
</pre></td><td class="code"><pre><code class="py"><span class="line"><span></span><span class="k">def</span> <span class="nf">hp_read_swf</span><span class="p">(</span><span class="n">cell</span><span class="p">,</span> <span class="n">record</span><span class="p">):</span>
</span><span class="line">    <span class="n">record</span><span class="o">.</span><span class="n">help</span><span class="o">.</span><span class="n">cell_or_pin</span><span class="o">.</span><span class="n">store_relaxed</span><span class="p">(</span><span class="n">cell</span><span class="o">.</span><span class="n">as_int</span><span class="p">())</span>
</span><span class="line">    <span class="n">compiler_barrier</span><span class="p">()</span>  <span class="c1"># RA</span>
</span><span class="line">    <span class="n">guess</span> <span class="o">=</span> <span class="n">cell</span><span class="o">.</span><span class="n">load_acquire</span><span class="p">()</span>  <span class="c1"># R2</span>
</span><span class="line">    <span class="n">record</span><span class="o">.</span><span class="n">pin</span><span class="o">.</span><span class="n">store_relaxed</span><span class="p">(</span><span class="n">guess</span><span class="p">)</span>
</span><span class="line">    <span class="n">compiler_barrier</span><span class="p">()</span>  <span class="c1"># RB</span>
</span><span class="line">    <span class="k">if</span> <span class="n">record</span><span class="o">.</span><span class="n">help</span><span class="o">.</span><span class="n">cell_or_pin</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
</span><span class="line">        <span class="n">guess</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span><span class="n">record</span><span class="o">.</span><span class="n">help</span><span class="o">.</span><span class="n">cell_or_pin</span><span class="o">.</span><span class="n">load_acquire</span><span class="p">())</span><span class="o">.</span><span class="n">as_ptr</span><span class="p">()</span>
</span><span class="line">    <span class="k">return</span> <span class="n">guess</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>The cleanup function isn’t particularly different, except for the new
encoding scheme.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span>hp_cleanup_swf.py </span></figcaption>
<div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
<span class="line-number">18</span>
<span class="line-number">19</span>
<span class="line-number">20</span>
<span class="line-number">21</span>
<span class="line-number">22</span>
</pre></td><td class="code"><pre><code class="py"><span class="line"><span></span><span class="k">def</span> <span class="nf">hp_cleanup_swf</span><span class="p">(</span><span class="n">limbo</span><span class="p">,</span> <span class="n">records</span><span class="p">):</span>
</span><span class="line">    <span class="k">with</span> <span class="n">cleanup_lock</span><span class="p">:</span>
</span><span class="line">        <span class="n">to_reclaim</span> <span class="o">=</span> <span class="n">limbo</span><span class="o">.</span><span class="n">consume_snapshot_acquire</span><span class="p">()</span>
</span><span class="line">        <span class="n">os</span><span class="o">.</span><span class="n">membarrier</span><span class="p">()</span>  <span class="c1"># C1</span>
</span><span class="line">        <span class="k">for</span> <span class="n">record</span> <span class="ow">in</span> <span class="n">records</span><span class="p">:</span>
</span><span class="line">            <span class="n">cell</span> <span class="o">=</span> <span class="n">record</span><span class="o">.</span><span class="n">help</span><span class="o">.</span><span class="n">cell_or_pin</span><span class="o">.</span><span class="n">load_relaxed</span><span class="p">()</span>
</span><span class="line">            <span class="k">if</span> <span class="n">cell</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
</span><span class="line">                <span class="c1"># XXX: How do we know this is safe?!</span>
</span><span class="line">                <span class="n">value</span> <span class="o">=</span> <span class="o">-</span><span class="n">cell</span><span class="o">.</span><span class="n">as_ptr</span><span class="p">()</span><span class="o">.</span><span class="n">load_acquire</span><span class="p">()</span><span class="o">.</span><span class="n">as_int</span><span class="p">()</span>
</span><span class="line">                <span class="n">record</span><span class="o">.</span><span class="n">help</span><span class="o">.</span><span class="n">cell_or_pin</span><span class="o">.</span><span class="n">compare_exchange</span><span class="p">(</span><span class="n">cell</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>
</span><span class="line">        <span class="n">os</span><span class="o">.</span><span class="n">membarrier</span><span class="p">()</span>  <span class="c1"># C2</span>
</span><span class="line">        <span class="n">pinned</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
</span><span class="line">        <span class="k">for</span> <span class="n">record</span> <span class="ow">in</span> <span class="n">records</span><span class="p">:</span>
</span><span class="line">            <span class="n">helped</span> <span class="o">=</span> <span class="n">record</span><span class="o">.</span><span class="n">help</span><span class="o">.</span><span class="n">cell_or_pin</span><span class="o">.</span><span class="n">load_relaxed</span><span class="p">()</span>
</span><span class="line">            <span class="k">if</span> <span class="n">helped</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
</span><span class="line">                <span class="n">pinned</span><span class="o">.</span><span class="n">add</span><span class="p">((</span><span class="o">-</span><span class="n">helped</span><span class="p">)</span><span class="o">.</span><span class="n">as_ptr</span><span class="p">())</span>
</span><span class="line">            <span class="n">pinned</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">record</span><span class="o">.</span><span class="n">pin</span><span class="o">.</span><span class="n">load_relaxed</span><span class="p">())</span>
</span><span class="line">        <span class="k">for</span> <span class="n">resource</span> <span class="ow">in</span> <span class="n">to_reclaim</span><span class="p">:</span>
</span><span class="line">            <span class="k">if</span> <span class="n">resource</span> <span class="ow">in</span> <span class="n">pinned</span><span class="p">:</span>
</span><span class="line">                <span class="n">limbo</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">resource</span><span class="p">)</span>
</span><span class="line">            <span class="k">else</span><span class="p">:</span>
</span><span class="line">                <span class="n">resource</span><span class="o">.</span><span class="n">destroy</span><span class="p">()</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Again, <code>RA</code> matches <code>C1</code>, and <code>RB</code> <code>C2</code>.  We’ll see in the
microbenchmarks that shaving the handful of instructions associated
with incrementing the generation counter does help in tight loops.</p>

<h2 id="qualitative-differences-between-hp-implementations">Qualitative differences between HP implementations</h2>

<p>A key attribute for hazard pointers is how much they slow down pointer
traversal in the common case.  However, there other qualitative
factors that should impact our choice of implementation.</p>

<p>The <a href="https://github.com/concurrencykit/ck/blob/master/include/ck_hp.h">classic fenced (<code>hp_read_explicit</code>) implementation</a>
needs one atomic or fence instruction per read, but does not depend on any
exotic OS operation.</p>

<p>A <a href="https://github.com/facebook/folly/blob/master/folly/synchronization/Hazptr.h">simple membarrier implementation (<code>hp_read_membarrier</code>)</a>
is ABI compatible with the fenced implementations, but lets the read side
replace the fence with a compiler barrier, as long as the
slow cleanup path can issue <a href="https://man7.org/linux/man-pages/man2/membarrier.2.html"><code>membarrier</code> syscalls</a>
on Linux, or <a href="https://docs.microsoft.com/en-us/windows/win32/api/processthreadsapi/nf-processthreadsapi-flushprocesswritebuffers">the similar <code>FlushProcessWriteBuffers</code></a>
on Windows.  All the remaining implementations (we won’t mention the much more complex wait-free implementation of <a href="https://arxiv.org/abs/2002.07053">Blelloch and Wei</a>)
also rely on the same syscalls to avoid fences or atomic instructions
on the read side, while additionally providing wait-freedom (constant
execution time) for readers, rather than mere lock-freedom.</p>

<p>The simple <code>MOVSQ</code>-based implementations (<code>hp_read_movs</code>) is fully
compatible with <code>hp_read_membarrier</code>, wait-free, and usually compiles
down to fewer instruction bytes, but slightly slower.  Adding
speculation (<code>hp_read_movs_spec</code>) retains compatibility and closes the
performance gap, with a comparable number of instruction bytes as the
lock-free membarrier implementation.  Both implementations rely on
<code>MOVSQ</code>, an instruction that only exists on <code>x86</code> and <code>amd64</code>.</p>

<p>However, we can also provide portable wait-freedom, once we modify the
cleanup code to help the read side sections forward.  The basic
implementation <code>hp_read_wf</code> compiles to many more instructions than
the other read-side implementations, but those instructions are mostly
upstream of the protected pointer read; in microbenchmarks, the result
can often be faster than the simple <code>hp_read_membarrier</code> or the
speculative <code>hp_read_movs_spec</code>.  The downside is that instruction
bytes tend to hurt much more in real code than in microbenchmarks.</p>

<p>We can simplify and shrink the portable wait-free code by assuming
mutual exclusion on the cleanup path (<code>hp_read_swf</code>).  Performance is
even better, and instruction bytes comparable to <code>hp_read_membarrier</code>.
However, we’ve introduced more opportunities for reclamation hiccups.</p>

<p>More importantly, achieving wait-freedom with concurrent help suffers
from a fundamental issue: helpers don’t know that the pointer they’re
trying to help read is stale until they CAS the value they read into
place.  This means they must be able to safely read potentially stale
pointers without crashing.  One might think mutual exclusion in the
cleanup function addresses this issue, but systems often mix and match
different reclamation schemes, as well as lock-free and lock-ful code.
On Linux, we can probably
abuse <a href="https://man7.org/linux/man-pages/man2/process_vm_readv.2.html">the <code>process_vm_readv</code> syscall</a>;
in general I suppose we can setup signal handlers to catch <code>SIGSEGV</code>
and <code>SIGBUS</code> in dedicated cleanup threads.</p>

<p><hr style="width: 50%" /></p>
<div class="footnotes">
  <ol>
    <li id="fn:but-also">
      <p>I also tend to read anything by <a href="https://dblp.uni-trier.de/pers/b/Blelloch:Guy_E=.html">Guy Blelloch</a>. <a href="#fnref:but-also" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:it-is-gc">
      <p>In fact, I’ve often argued that SMR <em>is</em> garbage collection, just not tracing GC. <a href="#fnref:it-is-gc" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:stable-alloc">
      <p>Hazard pointer records must still be managed separately, e.g., with a type stable allocator, but we can bootstrap everything else once we have a few records per thread. <a href="#fnref:stable-alloc" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:even-with-pinned-nodes">
      <p>We can even do that without keeping track of the number of nodes that were previously pinned by hazard pointer records and kept in the limbo list: each record can only pin at most one node, so we can wait until the limbo list is, e.g., twice the size of the record set. <a href="#fnref:even-with-pinned-nodes" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:or-hw-level">
      <p>Let’s also hope efforts like <a href="https://www.cl.cam.ac.uk/research/security/ctsrd/cheri/">CHERI</a> don’t have to break lock-free code. <a href="#fnref:or-hw-level" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:travis-says-its-fine">
      <p>That’s what <a href="https://travisdowns.github.io/blog/2020/07/06/concurrency-costs.html">Travis Downs classifies as a Level 1 concurrency cost</a>, which is usually fine for writes, but adds a sizable overhead to simple read-only code. <a href="#fnref:travis-says-its-fine" class="reversefootnote">&#8617;</a></p>
    </li>
  </ol>
</div>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Check for borrows in bitwise operations]]></title>
    <link href="https://www.pvk.ca/Blog/2020/05/02/check-for-borrows-in-bitwise-operations/"/>
    <updated>2020-05-02T17:24:39-04:00</updated>
    <id>https://www.pvk.ca/Blog/2020/05/02/check-for-borrows-in-bitwise-operations</id>
    <content type="html"><![CDATA[<p><small>2020-05-03: Had to add a complement step in the ULEB
section. Seems I couldn’t actually avoid that crummy-looking
notation. Spotted by redditor /u/Y_Less.</small></p>

<p>In the <a href="https://bits.houmus.org/2020-02-01/this-goes-to-eleven-pt4">fourth installment of his series on sorting with AVX2</a>,
<a href="https://twitter.com/damageboy">@damageboy</a> has a short aside where he
tries to detect partitioning (pivot) patterns where elements less than
and greater than or equal to the pivot are already in the correct
order: in that case, the partitioning routine does not need to permute
the block of values.  The practical details are irrelevant for this
post; what matters is that we wish to quickly identify whether a byte
value matches any of the follow nine cases:</p>

<ul>
  <li><code>0b11111111</code></li>
  <li><code>0b11111110</code></li>
  <li><code>0b11111100</code></li>
  <li><code>0b11111000</code></li>
  <li><code>0b11110000</code></li>
  <li><code>0b11100000</code></li>
  <li><code>0b11000000</code></li>
  <li><code>0b10000000</code></li>
  <li><code>0b00000000</code></li>
</ul>

<p>Looking at the bit patterns,<sup id="fnref:b-for-bit-literal"><a href="#fn:b-for-bit-literal" class="footnote">1</a></sup> the OP’s solution with <a href="https://www.felixcloutier.com/x86/popcnt">popcount</a> and <a href="https://www.felixcloutier.com/x86/bsf">bitscan</a>
is pretty natural.  These instructions are somewhat complex (latency
closer to 3 cycles than 1, and often port restricted),
and it seems like the sort of problem that would have had efficient
solutions before SSE4 finally graced x86 with a <a href="https://en.wikipedia.org/wiki/Hamming_weight">population count</a> instruction.</p>

<p>In the context of a sorting library’s partition loop, <code>popcnt</code> and
<code>bsf</code> is probably more than good enough:
<a href="https://bits.houmus.org/2020-02-01/this-goes-to-eleven-pt4">the post shows that the real issue is branch mispredictions</a>
being slower than permuting unconditionally.
This is just a fun challenge to think about (:</p>

<h2 id="warm-up-is_power_of_two">Warm-up: <code>is_power_of_two</code></h2>

<p>Detecting whether a machine integer is a power of two (or zero) is
another task that has a straightforward solution in terms of popcount
or bitscan.  There’s also a simpler classic solution to this problem:</p>

<p><code>x == 0 || is_power_of_two(x) &lt;==&gt; (x &amp; (x - 1)) == 0</code></p>

<p>How does that expression work?  Say <code>x</code> is a power of two. Its binary
representation is <code>0b0...010...0</code>: any number of leading zeros,<sup id="fnref:big-endian"><a href="#fn:big-endian" class="footnote">2</a></sup>
a single “1” bit, and trailing zeros (maybe none).  Let’s see what happens when
we subtract 1 from <code>x</code>:</p>

<pre><code>x           = 0b00...0010...0
     x - 1  = 0b00...0001...1
x &amp; (x - 1) = 0b00...0000...0
</code></pre>

<p>The subtraction triggered a chain of <a href="https://en.wikipedia.org/wiki/Carry_(arithmetic)">borrows</a>
throughout the trailing zeros, until we finally hit that 1 bit.
In decimal, subtracting one from <code>10...0</code> yields <code>09...9</code>;
in binary we instead find <code>01...1</code>.
If you ever studied the circuit depth (latency) of carry chains
(for me, that was for circuit complexity theory), you know
that this is difficult to do well.
Luckily for us, <a href="https://en.wikipedia.org/wiki/Kogge%E2%80%93Stone_adder">chip makers work hard to pull it off</a>,
and we can just use carries as a data-controlled
primitive to efficiently flip ranges of bits.</p>

<p>When <code>x</code> is a power of two, <code>x</code> and <code>x - 1</code> have no “1” bit in common,
so taking the bitwise <code>and</code> yields zero.  That’s also true when <code>x</code> is 0,
since <code>and</code>ing anything with 0 yields zero.  Let’s see what happens
for non-zero, non-power-of-two values <code>x = 0bxx...xx10..0</code>,
i.e., where <code>x</code> consists of an arbitrary non-zero sequence of bits <code>xx..xx</code>
followed by the least set bit (there’s at least one, since <code>x</code> is neither zero nor a power of two), and the trailing zeros:</p>

<pre><code>x           = 0bxx...xx10...0
     x - 1  = 0bxx...xx01...1
x &amp; (x - 1) = 0bxx...xx000000
</code></pre>

<p>The leading not-all-zero <code>0bxx...xx</code> is unaffected by the subtraction,
so it passes through the bitwise <code>and</code> unscathed (<code>and</code>ing any bit with
itself yields that same bit), and we know there’s at least one non-zero
bit in there; our test correctly rejects it!</p>

<h2 id="stretching-decoding-varints">Stretching: decoding varints</h2>

<p>When decoding variable length integers in <a href="https://en.wikipedia.org/wiki/LEB128#Unsigned_LEB128">ULEB</a>
format, e.g., for <a href="https://developers.google.com/protocol-buffers/docs/encoding">protocol buffers</a>,
it quickly becomes clear that, in order to avoid byte-at-a-time logic,
we must rapidly segment (<a href="https://en.wikipedia.org/wiki/Lexical_analysis">lex or tokenize</a>, in a way) our byte stream to determine where each ULEB
ends.  Let’s focus on the fast path, when the encoded ULEB fits in a
machine register.</p>

<p>We have <code>uleb = 0bnnnnnnnnmmmmmmmm...0zzzzzzz1yyyyyyy1...</code>:
a sequence of bytes<sup id="fnref:remember-endianness"><a href="#fn:remember-endianness" class="footnote">3</a></sup> with the topmost bit equal to 1,
terminated by a byte with the top bit set to 0,
and, finally, arbitrary nuisance bytes (<code>m...m</code>, <code>n...n</code>, etc.) we wish to ignore.
Ideally, we’d extract <code>data = 0b0000000000000000...?zzzzzzz?yyyyyyy?...</code> from <code>uleb</code>: we want to clear the
nuisance bytes, and are fine with arbitrary values in the
ULEB’s control bits.</p>

<p>It’s much easier to find bits set to 1 than to zero, so the first thing to do is
to complement the <code>ULEB</code> data and
clear out everything but potential ULEB control bits (the high bit of
each byte), with <code>c = ~uleb &amp; (128 * (WORD_MAX / 255))</code>, i.e.,
compute the bitwise <code>and</code> of <code>~uleb</code> with a bitmask of the high bit in each byte.</p>

<pre><code>   uleb = 0bnnnnnnnnmmmmmmmm...0zzzzzzz1yyyyyyy1...
  ~uleb = 0b̅n̅n̅n̅n̅n̅n̅n̅n̅m̅m̅m̅m̅m̅m̅m̅m̅...1z̅z̅z̅z̅z̅z̅z0y̅y̅y̅y̅y̅y̅y0...
      c = 0b̅n̅0000000̅m̅0000000...10000000000000000...
</code></pre>

<p>We could now bitscan to find the index of the first 1 (marking the
last ULEB byte), and then generate a mask.  However, it seems wasteful to
generate an index with a scan, only to convert it back into bitmap
space with a shift.  We’ll probably still want that index to know how
far to advance the decoder’s cursor, but we can hopefully update the
cursor in parallel with decoding the current ULEB value.</p>

<p>When we were trying to detect powers of two, we subtracted <code>1</code> from
<code>x</code>, a value kind of like <code>c</code>, in order to generate a new value
that differed from <code>x</code> in all the bits up to and including the first
set (equal to <code>1</code>) bit of <code>x</code>, and identical in the remaining bits.  We
then used the fact that <code>and</code>ing a bit with itself yields that same
bit to detect whether there was any non-zero bit in the remainder.</p>

<p>Here, we wish to do something else with the remaining untouched bits, we
wish to set them all to zero.  Another bitwise operator does
what we want: <code>xor</code>ing a bit with itself always yields zero, while
<code>xor</code>ing bits that differ yields <code>1</code>.  That’s the plan for ULEB. We’ll
subtract 1 from <code>c</code> and <code>xor</code> that back with <code>c</code>.</p>

<pre><code>       uleb = 0bnnnnnnnnmmmmmmmm...0zzzzzzz1yyyyyyy1...
      ~uleb = 0b̅n̅n̅n̅n̅n̅n̅n̅n̅m̅m̅m̅m̅m̅m̅m̅m̅...1z̅z̅z̅z̅z̅z̅z0y̅y̅y̅y̅y̅y̅y0...
c           = 0b̅n̅0000000̅m̅0000000...10000000000000000...
     c - 1  = 0b̅n̅0000000̅m̅0000000...01111111111111111...
c ^ (c - 1) = 0b0000000000000000...11111111111111111...
</code></pre>

<p>We now just have to bitwise <code>and</code> <code>uleb</code> with <code>c ^ (c - 1)</code>
to obtain the bits of the first <code>ULEB</code> value in <code>uleb</code>, while
overwriting everything else with 0.  Once we have that, we can either
<a href="https://www.felixcloutier.com/x86/pext">extract data bits with <code>PEXT</code></a>
on recent Intel chips, or otherwise dust off interesting stunts for <a href="https://en.wikipedia.org/wiki/SWAR">SWAR</a> shifts by variable amounts.</p>

<h2 id="now-for-damageboys-problem">Now for <a href="https://bits.houmus.org/2020-02-01/this-goes-to-eleven-pt4">damageboy</a>’s problem</h2>

<p>Let’s first repeat the question that motivated this post.  We want to detect when a byte <code>p</code> is one of the following nine values:</p>

<ul>
  <li><code>0b11111111</code></li>
  <li><code>0b11111110</code></li>
  <li><code>0b11111100</code></li>
  <li><code>0b11111000</code></li>
  <li><code>0b11110000</code></li>
  <li><code>0b11100000</code></li>
  <li><code>0b11000000</code></li>
  <li><code>0b10000000</code></li>
  <li><code>0b00000000</code></li>
</ul>

<p>These bit patterns feel similar to those for power of two bytes: if we
complement the bits, these values are all 1 less than a power of two
(or -1, one less than zero).  We already know how to detect when a
value <code>x</code> is zero or a power of two (<code>x &amp; (x - 1) == 0</code>), so it’s easy
to instead determine whether <code>~p</code> is one less than zero or a power of
two: <code>(~p + 1) &amp; ~p == 0</code>.</p>

<p>This is already pretty good: bitwise <code>not</code> the byte <code>p</code>,
and check if it’s one less than zero or a power of two (three simple
instructions on the critical path).  We can do better.</p>

<p>There’s another name for <code>~p + 1</code>, i.e., for bitwise complementing a value and
adding one: that’s simply <code>-p</code>, the additive inverse of <code>p</code> in two’s
complement!  We can use <code>-p &amp; ~p == 0</code>.  That’s one fewer
instruction on the critical path of our dependency graph (down to two, since we can <a href="https://www.felixcloutier.com/x86/test"><code>test</code> whether <code>and</code>ing yields zero</a>), and still only
uses simple instructions that are unlikely to be port constrained.</p>

<p>Let’s check our logic by enumerating all byte-sized values.</p>

<pre><code>CL-USER&gt; (dotimes (p 256)
           (when (zerop (logand (- p) (lognot p) 255))
             (format t "0b~2,8,'0r~%" p)))
0b00000000
0b10000000
0b11000000
0b11100000
0b11110000
0b11111000
0b11111100
0b11111110
0b11111111
</code></pre>

<p>These <em>are</em> the bytes we’re looking for (in ascending rather
than descending order)!</p>

<h2 id="remember-the-power-of-borrows">Remember the power of borrows</h2>

<p>I hope the examples above communicated a pattern I often observe when
mangling bits: operations that are annoying (not hard, just a bit more
complex than we’d like) in the bitmap domain can be simpler in two’s
complement arithmetic.  Arithmetic operations are powerful mutators
for bitmaps, but they’re often hard to control.  Subtracting or adding
1 are the main exceptions: it’s easy to describe their impact in terms
of the low bits of the bitmap.  In fact, we can extend that trick to
subtracting or adding powers of two: it’s the same carry/borrow chain effect as for 1,
except that bits smaller than the power of two pass straight
through…
which might be useful when we expect a known tag followed by a ULEB value that must be decoded.</p>

<p>If you find yourself wishing for a way to flip ranges of bits in a
data-dependent fashion, it’s always worth considering the two’s
complement representation of the problem for a couple minutes.  Adding
or subtracting powers of two doesn’t always work, but the payoff is
pretty good when it does.</p>

<p>P.S., <a href="http://0x80.pl/notesen/2016-10-16-detecting-bit-pattern.html">Wojciech Muła offers a different 3-operation sequence with <code>-p</code></a>
to solve damageboy’s problem.
That’s another nice primitive to generate bitmasks dynamically.</p>

<p><small>Thank you Ruchir for helping me clarify the notation around the ULEB section.</small></p>

<p><hr style="width: 50%" /></p>
<div class="footnotes">
  <ol>
    <li id="fn:b-for-bit-literal">
      <p>I use the <code>0b...</code> syntax throughout this post to denote bit literals, similarly to the usual <code>0x...</code> hexadecimal literals. <a href="#fnref:b-for-bit-literal" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:big-endian">
      <p>While I prefer to work with little-endian bytes, I find everything makes more sense with big-endian bits. <a href="#fnref:big-endian" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:remember-endianness">
      <p>Remember, while ULEB is little-endian, we use big bit-endianness. <a href="#fnref:remember-endianness" class="reversefootnote">&#8617;</a></p>
    </li>
  </ol>
</div>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[How hard is it to guide test case generators with branch coverage feedback?]]></title>
    <link href="https://www.pvk.ca/Blog/2020/03/11/how-hard-is-it-to-guide-test-case-generators-with-branch-coverage-feedback/"/>
    <updated>2020-03-11T18:00:26-04:00</updated>
    <id>https://www.pvk.ca/Blog/2020/03/11/how-hard-is-it-to-guide-test-case-generators-with-branch-coverage-feedback</id>
    <content type="html"><![CDATA[<p>To make a long story short, it’s almost easy,
now that <a href="https://github.com/torvalds/linux/blob/master/tools/perf/Documentation/intel-bts.txt">tracing</a> is available on commodity hardware,
especially with a <a href="https://gist.github.com/pkhuong/1ce34e33c6df4b9be3bc9beb22415a47">small library to handle platform-specific setup</a>.</p>

<p>Here’s a graph of the empirical distribution functions
for the number of calls into <a href="https://github.com/google/fuzzer-test-suite/tree/7e08b745d1e264eedb9a91b1fd0a931f1bec3b83/openssl-1.0.1f">OpenSSL 1.0.1f</a>
it takes for <a href="https://hypothesis.works/">Hypothesis</a>
to find <a href="https://en.wikipedia.org/wiki/Heartbleed">Heartbleed</a>,
given a description of the <a href="https://tools.ietf.org/html/rfc6520">format for Heartbeat requests</a> (“grammar”),
and the same with additional branch coverage feedback (“bts”, for Intel Branch Trace Store).</p>

<!-- ggplot(data, aes(x=Calls, colour=Impl)) + stat_ecdf() + scale_color_discrete(name="Implementation") + scale_x_log10() + ylab("Cumulative fraction") + xlab("Calls to OpenSSL until crash") -->
<p><img class="center" src="/images/2020-03-11-how-hard-is-it-to-guide-test-case-generators-with-branch-coverage-feedback/ecdf.png" /></p>

<p>On average, knowing the grammar for Heartbeat requests lets Hypothesis find
the vulnerability after 535 calls to OpenSSL;
when we add branch coverage feedback, the average goes down to 473<sup id="fnref:realtime"><a href="#fn:realtime" class="footnote">1</a></sup> calls, 11.5% faster.
The plot shows that,
as long as we have time for more than 100 calls to OpenSSL,
branch coverage information makes it more likely that Hypothesis will find Heartbleed
for every attempt budget.
I’ll describe this experiment in more details later in the post;
first, why did I ask that question?</p>

<h2 id="enumerating-test-cases-by-hand-is-a-waste-of-peoples-time">Enumerating test cases by hand is a waste of people’s time</h2>

<p>I care about efficiently generating test cases because
I believe that most of the time people spend writing, reviewing, and maintaining
classic <a href="https://testing.googleblog.com/2010/12/test-sizes.html">small or medium tests</a>
is misallocated.
There’s a place for them, same as there is for manual QA testing… but their returns curve is strongly concave.</p>

<p>Here are the sort of things I want to know when I look at typical unit test code:</p>
<ol>
  <li>Why do we make this exact assertion; what makes a result acceptable?<sup id="fnref:matchers"><a href="#fn:matchers" class="footnote">2</a></sup></li>
  <li>Why do we feed this or that input; what makes input data useful or interesting?</li>
  <li>What is expected to change when I tweak the external behaviour of the system under test;<sup id="fnref:change-detector"><a href="#fn:change-detector" class="footnote">3</a></sup> how are answers to the previous two questions encoded?</li>
</ol>

<p>As programmers, I think it’s natural to say that,
if we need to formalize how we come up with assertions, or how we decide what inputs to use during testing,
we should express that in code.
But once we have that code, why would we enumerate test cases manually?
That’s a job for a computer!</p>

<h2 id="property-based-testing-at-backtrace"><a href="https://increment.com/testing/in-praise-of-property-based-testing/">Property-based testing</a> at Backtrace</h2>

<p>I have such conviction in this thesis that,
as soon as I took over the query processing component (a library written in C with a dash of intrinsics and inline assembly) at <a href="https://backtrace.io">Backtrace</a>,
I introduced a new testing approach based on <a href="https://hypothesis.readthedocs.io/en/latest/index.html">Hypothesis</a>.
The query engine was always designed and built as a discrete library,
so it didn’t take too much work to disentangle it from other pieces of business logic.
That let us quickly add coverage for the external interface (partial coverage, this is still work
in progress), as well as for key internal components that we chose to expose for testing.</p>

<p>Along the way, I had to answer a few reasonable questions:</p>

<ol>
  <li>What is Hypothesis?</li>
  <li>Why Hypothesis?</li>
  <li>Wait, there are multiple language backends for Hypothesis, but none for C or C++; how does that work?</li>
</ol>

<h3 id="what-is-hypothesis">What is Hypothesis?</h3>
<p><a href="https://hypothesis.works/">Hypothesis</a> is a Python library that helps programmers generate test cases programmatically,
and handles a lot of the annoying work involved in making such generators practical to use.
Here’s an excerpt from real test code for our vectorised operations on arrays of 64-bit integers.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span>test_u64_block.py </span></figcaption>
<div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
<span class="line-number">18</span>
<span class="line-number">19</span>
<span class="line-number">20</span>
<span class="line-number">21</span>
</pre></td><td class="code"><pre><code class="py"><span class="line"><span></span><span class="kn">from</span> <span class="nn">hypothesis</span> <span class="kn">import</span> <span class="n">given</span>
</span><span class="line"><span class="kn">import</span> <span class="nn">hypothesis.strategies</span> <span class="kn">as</span> <span class="nn">st</span>
</span><span class="line">
</span><span class="line"><span class="k">def</span> <span class="nf">check_u64_bitmask</span><span class="p">(</span><span class="n">booleans</span><span class="p">):</span>
</span><span class="line">    <span class="sd">&quot;&quot;&quot;Given a list of 8 booleans, generates the corresponding array of</span>
</span><span class="line"><span class="sd">    u64 masks, and checks that they are correctly compressed to a u8</span>
</span><span class="line"><span class="sd">    bitmask.</span>
</span><span class="line"><span class="sd">    &quot;&quot;&quot;</span>
</span><span class="line">    <span class="n">expected</span> <span class="o">=</span> <span class="mi">0</span>
</span><span class="line">    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">booleans</span><span class="p">):</span>
</span><span class="line">        <span class="k">if</span> <span class="n">value</span><span class="p">:</span>
</span><span class="line">            <span class="n">expected</span> <span class="o">|=</span> <span class="mi">1</span> <span class="o">&lt;&lt;</span> <span class="n">i</span>
</span><span class="line">    <span class="n">masks</span> <span class="o">=</span> <span class="n">struct</span><span class="o">.</span><span class="n">pack</span><span class="p">(</span><span class="s2">&quot;8Q&quot;</span><span class="p">,</span> <span class="o">*</span><span class="p">[</span><span class="mi">2</span> <span class="o">**</span> <span class="mi">64</span> <span class="o">-</span> <span class="mi">1</span> <span class="k">if</span> <span class="n">boolean</span> <span class="k">else</span> <span class="mi">0</span> <span class="k">for</span> <span class="n">boolean</span> <span class="ow">in</span> <span class="n">booleans</span><span class="p">])</span>
</span><span class="line">    <span class="k">assert</span> <span class="n">expected</span> <span class="o">==</span> <span class="n">C</span><span class="o">.</span><span class="n">u64_block_bitmask</span><span class="p">(</span><span class="n">FFI</span><span class="o">.</span><span class="n">from_buffer</span><span class="p">(</span><span class="s2">&quot;uint64_t[]&quot;</span><span class="p">,</span> <span class="n">masks</span><span class="p">))</span>
</span><span class="line">
</span><span class="line">
</span><span class="line"><span class="k">class</span> <span class="nc">TestU64BlockOp</span><span class="p">(</span><span class="n">TestCase</span><span class="p">):</span>
</span><span class="line">
</span><span class="line">    <span class="nd">@given</span><span class="p">(</span><span class="n">bits</span><span class="o">=</span><span class="n">st</span><span class="o">.</span><span class="n">lists</span><span class="p">(</span><span class="n">st</span><span class="o">.</span><span class="n">booleans</span><span class="p">(),</span> <span class="n">min_size</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">max_size</span><span class="o">=</span><span class="mi">8</span><span class="p">))</span>
</span><span class="line">    <span class="k">def</span> <span class="nf">test_u64_block_bitmask</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">bits</span><span class="p">):</span>
</span><span class="line">        <span class="n">check_u64_bitmask</span><span class="p">(</span><span class="n">bits</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>A key component of these operations is a C (SSE intrinsics, really) function that accepts eight 64-bit masks as four 128-bit SSE registers (one pair of masks per register),
and returns a byte, with one bit per mask.
In order to test that logic, we expose <code>u64_block_bitmask</code>, a wrapper that accepts an array of eight masks
and forwards its contents to the mask-to-bit function.</p>

<p><img class="center" src="/images/2020-03-11-how-hard-is-it-to-guide-test-case-generators-with-branch-coverage-feedback/reduction.jpg" /></p>

<p><code>check_u64_bitmask</code> calls that wrapper function from Python, and asserts that its return value is as expected: 1 for each mask that’s all 1s, and 0 for each mask that’s all 0s.
We turn <code>check_u64_bitmask</code> into a test cases generator
by annotating the test method <code>test_u64_block_bitmask</code> with a <a href="https://hypothesis.readthedocs.io/en/latest/details.html#hypothesis.given"><code>@given</code> decorator</a>
that asks Hypothesis to generate arbitrary lists of eight booleans.</p>

<p>Of course, there are only 256 lists of eight booleans; we should test that exhaustively.
Hypothesis has the <a href="https://hypothesis.readthedocs.io/en/latest/reproducing.html#hypothesis.example"><code>@example</code> decorator</a>,
so it’s really easy to implement our own Python decorator to apply
<code>hypothesis.example</code> once for each element in an iterable.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span>test_u64_block.py </span></figcaption>
<div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
<span class="line-number">18</span>
<span class="line-number">19</span>
</pre></td><td class="code"><pre><code class="py"><span class="line"><span></span><span class="k">def</span> <span class="nf">all_examples</span><span class="p">(</span><span class="n">examples</span><span class="p">):</span>
</span><span class="line">    <span class="sd">&quot;&quot;&quot;Applies a list of hypothesis.examples.&quot;&quot;&quot;</span>
</span><span class="line">    <span class="k">def</span> <span class="nf">apply_examples</span><span class="p">(</span><span class="n">fn</span><span class="p">):</span>
</span><span class="line">        <span class="k">for</span> <span class="n">ex</span> <span class="ow">in</span> <span class="nb">reversed</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">examples</span><span class="p">)):</span>
</span><span class="line">            <span class="n">fn</span> <span class="o">=</span> <span class="n">example</span><span class="p">(</span><span class="n">ex</span><span class="p">)(</span><span class="n">fn</span><span class="p">)</span>
</span><span class="line">    <span class="k">return</span> <span class="n">apply_examples</span>
</span><span class="line">
</span><span class="line">
</span><span class="line"><span class="k">def</span> <span class="nf">extract_bits</span><span class="p">(</span><span class="n">number</span><span class="p">,</span> <span class="n">num_bits</span><span class="p">):</span>
</span><span class="line">    <span class="sd">&quot;&quot;&quot;Converts the num_bits bit number to a list of booleans.&quot;&quot;&quot;</span>
</span><span class="line">    <span class="k">return</span> <span class="p">[(</span><span class="n">number</span> <span class="o">&amp;</span> <span class="p">(</span><span class="mi">1</span> <span class="o">&lt;&lt;</span> <span class="n">shift</span><span class="p">))</span> <span class="o">!=</span> <span class="mi">0</span> <span class="k">for</span> <span class="n">shift</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_bits</span><span class="p">)]</span>
</span><span class="line">
</span><span class="line">
</span><span class="line"><span class="k">class</span> <span class="nc">TestU64BlockOp</span><span class="p">(</span><span class="n">TestCase</span><span class="p">):</span>
</span><span class="line">
</span><span class="line">    <span class="nd">@all_examples</span><span class="p">(</span><span class="n">extract_bits</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="mi">8</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">256</span><span class="p">))</span>
</span><span class="line">    <span class="nd">@given</span><span class="p">(</span><span class="n">bits</span><span class="o">=</span><span class="n">st</span><span class="o">.</span><span class="n">lists</span><span class="p">(</span><span class="n">st</span><span class="o">.</span><span class="n">booleans</span><span class="p">(),</span> <span class="n">min_size</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">max_size</span><span class="o">=</span><span class="mi">8</span><span class="p">))</span>
</span><span class="line">    <span class="k">def</span> <span class="nf">test_u64_block_bitmask</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">bits</span><span class="p">):</span>
</span><span class="line">        <span class="n">check_u64_bitmask</span><span class="p">(</span><span class="n">bits</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>That’s pretty cool, but we could enumerate that more efficiently in C.
Where Hypothesis shines is in reporting easily actionable failures.
We’re wasting computer time in order to save developer time, and that’s usually a reasonable trade-off.
For example, here’s what Hypothesis spits back via pytest when I introduce a bug to ignore the
last pair of masks, masks 6 and 7, and instead reuse the register that holds masks 4 and 5 (a mistake that’s
surprisingly easy to make when writing intrinsics by hand).</p>

<p><img class="center" src="/images/2020-03-11-how-hard-is-it-to-guide-test-case-generators-with-branch-coverage-feedback/bad-reduction.jpg" /></p>

<pre><code>booleans = [False, False, False, False, False, False, ...]

    def check_u64_bitmask(booleans):
        """Given a list of 8 booleans, generates the corresponding array of
        u64 masks, and checks that they are correctly compressed to a u8
        bitmask.
        """
        expected = 0
        for i, value in enumerate(booleans):
            if value:
                expected |= 1 &lt;&lt; i
        masks = struct.pack("8Q", *[2 ** 64 - 1 if boolean else 0 for boolean in booleans])
&gt;       assert expected == C.u64_block_bitmask(FFI.from_buffer("uint64_t[]", masks))
E       AssertionError: assert 128 == 0
E         -128
E         +0

test_u64_block.py:40: AssertionError
-------------------------------------- Hypothesis ----------------------------------------------
Falsifying example: test_u64_block_bitmask(
    self=&lt;test_u64_block.TestU64BlockOp testMethod=test_u64_block_bitmask&gt;,
    bits=[False, False, False, False, False, False, False, True],
)
</code></pre>

<p>Hypothesis finds the bug in a fraction of a second,
but, more importantly, it then works harder to report a minimal counter-example.<sup id="fnref:unless-examples"><a href="#fn:unless-examples" class="footnote">4</a></sup>
With all but the last mask set to 0,
it’s easy to guess that we’re probably ignoring the value of
the last mask (and maybe more), which would be why we found a bitmask of
0 rather than 128.</p>

<h3 id="why-hypothesis">Why Hypothesis?</h3>
<p>So far this is all regular property-based testing,
with a hint of more production-readiness than we’ve come to expect from clever software correctness tools.
What really sold me was <a href="https://hypothesis.readthedocs.io/en/latest/stateful.html">Hypothesis’s stateful testing</a>
capability, which makes it easy to test not only individual functions, but also methods on stateful objects.</p>

<p>For example, here is the test code for our specialised representation of lists of row ids (of 64-bit integers),
which reuses internal bits as inline storage in the common case when the list is small (the type is called <code>entry</code> because it’s
a pair of a key and a list of values).</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span>test_inlined_list.py </span></figcaption>
<div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
<span class="line-number">18</span>
<span class="line-number">19</span>
<span class="line-number">20</span>
<span class="line-number">21</span>
<span class="line-number">22</span>
<span class="line-number">23</span>
<span class="line-number">24</span>
<span class="line-number">25</span>
<span class="line-number">26</span>
<span class="line-number">27</span>
<span class="line-number">28</span>
<span class="line-number">29</span>
<span class="line-number">30</span>
<span class="line-number">31</span>
<span class="line-number">32</span>
<span class="line-number">33</span>
<span class="line-number">34</span>
<span class="line-number">35</span>
<span class="line-number">36</span>
<span class="line-number">37</span>
<span class="line-number">38</span>
<span class="line-number">39</span>
<span class="line-number">40</span>
<span class="line-number">41</span>
<span class="line-number">42</span>
<span class="line-number">43</span>
<span class="line-number">44</span>
<span class="line-number">45</span>
<span class="line-number">46</span>
<span class="line-number">47</span>
<span class="line-number">48</span>
<span class="line-number">49</span>
<span class="line-number">50</span>
<span class="line-number">51</span>
<span class="line-number">52</span>
<span class="line-number">53</span>
<span class="line-number">54</span>
<span class="line-number">55</span>
<span class="line-number">56</span>
<span class="line-number">57</span>
<span class="line-number">58</span>
<span class="line-number">59</span>
<span class="line-number">60</span>
</pre></td><td class="code"><pre><code class="py"><span class="line"><span></span><span class="k">class</span> <span class="nc">PregrouperEntryList</span><span class="p">(</span><span class="n">RuleBasedStateMachine</span><span class="p">):</span>
</span><span class="line">    <span class="sd">&quot;&quot;&quot;Populate a pregrouper entry in LIST mode; it should have all row</span>
</span><span class="line"><span class="sd">    ids in insertion order.</span>
</span><span class="line"><span class="sd">    &quot;&quot;&quot;</span>
</span><span class="line">
</span><span class="line">    <span class="n">MODE</span> <span class="o">=</span> <span class="n">C</span><span class="o">.</span><span class="n">PREGROUP_MODE_LIST</span>
</span><span class="line">    <span class="n">U64S</span> <span class="o">=</span> <span class="n">st</span><span class="o">.</span><span class="n">one_of</span><span class="p">(</span>
</span><span class="line">        <span class="c1"># Either one of the sentinel values</span>
</span><span class="line">        <span class="n">st</span><span class="o">.</span><span class="n">sampled_from</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">2</span> <span class="o">**</span> <span class="mi">64</span> <span class="o">-</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span> <span class="o">**</span> <span class="mi">64</span><span class="p">))),</span>
</span><span class="line">        <span class="c1"># or any row id.</span>
</span><span class="line">        <span class="n">st</span><span class="o">.</span><span class="n">integers</span><span class="p">(</span><span class="n">min_value</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">max_value</span><span class="o">=</span><span class="mi">2</span> <span class="o">**</span> <span class="mi">64</span> <span class="o">-</span> <span class="mi">1</span><span class="p">),</span>
</span><span class="line">    <span class="p">)</span>
</span><span class="line">
</span><span class="line">    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span class="line">        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span class="line">        <span class="bp">self</span><span class="o">.</span><span class="n">rows</span> <span class="o">=</span> <span class="p">[]</span>
</span><span class="line">        <span class="bp">self</span><span class="o">.</span><span class="n">error</span> <span class="o">=</span> <span class="n">FFI</span><span class="o">.</span><span class="n">new</span><span class="p">(</span><span class="s2">&quot;crdb_error_t *&quot;</span><span class="p">)</span>
</span><span class="line">        <span class="bp">self</span><span class="o">.</span><span class="n">entry</span> <span class="o">=</span> <span class="bp">None</span>
</span><span class="line">
</span><span class="line">    <span class="k">def</span> <span class="nf">teardown</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span class="line">        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">entry</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
</span><span class="line">            <span class="n">C</span><span class="o">.</span><span class="n">pregrouper_entry_deinit</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">entry</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">MODE</span><span class="p">)</span>
</span><span class="line">            <span class="bp">self</span><span class="o">.</span><span class="n">entry</span> <span class="o">=</span> <span class="bp">None</span>
</span><span class="line">
</span><span class="line">    <span class="k">def</span> <span class="nf">perror</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">):</span>
</span><span class="line">        <span class="k">return</span> <span class="s2">&quot;</span><span class="si">%s</span><span class="s2">: </span><span class="si">%s</span><span class="s2"> </span><span class="si">%i</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">FFI</span><span class="o">.</span><span class="n">string</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">error</span><span class="o">.</span><span class="n">message</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">error</span><span class="o">.</span><span class="n">error</span><span class="p">)</span>
</span><span class="line">
</span><span class="line">    <span class="nd">@precondition</span><span class="p">(</span><span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">entry</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">)</span>
</span><span class="line">    <span class="nd">@rule</span><span class="p">(</span><span class="n">row</span><span class="o">=</span><span class="n">U64S</span><span class="p">)</span>
</span><span class="line">    <span class="k">def</span> <span class="nf">create_entry</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">row</span><span class="p">):</span>
</span><span class="line">        <span class="bp">self</span><span class="o">.</span><span class="n">entry</span> <span class="o">=</span> <span class="n">FFI</span><span class="o">.</span><span class="n">new</span><span class="p">(</span><span class="s2">&quot;struct crdb_pregrouper_entry *&quot;</span><span class="p">)</span>
</span><span class="line">        <span class="n">C</span><span class="o">.</span><span class="n">pregrouper_entry_init</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">entry</span><span class="p">,</span> <span class="p">[</span><span class="n">row</span><span class="p">])</span>
</span><span class="line">        <span class="bp">self</span><span class="o">.</span><span class="n">rows</span> <span class="o">=</span> <span class="p">[</span><span class="n">row</span><span class="p">]</span>
</span><span class="line">
</span><span class="line">    <span class="nd">@precondition</span><span class="p">(</span><span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">entry</span><span class="p">)</span>
</span><span class="line">    <span class="nd">@rule</span><span class="p">(</span><span class="n">row</span><span class="o">=</span><span class="n">U64S</span><span class="p">)</span>
</span><span class="line">    <span class="k">def</span> <span class="nf">add_row</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">row</span><span class="p">):</span>
</span><span class="line">        <span class="k">assert</span> <span class="n">C</span><span class="o">.</span><span class="n">pregrouper_entry_add_row</span><span class="p">(</span>
</span><span class="line">            <span class="bp">self</span><span class="o">.</span><span class="n">entry</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">MODE</span><span class="p">,</span> <span class="p">[</span><span class="n">row</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">error</span>
</span><span class="line">        <span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">perror</span><span class="p">(</span><span class="s2">&quot;add_row&quot;</span><span class="p">)</span>
</span><span class="line">        <span class="bp">self</span><span class="o">.</span><span class="n">rows</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">row</span><span class="p">)</span>
</span><span class="line">
</span><span class="line">    <span class="nd">@precondition</span><span class="p">(</span><span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">entry</span><span class="p">)</span>
</span><span class="line">    <span class="nd">@rule</span><span class="p">()</span>
</span><span class="line">    <span class="k">def</span> <span class="nf">finalize</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span class="line">        <span class="k">assert</span> <span class="n">C</span><span class="o">.</span><span class="n">pregrouper_entry_finalize</span><span class="p">(</span>
</span><span class="line">            <span class="bp">self</span><span class="o">.</span><span class="n">entry</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">MODE</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">error</span>
</span><span class="line">        <span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">perror</span><span class="p">(</span><span class="s2">&quot;finalize&quot;</span><span class="p">)</span>
</span><span class="line">
</span><span class="line">    <span class="nd">@precondition</span><span class="p">(</span><span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">entry</span><span class="p">)</span>
</span><span class="line">    <span class="nd">@rule</span><span class="p">()</span>
</span><span class="line">    <span class="k">def</span> <span class="nf">check</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span class="line">        <span class="bp">self</span><span class="o">.</span><span class="n">finalize</span><span class="p">()</span>
</span><span class="line">        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">rows</span> <span class="o">==</span> <span class="p">[</span>
</span><span class="line">            <span class="bp">self</span><span class="o">.</span><span class="n">entry</span><span class="o">.</span><span class="n">payload</span><span class="o">.</span><span class="n">list</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
</span><span class="line">            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">entry</span><span class="o">.</span><span class="n">payload</span><span class="o">.</span><span class="n">list</span><span class="o">.</span><span class="n">n_entries</span><span class="p">)</span>
</span><span class="line">        <span class="p">]</span>
</span><span class="line">
</span><span class="line">
</span><span class="line"><span class="n">TestPregrouperEntryList</span> <span class="o">=</span> <span class="n">PregrouperEntryList</span><span class="o">.</span><span class="n">TestCase</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Most <a href="https://hypothesis.readthedocs.io/en/latest/stateful.html#hypothesis.stateful.rule"><code>@rule</code>-decorated</a> methods call a C function
before updating a Python-side model of the values we expect to find in the list.
The <a href="https://hypothesis.readthedocs.io/en/latest/stateful.html#hypothesis.stateful.rule"><code>@rule</code> decorator</a> mark methods that Hypothesis may call to generate examples;
the decorator’s arguments declare how each method should be invoked.
Some methods also have a <a href="https://hypothesis.readthedocs.io/en/latest/stateful.html#preconditions"><code>@precondition</code> decorator</a> to specify when they can be invoked
(a <code>@rule</code> without any <code>@precondition</code> is always safe to call).
There is one method (<code>create_entry</code>) to create a new list populated with an initial row id,
another (<code>add_row</code>) to add a row id to the list,
one to <code>finalize</code> the list, something which should always be safe to call and <em>must</em> be done before reading the list’s contents
(finalizing converts away from the inline representation),
and a <code>check</code> to compare the list of row ids in C to the one we maintained in Python.</p>

<p>Row ids are arbitrary 64-bit integers, so we could simply
ask Hypothesis to generate integers in \([0, 2^{64} - 1]\).
However, we also know that the implementation uses high row id values around
<code>UINT64_MAX</code> as sentinels in its implementation of inline storage, as shown below.</p>

<pre><code>struct inlined_list {
    union {
        uint64_t data[2];
        struct {
            uint64_t *arr;
            unsigned int capacity;
            unsigned int length;
        };
    };
    uint64_t control;
};

          Out of line list      Inline list of 2      Inline list of 3
          ----------------      ----------------      ----------------
data[0]:    arr                   elt #0                elt #0
data[1]:    capacity &amp; length     elt #1                elt #1
control:    UINT64_MAX            UINT64_MAX - 2        elt #2 &lt; UINT64_MAX - 2
</code></pre>

<p>That’s why we
bias the data generation towards row ids that could also be mistaken for sentinel values:
we generate each row id by either sampling from a set of sentinel-like values, 
or by sampling from all 64-bit integers.
This approach to defining the input data is decidedly non-magical,
compared to the way I work with fuzzers.
However, fuzzers also tend to be slow and somewhat fickle.
I think it makes sense to ask programmers to think about how their own code should be tested,
instead of hoping a computer program will eventually intuit what edge cases look like.<sup id="fnref:no-preconception"><a href="#fn:no-preconception" class="footnote">5</a></sup></p>

<p>It’s pretty cool that Hypothesis will now generate a bunch of API calls for me, but,
again, what makes Hypothesis really valuable is the way it
minimises long sequences of random calls into
understandable counter-examples.
Here’s what Hypothesis/pytest reports when I remove a guard that saves us from writing a row id
to a control word when that id would look like a sentinel value.</p>

<pre><code>self = PregrouperEntryList({})

    @precondition(lambda self: self.entry)
    @rule()
    def check(self):
        self.finalize()
&gt;       assert self.rows == [
            self.entry.payload.list.values[i]
            for i in range(self.entry.payload.list.n_entries)
        ]
E       AssertionError: assert [184467440737...4073709551613] == [184467440737...4073709551613]
E         Left contains one more item: 18446744073709551613
E         Full diff:
E         - [18446744073709551613, 18446744073709551613, 18446744073709551613]
E         ?                        ----------------------
E         + [18446744073709551613, 18446744073709551613]

test_pregroup_merge.py:81: AssertionError
------------------------------------------ Hypothesis ------------------------------------------
Falsifying example:
state = PregrouperEntryList()
state.create_entry(row=18446744073709551613)
state.add_row(row=18446744073709551613)
state.add_row(row=18446744073709551613)
state.check()
state.teardown()
</code></pre>

<p>We can see that we populated a list
thrice with the same row id, <code>18446744073709551613</code>,
but only found it twice in the final C-side list.
That row id is \(2^{64} - 3,\) the value we use to denote inline lists of two values.
This drawing shows how the last write ended up going to a control word where it was treated as a sentinel, making the inline representation look
like a list of two values, instead of three values.</p>

<pre><code>           Bad list of 3                Identical list of 2
          ----------------             ---------------------
data[0]:    UINT64_MAX - 2              UINT64_MAX - 2
data[1]:    UINT64_MAX - 2              UINT64_MAX - 2
control:    UINT64_MAX - 2 (payload)    UINT64_MAX - 2 (sentinel)

</code></pre>

<p>I restored the logic to prematurely stop using the inline representation
and convert to a heap-allocated vector whenever the row value would be interpreted as a sentinel,
and now Hypothesis doesn’t find anything wrong.
We also know that this specific failure is fixed,
because Hypothesis retries examples from its <a href="https://hypothesis.readthedocs.io/en/latest/database.html">failure database</a><sup id="fnref:failure-in-ci"><a href="#fn:failure-in-ci" class="footnote">6</a></sup> on every rerun.</p>

<h3 id="but-hypothesis-is-a-python-library">But Hypothesis is a Python library?!</h3>
<p>There are multiple language-specific libraries under the <a href="https://github.com/HypothesisWorks/hypothesis">Hypothesis project</a>;
none of them is in C, and only the Python implementation is actively maintained.
One might think that makes Hypothesis inappropriate for testing C.
However, the big ideas in Hypothesis are language-independent.
There is a practical reason for the multiple implementations:
for a tool to be really usable, it has to integrate well with the programming language’s surrounding ecosystem.
In most languages, we also expect to write test code in the same language as the system under test.</p>

<p>C (and C++, I would argue) is an exception.
When I tell an experienced C developer they should write test code in Python,
I expect a sigh of relief.
The fact that Hypothesis is written in Python,
as opposed to another managed language like Ruby or C# also helps:
embedding and calling C libraries is Python’s bread and butter.
The weak state of C tooling is another factor:
no one has a strong opinion regarding how to invoke C test code,
or how the results should be reported.
I’ll work with anything standard enough (e.g., pytest’s JUnit dump) to be ingested by Jenkins.</p>

<p>The last thing that sealed the deal for me is <a href="https://cffi.readthedocs.io/en/latest/">Python’s CFFI</a>.
With that library, I simply had to make sure my public header files were clean enough to be parsed without a full-blown compiler;
I could then write some simple Python code to <a href="https://gist.github.com/pkhuong/fe81822fd6adab723f91601f39dce4fb#file-crdb-py-L58">strip away preprocessor directive</a>,
<a href="https://gist.github.com/pkhuong/fe81822fd6adab723f91601f39dce4fb#file-crdb-py-L70">read headers in dependency order</a>,
and <a href="https://gist.github.com/pkhuong/fe81822fd6adab723f91601f39dce4fb#file-crdb-py-L77">load the production shared object</a>,
without any test-specific build step.
The snippets of test code above don’t look that different from tests for a regular Python module,
but there’s also a clear mapping from each Python call to a C call.
The level of magic is just right.</p>

<p>There is one testing concern that’s almost specific to C and C++ programs:
we must be on the lookout for memory management bugs.
For that, we use our <a href="https://github.com/google/sanitizers/wiki/AddressSanitizer">ASan</a>
build and bubble up <em>some</em> issues (e.g., read overflows or leaks) back to Python;
everything else results in an <code>abort()</code>, which, while suboptimal for minimisation, is still useful.
I simplified our test harness for the Heartbleed experiment;
see below for <a href="https://gist.github.com/pkhuong/fe81822fd6adab723f91601f39dce4fb">gists that anyone can use as starting points</a>.</p>

<h2 id="why-not-fuzzing">Why not fuzzing?</h2>

<p>I abused fuzzers a lot at Google,
mostly because the tooling was there
and it was trivial to burn hundreds of CPU-hours.
Technical workarounds seemed much easier than trying to add support for actual property-based testers,
so I would add domain specific assertions in order to detect more than crash conditions,
and translate bytes into more structured inputs or even convert them to series of method calls.
Now that I don’t have access to prebuilt infrastructure for fuzzers,
that approach doesn’t make as much sense.
That’s particularly true when byte arrays don’t naturally fit the entry point:
I spent a lot of time making sure the fuzzer was exercising branches in the system under test, not the test harness,
and designing input formats such that common fuzzer mutations, e.g., removing a byte, had a local effect and not, e.g., cause a frameshift mutation for the rest of the input…
and that’s before considering the time I wasted manually converting bytes to their structured interpretation on failures.</p>

<p>Hypothesis natively supports structured inputs and function calls,
and reports buggy inputs in terms of these high level concepts.
It is admittedly slower than fuzzers,
especially when compared to fuzzers that (like Hypothesis) don’t fork/exec for each evaluation.
I’m comfortable with that: my experience with NP-Hard problems tells me it’s better
to start by trying to do smart things with the structure of the problem, and later speed that up,
rather than putting all our hopes in making bad decisions really really fast.
Brute force can only do so much to an exponential-time cliff.</p>

<p>I had one niggling concern when leaving the magical world of fuzzers for staid property-based testing.
In some cases, I had seen coverage information steer fuzzers towards really subtle bugs;
could I benefit from the same smartness in Hypothesis?
That’s how I came up with the idea of simulating a reasonable testing process that ought to find <a href="https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2014-0160">CVE-2014-0160</a>,
<a href="https://heartbleed.com/">Heartbleed</a>.</p>

<h2 id="role-playing-cve-2014-0160">Role-playing CVE-2014-0160</h2>

<p><a href="https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2014-0160">CVE-2014-0160</a> a.k.a. <a href="https://heartbleed.com/">Heartbleed</a>
is a read heap overflow in OpenSSL 1.0.1 (\(\leq\) 1.0.1f) that leaks potentially private data over the wire.
It’s a straightforward logic bug in the implementation of <a href="https://tools.ietf.org/html/rfc6520">RFC 6520, a small optional (D)TLS extension</a>
that lets clients or servers ask for a ping.
<a href="https://www.theregister.co.uk/2014/04/09/heartbleed_explained/">The Register</a> has a concise visualisation of a bad packet.  We must send correctly sized packets that happen to ask for more pingback data than was sent to OpenSSL.</p>

<p><a href="https://www.theregister.co.uk/2014/04/09/heartbleed_explained/">
<img class="center" src="/images/2020-03-11-how-hard-is-it-to-guide-test-case-generators-with-branch-coverage-feedback/the_register_heartbleed_diagram.png" />
</a></p>

<p>State of the art fuzzers like <a href="http://lcamtuf.coredump.cx/afl/">AFL</a> or <a href="https://github.com/google/honggfuzz">Honggfuzz</a> find that bug in seconds when given an entry point that passes bytes to the connection handler,
like data that had just come over the wire.
When provided with a corpus of valid messages, they’re even faster.</p>

<p>It’s a really impressive showing of brute force that these programs to come up with almost valid packets so quickly,
and traditional property-based testing frameworks are really not up to that level of magic.
However, I don’t find the black box setting that interesting.
It’s probably different for security testing,
since not leaking invalid data is apparently seen as a feature one can slap on after the fact:
there are so many things to test that it’s probably best to focus on what fuzzing can easily find, and, in any case,
it doesn’t seem practical to manually boil that ocean one functionality at a time.</p>

<p>From a software testing point of view however, 
I would expect the people who send in a patch to implement something like the Heartbeat extension
to also have a decent idea how to send bytes that exercise their new code.
Of course, a sufficiently diligent coder would have found the heap overflow during testing,
or simply not have introduced that bug.
That’s not a useful scenario to explore; 
I’m interested in something that does find Heartbleed, and also looks like a repeatable process.
The question becomes “Within this repeatable process, can branch coverage feedback help Hypothesis find Heartbeat?”</p>

<p>Here’s what I settled on: let’s only assume the new feature code also comes
with a packet generator to exercise that code.  In Hypothesis, it might look like the following.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span>test_with_grammar.py </span></figcaption>
<div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
<span class="line-number">18</span>
<span class="line-number">19</span>
<span class="line-number">20</span>
<span class="line-number">21</span>
</pre></td><td class="code"><pre><code class="py"><span class="line"><span></span><span class="k">class</span> <span class="nc">GrammarTester</span><span class="p">(</span><span class="n">sanitizers</span><span class="o">.</span><span class="n">RuleBasedStateMachine</span><span class="p">):</span>
</span><span class="line">    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span><span class="line">        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</span><span class="line">        <span class="c1"># Avoid reporting initialisers as leaks.</span>
</span><span class="line">        <span class="k">with</span> <span class="n">sanitizers</span><span class="o">.</span><span class="n">leaky_region</span><span class="p">():</span>
</span><span class="line">            <span class="k">assert</span> <span class="n">C</span><span class="o">.</span><span class="n">LLVMFuzzerTestOneInput</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span>
</span><span class="line">        <span class="bp">self</span><span class="o">.</span><span class="n">buf</span> <span class="o">=</span> <span class="sa">b</span><span class="s2">&quot;&quot;</span>
</span><span class="line">
</span><span class="line">    <span class="k">def</span> <span class="nf">teardown</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span class="line">        <span class="k">assert</span> <span class="n">C</span><span class="o">.</span><span class="n">LLVMFuzzerTestOneInput</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">buf</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">buf</span><span class="p">))</span> <span class="o">==</span> <span class="mi">0</span>
</span><span class="line">
</span><span class="line">    <span class="nd">@initialize</span><span class="p">(</span>
</span><span class="line">        <span class="n">tls_ver</span><span class="o">=</span><span class="n">st</span><span class="o">.</span><span class="n">sampled_from</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]),</span>
</span><span class="line">        <span class="n">payload</span><span class="o">=</span><span class="n">st</span><span class="o">.</span><span class="n">binary</span><span class="p">(),</span>
</span><span class="line">        <span class="n">padding</span><span class="o">=</span><span class="n">st</span><span class="o">.</span><span class="n">binary</span><span class="p">(</span><span class="n">min_size</span><span class="o">=</span><span class="mi">16</span><span class="p">),</span>
</span><span class="line">    <span class="p">)</span>
</span><span class="line">    <span class="k">def</span> <span class="nf">add_heartbeat</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tls_ver</span><span class="p">,</span> <span class="n">payload</span><span class="p">,</span> <span class="n">padding</span><span class="p">):</span>
</span><span class="line">        <span class="n">hb_payload</span> <span class="o">=</span> <span class="nb">bytes</span><span class="p">([</span><span class="mh">0x01</span><span class="p">])</span> <span class="o">+</span> <span class="n">struct</span><span class="o">.</span><span class="n">pack</span><span class="p">(</span><span class="s2">&quot;&gt;H&quot;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">payload</span><span class="p">))</span> <span class="o">+</span> <span class="n">payload</span> <span class="o">+</span> <span class="n">padding</span>
</span><span class="line">        <span class="bp">self</span><span class="o">.</span><span class="n">buf</span> <span class="o">+=</span> <span class="nb">bytes</span><span class="p">([</span><span class="mh">0x18</span><span class="p">,</span> <span class="mh">0x03</span><span class="p">,</span> <span class="n">tls_ver</span><span class="p">])</span>
</span><span class="line">        <span class="bp">self</span><span class="o">.</span><span class="n">buf</span> <span class="o">+=</span> <span class="n">struct</span><span class="o">.</span><span class="n">pack</span><span class="p">(</span><span class="s2">&quot;&gt;H&quot;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">hb_payload</span><span class="p">))</span>
</span><span class="line">        <span class="bp">self</span><span class="o">.</span><span class="n">buf</span> <span class="o">+=</span> <span class="n">hb_payload</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>We have a single rule to initialize the test buffer with a valid heartbeat packet, 
and we send the whole buffer to a standard fuzzer entry point at the end.
In practice, I would also ask for some actual assertions that the system under test handles the packets correctly,
but that’s not important when it comes to Heartbleed:
we just need to run with ASan and look for heap overflows, which are essentially never OK.</p>

<p>Being able to provide a happy-path-only “test” like the above should be less than table stakes in a healthy project.
Let’s simulate a bug-finding process that 
looks for crashes after adding three generic buffer mutating primitives:
one that replaces a single byte in the message buffer,
another one that removes some bytes from the end of the buffer,
and a last one that appends some bytes to the buffer.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span>test_with_grammar.py </span></figcaption>
<div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
<span class="line-number">18</span>
<span class="line-number">19</span>
<span class="line-number">20</span>
</pre></td><td class="code"><pre><code class="py"><span class="line"><span></span><span class="k">class</span> <span class="nc">GrammarTester</span><span class="p">(</span><span class="n">sanitizers</span><span class="o">.</span><span class="n">RuleBasedStateMachine</span><span class="p">):</span>
</span><span class="line">    <span class="o">...</span>
</span><span class="line">
</span><span class="line">    <span class="nd">@precondition</span><span class="p">(</span><span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">buf</span><span class="p">)</span>
</span><span class="line">    <span class="nd">@rule</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">st</span><span class="o">.</span><span class="n">data</span><span class="p">(),</span> <span class="n">value</span><span class="o">=</span><span class="n">st</span><span class="o">.</span><span class="n">integers</span><span class="p">(</span><span class="n">min_value</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">max_value</span><span class="o">=</span><span class="mi">255</span><span class="p">))</span>
</span><span class="line">    <span class="k">def</span> <span class="nf">replace_byte</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
</span><span class="line">        <span class="n">index</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">draw</span><span class="p">(</span><span class="n">st</span><span class="o">.</span><span class="n">integers</span><span class="p">(</span><span class="n">min_value</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">max_value</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">buf</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span>
</span><span class="line">        <span class="n">prefix</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">buf</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="n">index</span><span class="p">]</span>
</span><span class="line">        <span class="n">suffix</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">buf</span><span class="p">[</span><span class="n">index</span> <span class="o">+</span> <span class="mi">1</span> <span class="p">:]</span>
</span><span class="line">        <span class="bp">self</span><span class="o">.</span><span class="n">buf</span> <span class="o">=</span> <span class="n">prefix</span> <span class="o">+</span> <span class="nb">bytes</span><span class="p">([</span><span class="n">value</span><span class="p">])</span> <span class="o">+</span> <span class="n">suffix</span>
</span><span class="line">
</span><span class="line">    <span class="nd">@precondition</span><span class="p">(</span><span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">buf</span><span class="p">)</span>
</span><span class="line">    <span class="nd">@rule</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">st</span><span class="o">.</span><span class="n">data</span><span class="p">())</span>
</span><span class="line">    <span class="k">def</span> <span class="nf">strip_suffix</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
</span><span class="line">        <span class="n">count</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">draw</span><span class="p">(</span><span class="n">st</span><span class="o">.</span><span class="n">integers</span><span class="p">(</span><span class="n">min_value</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_value</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">buf</span><span class="p">)))</span>
</span><span class="line">        <span class="bp">self</span><span class="o">.</span><span class="n">buf</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">buf</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="o">-</span><span class="n">count</span><span class="p">]</span>
</span><span class="line">
</span><span class="line">    <span class="nd">@rule</span><span class="p">(</span><span class="n">suffix</span><span class="o">=</span><span class="n">st</span><span class="o">.</span><span class="n">binary</span><span class="p">(</span><span class="n">min_size</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
</span><span class="line">    <span class="k">def</span> <span class="nf">add_suffix</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">suffix</span><span class="p">):</span>
</span><span class="line">        <span class="bp">self</span><span class="o">.</span><span class="n">buf</span> <span class="o">+=</span> <span class="n">suffix</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Given the initial generator rules and these three mutators,
Hypothesis will assemble sequences of calls to create and mutate buffers before sending them to OpenSSL at the end of the “test.”</p>

<p>The first time I ran this, Hypothesis found the bug in a second or two</p>

<pre><code>==12810==ERROR: AddressSanitizer: heap-buffer-overflow on address 0x62900012b748 at pc 0x7fb70d372f4e bp 0x7ffe55e56a30 sp 0x7ffe55e561e0
READ of size 30728 at 0x62900012b748 thread T0

0x62900012b748 is located 0 bytes to the right of 17736-byte region [0x629000127200,0x62900012b748)
allocated by thread T0 here:
    #0 0x7fb70d3e3628 in malloc (/usr/lib/x86_64-linux-gnu/libasan.so.5+0x107628)
    #1 0x7fb7058ee939  (fuzzer-test-suite/openssl-1.0.1f-fsanitize.so+0x19a939)
    #2 0x7fb7058caa08  (fuzzer-test-suite/openssl-1.0.1f-fsanitize.so+0x176a08)
    #3 0x7fb7058caf41  (fuzzer-test-suite/openssl-1.0.1f-fsanitize.so+0x176f41)
    #4 0x7fb7058a658d  (fuzzer-test-suite/openssl-1.0.1f-fsanitize.so+0x15258d)
    #5 0x7fb705865a12  (fuzzer-test-suite/openssl-1.0.1f-fsanitize.so+0x111a12)
    #6 0x7fb708326deb in ffi_call_unix64 (/home/pkhuong/follicle/follicle/lib/Python3.7/site-packages/.libs_cffi_backend/libffi-806b1a9d.so.6.0.4+0x6deb)
    #7 0x7fb7081b4f0f  (&lt;unknown module&gt;)
</code></pre>

<p>and then spent the 30 seconds trying to minimise the failure.
Unfortunately, it seems that ASan tries to be smart and avoids reporting duplicate errors, so minimisation does not work for memory errors.
It also doesn’t matter that much if we find a minimal test case: a core dump and a reproducer is usually good enough.</p>

<p>You can find the complete code for <a href="https://gist.github.com/pkhuong/fe81822fd6adab723f91601f39dce4fb#file-test_with_grammar-py">GrammarTester</a>,
along with the <a href="https://gist.github.com/pkhuong/fe81822fd6adab723f91601f39dce4fb#file-sanitizers-py">ASan wrapper</a>,
and <a href="https://gist.github.com/pkhuong/fe81822fd6adab723f91601f39dce4fb#file-llvm_one_input-py">CFFI glue</a> in <a href="https://gist.github.com/pkhuong/fe81822fd6adab723f91601f39dce4fb">this gist</a>.</p>

<p>For the rest of this post, we’ll make ASan crash on the first error, and count the number of test cases generated (i.e., the number of calls into the OpenSSL fuzzing entry point)
until ASan made OpenSSL crash.</p>

<h2 id="how-can-we-do-better-with-hardware-tracing">How can we do better with hardware tracing?</h2>

<p>Intel chips have offered <a href="https://github.com/torvalds/linux/blob/master/tools/perf/Documentation/intel-bts.txt">BTS, a branch trace store</a>, since Nehalem (2008-9), if not earlier.
BTS is slower than <a href="https://software.intel.com/en-us/blogs/2013/09/18/processor-tracing">PT, its full blown hardware tracing successor</a>,
and only traces branches, but it does so in a dead simple format.
I wrapped Linux perf’s interface for BTS in a <a href="https://gist.github.com/pkhuong/1ce34e33c6df4b9be3bc9beb22415a47">small library</a>;
let’s see if we can somehow feed that trace to Hypothesis and consistently find Heartbeat faster.</p>

<p>But first, how do fuzzers use coverage information?</p>

<p>A lot of the impressive stuff that fuzzers find stems from their ability to infer the constants that were compared with the fuzzing input by the system under test.
That’s not really that important when we assume a more white box testing setting,
where the same person or group responsible for writing the code is also tasked with testing it, or at least specifying how to do so.</p>

<p>Apart from guessing what valid inputs look like,
fuzzers also use branch coverage information to diversify their inputs.
In the initial search phase, none of the inputs cause a crash, and fuzzers can only mutate existing, equally non-crashy, inputs or create new ones from scratch.
The goal is to maintain a small population that can trigger all the behaviours (branches) we’ve observed so far,
and search locally around each member of that population.
Pruning to keep the population small is beneficial for two reasons: first, it’s faster to iterate over a smaller population, and second,
it avoids redundantly exploring the neighbourhood of nearly identical inputs.</p>

<p>Of course, this isn’t ideal.
We’d prefer to keep one input per program state,
but we don’t know what the distinct program states are.
Instead, we only know what branches we took on the way to wherever we ended up.
It’s as if we were trying to generate directions to every landmark in a city,
but the only feedback we received was the set of streets we walked on while following the directions.
That’s far from perfect, but, with enough brute force, it might just be good enough.</p>

<p>We can emulate this diversification and local exploration logic with multi-dimensional <a href="http://proper.softlab.ntua.gr/Publications.html">Targeted example generation</a>,
for which <a href="https://hypothesis.readthedocs.io/en/latest/details.html#targeted-example-generation">Hypothesis has experimental support</a>.</p>

<p>We’ll assign an arbitrary unique label to each origin/destination pair we observe via BTS,
and assign a score of 1.0 to every such label (regardless of how many times we observed each pair).
Whenever Hypothesis compares two score vectors, a missing value is treated as \(-\infty\), so, everything else being equal, covering a branch is better than not covering it.
After that, we’ll rely on the fact that multidimensional discrete optimisation is
also all about maintaining a small but diverse population:
Hypothesis regularly prunes redundant examples (examples that exercises a subset of
the branches triggered by another example),
and generates new examples by mutating members of the population.
With our scoring scheme, the multidimensional search will split its efforts between families of examples that trigger different sets of branches,
and will also stop looking around examples that trigger a strict subset of another example’s branches.</p>

<p>Here’s the plan to give BTS feedback to Hypothesis and diversify its initial search for failing examples.
I’ll use my <a href="https://gist.github.com/pkhuong/1ce34e33c6df4b9be3bc9beb22415a47">libbts</a> to wrap perf syscalls into something usable,
and wrap that in Python to more easily <a href="https://gist.github.com/pkhuong/fe81822fd6adab723f91601f39dce4fb#file-bts-py">gather origin/destination pairs</a>.
Even though I enable BTS tracing only around FFI calls,
there will be some noise from libffi, as well as dummy transitions for interrupts or context switches; <code>bts.py</code> attempts to only consider interesting branches
by <a href="https://gist.github.com/pkhuong/fe81822fd6adab723f91601f39dce4fb#file-bts-py-L105">remembering the set of executable mappings present at startup</a>,
before loading the library under test,
and dropping jumps to or from addresses that were mapped at startup
(presumably, that’s from the test harness), or invalid zero or negative addresses
(which I’m pretty sure denote interrupts and syscalls).</p>

<p>We’ll then wrap the Python functions that call into OpenSSL to record the set of branches executed during that call,
and convert that set to a multidimensional score at the end of the test, in the <code>teardown</code> method.</p>

<p>The only difference is in the <code>__init__</code> method, which must also reset BTS state,
and in the <code>teardown</code> method, where we score the example if it failed to crash.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span>test_with_grammar_bts.py </span></figcaption>
<div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
<span class="line-number">18</span>
</pre></td><td class="code"><pre><code class="py"><span class="line"><span></span><span class="k">class</span> <span class="nc">GrammarBtsTester</span><span class="p">(</span><span class="n">sanitizers</span><span class="o">.</span><span class="n">RuleBasedStateMachine</span><span class="p">):</span>
</span><span class="line">    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span><span class="line">        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</span><span class="line">        <span class="n">bts</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
</span><span class="line">        <span class="k">with</span> <span class="n">sanitizers</span><span class="o">.</span><span class="n">leaky_region</span><span class="p">():</span>
</span><span class="line">            <span class="k">assert</span> <span class="n">C</span><span class="o">.</span><span class="n">LLVMFuzzerTestOneInput</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span>
</span><span class="line">        <span class="n">bts</span><span class="o">.</span><span class="n">update_useless_edges</span><span class="p">()</span>
</span><span class="line">        <span class="n">bts</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
</span><span class="line">        <span class="bp">self</span><span class="o">.</span><span class="n">buf</span> <span class="o">=</span> <span class="sa">b</span><span class="s2">&quot;&quot;</span>
</span><span class="line">
</span><span class="line">    <span class="k">def</span> <span class="nf">teardown</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span class="line">        <span class="k">assert</span> <span class="n">C</span><span class="o">.</span><span class="n">LLVMFuzzerTestOneInput</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">buf</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">buf</span><span class="p">))</span> <span class="o">==</span> <span class="mi">0</span>
</span><span class="line">        <span class="c1"># bts.report() returns a set of control flow edge ids.</span>
</span><span class="line">        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">bts</span><span class="o">.</span><span class="n">report</span><span class="p">():</span>
</span><span class="line">            <span class="n">target</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">))</span>
</span><span class="line">        <span class="n">bts</span><span class="o">.</span><span class="n">teardown</span><span class="p">()</span>
</span><span class="line">
</span><span class="line">    <span class="o">...</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Let’s instrument the <code>teardown</code> methods to print “CHECK” and flush before every call to the fuzzing entry point,
and make sure <a href="https://gist.github.com/pkhuong/fe81822fd6adab723f91601f39dce4fb#file-run-tests-sh">ASan crashes when it finds an issue</a>.
We’ll run the test files, grep for “CHECK”, and, assuming we don’t trigger into any runtime limit,
find out how many examples Hypothesis had to generate before causing a crash.</p>

<p>I ran this 12000 times for both <code>test_with_grammar.py</code> and <code>test_with_grammar_bts.py</code>.
Let’s take a look at the empirical distribution functions for the number of calls until a crash, for <code>test_with_grammar.py</code> (<code>grammar</code>)
and <code>test_with_grammar_bts.py</code> (<code>bts</code>).</p>

<!-- ggplot(data, aes(x=Calls, colour=Impl)) + stat_ecdf() + scale_color_discrete(name="Implementation") + scale_x_log10() + ylab("Cumulative fraction") + xlab("Calls to OpenSSL until crash") -->
<p><img class="center" src="/images/2020-03-11-how-hard-is-it-to-guide-test-case-generators-with-branch-coverage-feedback/ecdf.png" /></p>

<p>There’s a cross-over around 100 calls:
as long as we have enough time for least 100 calls to OpenSSL,
we’re more likely to find Heartbleed with coverage feedback than by rapidly searching blindly.
With fewer than 100 calls, it seems likely that branch coverage only guides the search
towards clearly invalid inputs that trigger early exit conditions.
Crucially, the curves are smooth and tap out before our limit of 10000 examples per execution,
so we’re probably not measuring a side-effect of the experimental setup.</p>

<p>In theory, the distribution function for the uninstrumented <code>grammar</code> search should look a lot like a geometric distribution,
but I don’t want to assume too much of the <code>bts</code> implementation.  Let’s confirm our gut feeling in <code>R</code> with a simple non-parametric test,
the <a href="https://en.wikipedia.org/wiki/Mann%E2%80%93Whitney_U_test">Wilcoxon rank sum test</a>, an unpaired analogue to the sign test:</p>

<pre><code>&gt; wilcox.test(data$Calls[data$Impl == 'bts'], data$Calls[data$Impl == 'grammar'], 'less')

        Wilcoxon rank sum test with continuity correction

data:  data$Calls[data$Impl == "bts"] and data$Calls[data$Impl == "grammar"]
W = 68514000, p-value = 4.156e-11
alternative hypothesis: true location shift is less than 0
</code></pre>

<p>We’re reasonably certain that the number of calls for a random run of <code>bts</code> is more
frequently less than the number of calls for an independently chosen random run of <code>grammar</code>
than the opposite.  Since the tracing overhead is negligible,
this means branch feedback saves us time more often than not.
For the 24 000 separate runs we observed,
<code>bts</code> is only faster 52% of the time, 
but that’s mostly because both distributions of calls to the system under test go pretty high.
On average, vanilla Hypothesis, without coverage feedback, found the vulnerability after 535 calls to OpenSSL;
with feedback, Hypothesis is 11.5% faster on average, and only needs 473 calls.</p>

<h2 id="time-to-use-this-in-anger">Time to use this in anger</h2>

<p>We have been using this testing approach (without branch coverage) at Backtrace for a couple months now,
and it’s working well as a developer tool that offers rapid feedback, enough that we’re considering running these tests in a commit hook.
Most of the work involved in making the approach useful was just plumbing, e.g., dealing with the way ASan reports errors,
or making sure we don’t report leaks that happen in Python, outside the system under test.
Once the commit hook is proven solid, we’ll probably want to look into running tests in the background for a long time.
That’s a very different setting from pre-commit or commit -time runs, where every bug is sacred.
If I let something run over the weekend, I must be able to rely on deduplication (i.e., minimisation is even more useful),
and I will probably want to silence or otherwise triage some issues.
That’s the sort of thing Backtrace already handles, so we are looking into sending Hypothesis reports directly to Backtrace,
the same way we do for clang-analyzer reports and for crashes or leaks found by ASan in our end-to-end tests.</p>

<p>The challenges are more research-y for coverage feedback. There’s no doubt a lot of mundane plumbing issues involved in making this feedback robust
(see, e.g., the <a href="https://gist.github.com/pkhuong/fe81822fd6adab723f91601f39dce4fb#file-bts-py-L172">logic in bts.py</a> to filter out interrupts and branches from the kernel, or branches from code that’s probably not in the system under test).
However, there’s also a fundamental question that we unfortunately can’t answer by copying fuzzers.</p>

<p>How should we score coverage over multiple calls?
After all, the ability to test a stateful interface via a sequence of method calls and expections is what really sold me on Hypothesis.
Fuzzers have it easy: they assume each call is atomic and independent of any other call to the system under test, even when they don’t fork for each execution.
This seems like a key reason why simple coverage metrics work well in fuzzers,
and I don’t know that we can trivially port ideas from fuzzing to stateful testing.</p>

<p>For example, my first stab at this experiment found no statistically significant improvement from BTS feedback.  The only difference is that the assertion lived in a <code>check</code> rule,
and not in the <code>teardown</code> method, which let Hypothesis trigger a call to OpenSSL at various points in the buffer mutation sequence… usually a good thing for test coverage.
I’m pretty sure the problem is that a single example could collect “points” for covering branches in multiple unrelated calls to OpenSSL,
while we would rather cover many branches in a single call.
What does it mean for stateful testing, where we want to invoke different functions multiple times in a test?</p>

<p>I have no idea; maybe we should come up with some synthetic stateful testing benchmarks that are expected to benefit from coverage information. However, the experiment in this post gives me hope that there exists some way to exploit coverage information in stateful testing.
<a href="https://gist.github.com/pkhuong/fe81822fd6adab723f91601f39dce4fb">The MIT-licensed support code in this gist</a>
(along <a href="https://gist.github.com/pkhuong/1ce34e33c6df4b9be3bc9beb22415a47">with libbts</a>)
should give you all a headstart to try more stuff and report your experiences.</p>

<p><small>Thank you David, Ruchir, Samy, and Travis for your comments on an early draft.</small></p>

<p><hr style="width: 50%" /></p>

<h2 id="appendix-how-to-get-started-with-your-own-project">Appendix: How to get started with your own project</h2>

<p>In a performance-oriented C library,
the main obstable to testing with Hypothesis and CFFI will probably be
that the headers are too complex for <a href="https://github.com/eliben/pycparser"><code>pycparser</code></a>.  I had to use a few tricks
to make ours parse.</p>

<p>First, I retro-actively imposed more discipline on what was really public and what
implementation details should live in private headers:
we want <a href="https://cffi.readthedocs.io/en/latest/">CFFI</a> to handle every public header, and only some private headers for more targeted testing.
This separation is a good thing to maintain in general, and, if anything,
having <a href="https://github.com/eliben/pycparser">pycparser</a> yell at us when we make our public interface depend on internals is a net benefit.</p>

<p>I then had to reduce our reliance on the C preprocessor.  In some cases,
that meant making types opaque and adding getters.
In many more cases, I simply converted small <code>#define</code>d integer constants to
anonymous enums <code>enum { CONSTANT_FOO = ... }</code>.</p>

<p>Finally, especially when testing internal functionality, I had to remove
<code>static inline</code> functions.
That’s another case where pycparser forces us to maintain cleaner headers,
and the fix is usually simple:
declare <code>inline</code> (not static) functions in the header,
<code>#include</code> a <code>.inl</code> file with the <code>inline</code> definition (we can easily drop directives in Python),
and re-declare the function as <code>extern</code> in the main source file for that header.
With this approach, the header can focus on documenting the interface,
the compiler still has access to an inline definition,
and we don’t waste instruction bytes on duplicate out-of-line definitions.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span>u64_block.h </span></figcaption>
<div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
</pre></td><td class="code"><pre><code class="c"><span class="line"><span></span><span class="cm">/**</span>
</span><span class="line"><span class="cm"> * This file documents the external interface.</span>
</span><span class="line"><span class="cm"> */</span>
</span><span class="line"><span class="kr">inline</span> <span class="kt">uint8_t</span> <span class="nf">crdb_u64_block_lt</span><span class="p">(</span><span class="k">const</span> <span class="kt">uint64_t</span> <span class="o">*</span><span class="p">,</span> <span class="kt">uint64_t</span> <span class="n">k</span><span class="p">);</span>
</span><span class="line">
</span><span class="line"><span class="cp">#include</span> <span class="cpf">&quot;u64_block.inl&quot;  /* Stripped in Python. */</span><span class="cp"></span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span>u64_block.inl </span></figcaption>
<div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
</pre></td><td class="code"><pre><code class="c"><span class="line"><span></span><span class="cm">/**</span>
</span><span class="line"><span class="cm"> * Describe implementation details here.</span>
</span><span class="line"><span class="cm"> */</span>
</span><span class="line"><span class="kr">inline</span> <span class="kt">uint8_t</span>
</span><span class="line"><span class="nf">crdb_u64_block_lt</span><span class="p">(</span><span class="k">const</span> <span class="kt">uint64_t</span> <span class="o">*</span><span class="n">block</span><span class="p">,</span> <span class="kt">uint64_t</span> <span class="n">k</span><span class="p">)</span>
</span><span class="line"><span class="p">{</span>
</span><span class="line">    <span class="p">....</span>
</span><span class="line"><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span>u64_block.c </span></figcaption>
<div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
</pre></td><td class="code"><pre><code class="c"><span class="line"><span></span><span class="cp">#include</span> <span class="cpf">&quot;u64_block.h&quot;</span><span class="cp"></span>
</span><span class="line">
</span><span class="line"><span class="cm">/* Provide the unique out-of-line definition. */</span>
</span><span class="line"><span class="kt">uint8_t</span> <span class="nf">crdb_u64_block_lt</span><span class="p">(</span><span class="k">const</span> <span class="kt">uint64_t</span> <span class="o">*</span><span class="n">block</span><span class="p">,</span> <span class="kt">uint64_t</span> <span class="n">k</span><span class="p">);</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>That doesn’t always work, mostly because regular <code>inline</code> functions aren’t
supposed to call <code>static inline</code> functions.  When I ran into that issue,
I either tried to factor the more complex slow path out to an out-of-line definition,
or, more rarely, resorted to CPP tricks (also hidden in a <code>.inl</code> file) to rewrite calls to
<code>extern int foo(...)</code>
with macros like <code>#define foo(...) static_inline_foo(__VA_ARGS__)</code>.</p>

<p>All that work isn’t really testing overhead; they’re mostly things
that library maintainers <em>should</em> do, but are easy to forget when
when we only hear from C programmers.</p>

<p>Once the headers were close enough to being accepted by CFFI,
I closed the gap with string munging in Python.
All the tests depend on the <a href="https://gist.github.com/pkhuong/fe81822fd6adab723f91601f39dce4fb#file-crdb-py">same file that parses all the headers we care about in the correct order and loads the shared object</a>.
Loading everything in the same order also enforces a reasonable dependency
graph, another unintended benefit.
Once everything is loaded, that file also <a href="https://gist.github.com/pkhuong/fe81822fd6adab723f91601f39dce4fb#file-crdb-py-L83">post-processes the CFFI functions</a> to hook
in ASan (and branch tracing), and strip away any namespacing
prefix.</p>

<p>The end result is a library that’s more easily used from managed
languages like Python, and which we can now test it like any other
Python module.</p>

<p><hr style="width: 50%" /></p>
<div class="footnotes">
  <ol>
    <li id="fn:realtime">
      <p>The graph shows time in terms of calls to the SUT, not real time. However, the additional overhead of gathering and considering coverage information is small enough that the feedback also improves wallclock and CPU time. <a href="#fnref:realtime" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:matchers">
      <p>High level <a href="https://github.com/google/googletest">matchers like GMock’s</a> help, but they don’t always explain why a given matcher makes sense. <a href="#fnref:matchers" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:change-detector">
      <p>There’s also a place for <a href="https://github.com/approvals/ApprovalTests.cpp/blob/master/doc/Overview.md">smart change detectors, especially when refactoring ill understood code</a>. <a href="#fnref:change-detector" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:unless-examples">
      <p>I had to disable the exhaustive list of examples to benefit from minimisation. Maybe one day I’ll figure out how to make Hypothesis treat explicit examples more like an initial test corpus. <a href="#fnref:unless-examples" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:no-preconception">
      <p>That reminds me of an AI Lab Koan. «In the days when Sussman was a novice, Minsky once came to him as he sat hacking at the PDP-6. “What are you doing?” asked Minsky. “I am training a randomly wired neural net to play Tic-tac-toe,” Sussman replied. “Why is the net wired randomly?” asked Minsky. Sussman replied, “I do not want it to have any preconceptions of how to play.” Minsky then shut his eyes. “Why do you close your eyes?” Sussman asked his teacher. “So that the room will be empty,” replied Minsky. At that moment, Sussman was enlightened.» <a href="#fnref:no-preconception" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:failure-in-ci">
      <p>The database is a directory of files full of binary data.  The specific meaning of these bytes depends on the Hypothesis version and on the test code, so the database should probably not be checked in.  Important examples (e.g., for regression testing) should instead be made persistent with <code>@example</code> decorators.  Hypothesis does guarantee that tese files are always valid (i.e., any sequence of bytes in the database will result in an example that can be generated by the version of Hypothesis and of the test code that reads it), so we don’t have to invalidate the cache when we update the test harness. <a href="#fnref:failure-in-ci" class="reversefootnote">&#8617;</a></p>
    </li>
  </ol>
</div>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Too much locality... for stores to forward]]></title>
    <link href="https://www.pvk.ca/Blog/2020/02/01/too-much-locality-for-store-forwarding/"/>
    <updated>2020-02-01T17:29:21-05:00</updated>
    <id>https://www.pvk.ca/Blog/2020/02/01/too-much-locality-for-store-forwarding</id>
    <content type="html"><![CDATA[<p><small>Apologies for the failed <a href="https://www.youtube.com/watch?v=K3DRkVjuqmc">Cake reference</a>.<br />
2020-02-02: Refer to Travis Downs’s investigation into this pathological case for forwarding.</small></p>

<p>I’ve been responsible for <a href="https://backtrace.io/">Backtrace.io</a>’s crash analytic database<sup id="fnref:started-work"><a href="#fn:started-work" class="footnote">1</a></sup> for a couple months now.
I have focused my recent efforts on improving query times for in-memory grouped aggregations, i.e.,
the archetypal MapReduce use-case where we generate key-value pairs, and <a href="https://en.wikipedia.org/wiki/Fold_(higher-order_function)">fold</a> over the values
for each key in some <a href="https://en.wikipedia.org/wiki/Semigroup">(semi)</a><a href="https://en.wikipedia.org/wiki/Group_(mathematics)">group</a>.
We have a cute cache-efficient data structure for this type of workload;
the inner loop simply inserts in a small hash table with <a href="/Blog/more_numerical_experiments_in_hashing.html">Robin Hood linear probing</a>,
in order to guarantee entries in the table are ordered by hash value.  This
ordering lets us easily dump the entries in sorted order, and <a href="https://www2.eecs.berkeley.edu/Pubs/TechRpts/1993/6309.html">block</a> the merge loop for an arbitrary number of sorted arrays
into a unified, larger, ordered hash table (which we can, again, dump to a sorted array).<sup id="fnref:more-later"><a href="#fn:more-later" class="footnote">2</a></sup></p>

<h1 id="observation">Observation</h1>

<p>As I updated more operators to use this data structure, I noticed that we were spending a lot of time in its inner loop.
In fact, <a href="http://www.brendangregg.com/linuxperf.html">perf</a> showed that the query server as a whole was spending 4% of its CPU time on one instruction in that loop:</p>

<pre><code> 2.17 |       movdqu     (%rbx),%xmm0
39.63 |       lea        0x1(%r8),%r14  # that's 40% of the annotated function
      |       mov        0x20(%rbx),%rax
 0.15 |       movaps     %xmm0,0xa0(%rsp)
</code></pre>

<p>The first thing to note is that instruction-level profiling tends to put the blame on the instruction <em>following</em> the one that triggered a sampling interrupt.
It’s not the <code>lea</code> (which computes <code>r14 &lt;- r8 + 1</code>) that’s slow, but the <code>movdqu</code> just before.
So, what is that <code>movdqu</code> loading into <code>xmm0</code>?  Maybe it’s just a normal cache miss, something inherent to the workload.</p>

<p>I turned on source locations <a href="http://man7.org/linux/man-pages/man1/perf-report.1.html">(hit <code>s</code> in <code>perf report</code>)</a>, and observed that this instruction was simply copying to the stack an argument that was passed by address.
The source clearly showed that the argument should be hot in cache: the inner loop was essentially</p>

<pre><code>A1. Generate a new key-value pair
B1. Mangle that kv pair just a bit to turn it into a hash element
C1. Insert the new hash element
A2.
B2.
C2.
</code></pre>

<p>and the <code>movdqu</code> happens in step C, to copy the element that step B just constructed.<sup id="fnref:dont-copy"><a href="#fn:dont-copy" class="footnote">3</a></sup></p>

<p>At this point, an important question suggests itself: does it matter?
We could simply increase the size of the base case and speed up the rest of the bottom-up recursion… eventually, the latency for the random accesses in the initial hash table will dominate the inner loop.</p>

<p>When I look into the performance of these deep inner loop, my goal isn’t only to do the same thing better.
The big wins, in my experience, come from the additional design freedom that we get from being able to find new uses for the same code.
Improved latency, throughput, or memory footprint really shine when the increased optionality from multiple such improvements compounds and lets us consider a much larger design space for the project as a whole.
That’s why I wanted to make sure this hash table insertion loop worked on as wide a set of parameter as possible: because that will give future me the ability to combine versatile tools.</p>

<h1 id="hypothesis">Hypothesis</h1>

<p>Back to the original question. Why do we spend so many cycles loading data we just wrote to cache?</p>

<p>The answer is in the question and in the title of this post: too little time elapses between the instructions that write data to the cache and the ones that read the same data.<sup id="fnref:but-forwarding"><a href="#fn:but-forwarding" class="footnote">4</a></sup>
A modern out-of-order machine (e.g., most amd64 chips) can execute multiple instructions at the same time, and will start executing instructions as soon as their operands are ready, even when earlier instructions in program order are still waiting for theirs.
Machine code is essentially a messy way to encode a <a href="https://fgiesen.wordpress.com/2018/03/05/a-whirlwind-introduction-to-dataflow-graphs/">dataflow graph</a>, 
which means our job as micro-optimisers is, at a high level, to avoid long dependency chains and make the dataflow graph as wide as possible.
When that’s too hard, we should distribute as much scheduling slack as possible between nodes in a chain, in order to absorb the knock-on effects of cache misses and other latency spikes.
If we fail, the chip will often find itself with no instruction ready to execute; stalling the pipeline like that is like slowing down by a factor of 10.</p>

<p>The initial inner loop simply executes steps A, B, and C in order, where step C depends on the result of step B, and step B on that of step A.
In theory, a chip with a wide enough instruction reordering window could pipeline multiple loop iterations.
In practice, real hardware can only <a href="http://blog.stuffedcow.net/2013/05/measuring-rob-capacity/">plan on the order of 100-200 instructions ahead</a>, and that mechanism depends on branches being predicted correctly.
We have to explicitly insert slack in our dataflow schedule, and we must distribute it well enough for instruction reordering to see the gaps.</p>

<p>This specific instance is a particularly bad case for contemporary machines:
step B populates the entry with regular (64-bit) register writes,
while step C copies the same bytes with vector reads and writes.
<a href="https://gist.github.com/travisdowns/bc9af3a0aaca5399824cf182f85b9e9c">Travis Downs looked into this forwarding scenario</a> and found that no other read-after-write setup behaves this badly, on Intel or AMD.
That’s probably why the <code>movdqu</code> vector load instruction was such an issue.
If the compiler had emitted the copy with GPR reads and writes,
that <em>might</em> have been enough for the hardware to hide the latency.
However, as <a href="https://twitter.com/trav_downs/status/1223766684932222976">Travis points out on Twitter</a>, it’s hard for a compiler to get that right across compilation units.
In any case, our most reliable (more so than passing this large struct by value and hoping the compiler will avoid mismatched instructions) and powerful tool to fix this at the source level is to schedule operations manually.</p>

<p>The dataflow graph for each loop iteration is currently a pure chain:</p>

<pre><code>         A1
         |
         v
         B1
         |
         v
         C1
                A2
                |
                v
                B2
                |
                v
                C2
</code></pre>

<p>How does one add slack to these chains? With bounded queues!</p>

<h1 id="experiment">Experiment</h1>

<p>My first fix was to add a one-element buffer between steps B and C.  The inner loop became</p>

<pre><code>A1. Generate a new key-value pair
C0. Insert the hash element from the previous iteration
B1. Mangle the kv pair and stash that in the buffer
A2.
C1.
B2
etc.
</code></pre>

<p>which yields a dataflow graph like</p>

<pre><code>        |     A1
        v     |
        C0    |
              |
              v
              B1
              |
              |     A2
              v     |
              C1    |
                    |
                    v
                    B2
                    |
</code></pre>

<p>We’ve introduced slack between steps A and B (there’s now step C from the previous iteration between them), and between steps B and C (we shifted step A from the next iteration between them).
There isn’t such a long delay between the definition of a value and its use that the data is likely to be evicted from L1.
However, there is more than enough work available between them to keep the pipeline busy with useful work while C waits for B’s result, or B for A’s.
That was a nice single-digit improvement in query latency for my internal benchmark, just by permuting a loop.</p>

<p>If a one-element buffer helps, we should clearly experiment with the buffer size, and that’s where I found a more impactful speed-up.
Once we have an array of elements to insert in a hash table, we can focus on a bulk insert of maybe 8 or 10 elements: instead of trying to improve the latency for
individual writes, we can focus on the throughput for multiple inserts at once.
That’s good because <a href="http://www.stuartcheshire.org/rants/Latency.html">throughput is an easier problem than latency</a>.
In the current case, passing the whole buffer to the hash table code made it easier to <a href="https://www2.eecs.berkeley.edu/Pubs/TechRpts/1993/6309.html">pipeline the insert loop in software</a>:
we can compute hashes ahead of time, and accelerate random accesses to the hash table with <a href="https://software.intel.com/sites/landingpage/IntrinsicsGuide/#text=_mm_prefetch&amp;expand=4391">software prefetching</a>.
The profile for the new inner loop is flatter, and the hottest part is as follows</p>

<pre><code>      |       mov        0x8(%rsp),%rdx
 9.91 |       lea        (%r12,%r12,4),%rax
 0.64 |       prefetcht0 (%rdx,%rax,8)
17.04 |       cmp        %rcx,0x28(%rsp)
</code></pre>

<p>Again, the blame for a “slow” instruction hits the following instruction, so it’s not <code>lea</code> (multiplying by 5) or <code>cmp</code> that are slow; it’s the load from the stack and the prefetch.
The good news is that these instructions do not have any dependent.  It’s all prefetching, and that’s only used for its side effects.
Moreover, they come from a block of code that was pipelined in software and executes one full iteration ahead of where its side effects might be useful.
It doesn’t really matter if these instructions are slow: they’re still far from being on the critical path!  This last restructuring yielded a 20% speed-up on a few slow queries.</p>

<p>I described two tools that I use regularly when optimising code for contemporary hardware.
Finding ways to scatter around scheduling slack is always useful, both in software and in real life planning.<sup id="fnref:unless-people"><a href="#fn:unless-people" class="footnote">5</a></sup>
One simple way to do so is to add bounded buffers, and to flush buffers as soon as they fill up (or refill when they become empty), instead of waiting until the next write to the buffer.
However, I think the more powerful transformation is using buffering to expose bulk operations, which tends to open up more opportunities than just doing the same thing in a loop.
In the case above, we found a 20% speed-up; for someone who visit their <a href="https://help.backtrace.io/en/articles/2765535-triage">Backtrace dashboard</a> a couple times a day, that can add up to an hour or two at the end of the year.</p>

<p>TL;DR: When a function is hot enough to look into, it’s worth asking why it’s called so often, in order to focus on higher level bulk operations.</p>

<p><hr style="width: 50%" /></p>
<div class="footnotes">
  <ol>
    <li id="fn:started-work">
      <p>And by that, I mean I started working there a couple months ago (: <a href="#fnref:started-work" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:more-later">
      <p>I think that’s a meaty idea, and am planning a longer post on that data structure and where it fits in the hash/sort join continuum. <a href="#fnref:more-later" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:dont-copy">
      <p>Would I have avoided this issue if I had directly passed by value? The resulting code might have been friendlier to store-to-load forwarding than loading a whole 128 bit SSE register, but see the next footnote. <a href="#fnref:dont-copy" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:but-forwarding">
      <p>Store-to-load forwarding can help improve the performance of this pattern, when we use forwarding patterns that the hardware supports. However, this mechanism can only decrease the penalty of serial dependencies, e.g., by shaving away some or all of the time it takes to store a result to cache and load it back; even when results can feed directly into dependencies, we still have to wait for inputs to be computed. This is fundamentally a scheduling issue. <a href="#fnref:but-forwarding" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:unless-people">
      <p>Unless you’re writing schedule optimising software and people will look at the result. A final hill climbing pass to make things look artificially tight often makes for an easier sale in that situation. <a href="#fnref:unless-people" class="reversefootnote">&#8617;</a></p>
    </li>
  </ol>
</div>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Lazy Linear Knapsack]]></title>
    <link href="https://www.pvk.ca/Blog/2020/01/20/lazy-linear-knapsack/"/>
    <updated>2020-01-20T23:10:19-05:00</updated>
    <id>https://www.pvk.ca/Blog/2020/01/20/lazy-linear-knapsack</id>
    <content type="html"><![CDATA[<p>The <a href="https://en.wikipedia.org/wiki/Continuous_knapsack_problem">continuous knapsack problem</a> may be the simplest non-trivial linear
programming problem:</p>

<p>\[\max_{x \in [0, 1]^n} p’x\]
subject to
\[w’x \leq b.\]</p>

<p>It has a linear objective, one constraint, and each decision variable
is bounded to ensure the optimum exists.  Note the key difference from
the <a href="https://en.wikipedia.org/wiki/Knapsack_problem#0/1_knapsack_problem">binary knapsack problem</a>: decision variables are allowed to take any
value between 0 and 1.  In other words, we can, e.g., stick half of
a profitable but large item in the knapsack. That’s why this knapsack
problem can be solved in linear time.</p>

<h2 id="dual-to-primal-is-reasonable">Dual to primal is reasonable</h2>

<p>Duality also lets us determine the shape of all optimal solutions to
this problem.  For each item \(i\) with weight \(w_i\) and profit
\(p_i\), let its profit ratio be \(r_i = p_i / w_i,\)
and let \(\lambda^\star\) be the optimal dual (Lagrange or linear)
multiplier associated with the capacity constraint \(w’x \leq b.\)
If \(\lambda^\star = 0,\) we simply take all items with a positive
profit ratio (\(r_i &gt; 0\)) and a non-negative weight \(w_i \geq 0.\)
Otherwise, every item with a profit ratio \(r_i &gt; \lambda^\star\)
will be at its weight upper bound (1 if \(w_i \geq 0\), 0
otherwise), and items with \(r_i &lt; \lambda^\star\) will instead be
at their lower bound (0 of \(w_i \leq 0\), and 1 otherwise).</p>

<p>Critical items, items with \(r_i = \lambda^\star,\) will take any value
that results in \(w’x = b.\) Given \(\lambda^\star,\) we can
derive the sum of weights for non-critical items; divide the
remaining capacity for critical items by the total weight of critical
items, and let that be the value for every critical item (with the
appropriate sign for the weight).</p>

<p>For example, if we have capacity \(b = 10,\) and the sum of weights
for non-critical items in the knsapsack is \(8,\) we’re left with another
two units of capacity to distribute however we want among
critical items (they all have the same profit ratio \(r_i =
\lambda^\star,\) so it doesn’t matter where that capacity goes).  Say
critical items with a positive weight have a collective weight of 4;
we could then assign a value of \(2 / 4 = 0.5\) to the corresponding
decision variable (and 0 for critical items with a non-positive
weight).</p>

<p>We could instead have \(b = 10,\) and the sum of weights for
non-critical items in the knapsack \(12\): we must find two units of
capacity among critical items (they all cost \(r_i = \lambda^\star\)
per unit, so it doesn’t matter which).  If critical items with a
negative weight have a collective weight of \(-3,\) we could assign
a value of \(-2 / -3 = 0.6\overline{6}\) to the corresponding decision
variables, and 0 for critical items with a non-negative weight.</p>

<p>The last case highlights something important about the knapsack: in
general, we can’t assume that the weights <em>or profits</em> are positive.
We could have an item with a non-positive weight and non-negative
profit (that’s always worth taking), an item with positive weight and
negative profit (never interesting), or weights and profits of the
same sign.  The last case is the only one that calls for actual
decision making.  Classically, items with negative weight and profit
are rewritten away, by assuming they’re taken in the knapsack, and
replacing them with a decision variable for the complementary decision
of removing that item from the knapsack (i.e., removing the additional
capacity in order to improve the profit).  I’ll try to treat them
directly as much as possible, because that reduction can be a
significant fraction of solve times in practice.</p>

<p>The characterisation of optimal solutions above makes it easy to
directly handle elements with a negative weight: just find the optimal
multiplier, compute the contribution of non-critical elements (with
decision variables at a bound) to the left-hand side of the capacity
constraint, separately sums the negative and positive weights for
critical elements, then do a final pass to distribute the remaining
capacity to critical elements (and 0-weight / 0-value elements if one
wishes).</p>

<h2 id="solving-the-dual-looks-like-selection">Solving the dual looks like selection</h2>

<p>Finding the optimal multiplier \(\lambda^\star\) is similar to a
selection problem: the value is either 0 (the capacity constraint is
redundant), or one of the profit ratios \(r_i,\) and, given a
multiplier value \(\lambda,\) we can determine if it’s too high or
too low in linear time.  If the non-critical elements yield a left-hand
side such that critical elements
can’t add enough capacity (i.e., no solution with the optimal form can
be feasible), \(\lambda\) is too low.  If the maximum weight of
potentially optimal solutions is too low, \(\lambda\) is too high.</p>

<p>We can thus sort the items by profit ratio \(r_i\), compute the
total weight corresponding to each ratio with a prefix sum (with a
pre-pass to sum all negative weights), and perform a linear (or
binary) search to find the critical profit ratio.
Moreover, the status of non-critical items is monotonic as
\(\lambda\) grows: if an item with positive weight is taken at
\(\lambda_0\), it is also taken for every \(\lambda \leq
\lambda_0\), and a negative-weight item that’s taken at
\(\lambda_0\) is also taken for every \(\lambda \geq \lambda_0.\)
This means we can adapt selection algorithms like <a href="https://en.wikipedia.org/wiki/Quickselect">Quickselect</a> to solve
the continuous knapsack problem in linear time.</p>

<p>I’m looking at large instances, so I would like to run these
algorithms in parallel or even distributed on multiple machines, and
ideally use GPUs or SIMD extensions.  Unfortunately, selection doesn’t
parallelise very well: we can run a distributed quickselect where
every processor partitions the data in its local RAM, but that still
requires a logarithmic number of iterations.</p>

<h2 id="selection-looks-like-quantile-estimation-does-the-dual">Selection looks like quantile estimation; does the dual?</h2>

<p><a href="https://cs.stackexchange.com/questions/27685/can-someone-explain-lazyselect">Lazy Select</a> offers a completely different angle for the selection
problem.  Selecting the \(k\)th smallest element from a list of
\(n\) elements is the same as finding the \(k / n\)th quantile<sup id="fnref:abuse-of-language"><a href="#fn:abuse-of-language" class="footnote">1</a></sup> in
that list of \(n\) elements.  We can use <a href="https://en.wikipedia.org/wiki/Hoeffding%27s_inequality">concentration bounds</a><sup id="fnref:binomial"><a href="#fn:binomial" class="footnote">2</a></sup> to estimate quantiles from a sample of, e.g.,
\(m = n^{3/4}\) elements: the population quantile value is very
probably between the \(qm - \frac{\log m}{\sqrt{m}}\)th and \(qm +
\frac{\log m}{\sqrt{m}}\)th values of the sample.  Moreover, this
range very probably includes at most \(\mathcal{O}(n^{3/4})\)
elements<sup id="fnref:same-bounds"><a href="#fn:same-bounds" class="footnote">3</a></sup>, so a second pass suffices to buffer all the
elements around the quantile, and find the exact quantile.  Even with
a much smaller sample size \(m = \sqrt{n},\) we would only need four
passes.</p>

<p>Unfortunately, we can’t directly use that correspondence between
selection and quantile estimation for the continuous knapsack.</p>

<p>I tried to apply a similar idea by sampling the knapsack elements
equiprobably, and extrapolating from a solution to the sample.  For
every \(\lambda,\) we can derive a selection function 
\(f_\lambda (i) = I[r_i \geq \lambda]w_i\) 
(invert the condition if the weight is negative),
and scale up \(\sum_i f(i)\) from the sample to the population).
As long as we sample independently of \(f\), we can reuse the
same sample for all \(f_\lambda.\)
The difficulty here is that, while the error for Lazy Select
scales as a function of \(n,\) the equivalent bounds with
variable weights are a function of \(n(|\max_i w_i| + |\min_i w_i|)^2.\)
That doesn’t seem necessarily practical; scaling with \(\sum_i |w_i|\)
would be more reasonable.</p>

<p>Good news: we can hit that, thanks to linearity.</p>

<p>Let’s assume weights are all integers.  Any item with weight \(w_i\)
is equivalent to \(w_i\) subitems with unit weight (or \(-w_i\)
elements with negative unit weight), and the same profit ratio \(r_i\),
i.e., profit \(p_i / |w_i|\).  The range of <em>subitem</em> weights is now a constant.</p>

<p>We could sample uniformly from the subitems with a <a href="https://en.wikipedia.org/wiki/Bernoulli_distribution">Bernoulli</a> for each
subitem, but that’s clearly linear time in the sum of weights, rather
than the number of elements.  If we wish to sample roughly \(m\) elements
from a total weight \(W = \sum_i |w_i|,\) we can instead determine how
many subitems (units of weight) to skip before sampling with a
<a href="https://en.wikipedia.org/wiki/Geometric_distribution">Geometric</a> of
success probability \(m / W.\) This shows us how to lift the
integrality constraint on weights: sample from an <a href="https://en.wikipedia.org/wiki/Exponential_distribution">Exponential</a>
with the same parameter \(m / W!\)</p>

<p>That helps, but we could still end up spending much more than constant
time on very heavy elements.  The trick is to deterministically
special-case these elements: stash any element with large weight
\(w_i \geq W / m\) to the side, exactly once.  By <a href="https://en.wikipedia.org/wiki/Markov%27s_inequality">Markov’s inequality</a>,<sup id="fnref:pigeonhole"><a href="#fn:pigeonhole" class="footnote">4</a></sup>
we know there aren’t too many heavy elements: at most \(m.\)</p>

<h2 id="lets-test-this-out">Let’s test this out</h2>

<p>The heart of the estimation problem can be formalised as follows:
given a list of elements \(i \in [n]\) with weight \(w_i \geq 0\),
generate a sample of \(m \leq n\) elements ahead of time. After the
sample has been generated, we want to accept an arbitrary predicate
\(p \in \{0,1\}^n\) and estimate \(\sum_{i\in [n]} p(i) w_i.\)</p>

<p>We just had a sketch of an algorithm for this problem.  Let’s see
what it looks like in Python.  The initial sample logic has to
determine the total weight, and sample items with probability
proportional to their weight.  Items heavier than the cutoff are not
considered in the sample and instead saved to an auxiliary list.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span>sample.py </span></figcaption>
<div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
<span class="line-number">18</span>
<span class="line-number">19</span>
<span class="line-number">20</span>
<span class="line-number">21</span>
<span class="line-number">22</span>
<span class="line-number">23</span>
</pre></td><td class="code"><pre><code class="py"><span class="line"><span></span><span class="k">def</span> <span class="nf">total_weight</span><span class="p">(</span><span class="n">items</span><span class="p">):</span>
</span><span class="line">    <span class="k">return</span> <span class="nb">sum</span><span class="p">(</span><span class="n">weight</span> <span class="k">for</span> <span class="p">(</span><span class="n">_</span><span class="p">,</span> <span class="n">weight</span><span class="p">)</span> <span class="ow">in</span> <span class="n">items</span><span class="p">)</span>
</span><span class="line">
</span><span class="line">
</span><span class="line"><span class="k">def</span> <span class="nf">sample_by_weight</span><span class="p">(</span><span class="n">items</span><span class="p">,</span> <span class="n">rate</span><span class="p">,</span> <span class="n">cutoff</span><span class="p">):</span>
</span><span class="line">    <span class="sd">&quot;&quot;&quot;Samples from a list of (index, weight), with weight &gt;= 0.</span>
</span><span class="line">
</span><span class="line"><span class="sd">    Items with weight &gt;= cutoff are taken with probability one.</span>
</span><span class="line"><span class="sd">    Others are sampled with rate `rate` / unit of weight.</span>
</span><span class="line"><span class="sd">    &quot;&quot;&quot;</span>
</span><span class="line">    <span class="n">sample</span> <span class="o">=</span> <span class="p">[]</span>
</span><span class="line">    <span class="n">large</span> <span class="o">=</span> <span class="p">[]</span>
</span><span class="line">    <span class="n">next_sample</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">expovariate</span><span class="p">(</span><span class="n">rate</span><span class="p">)</span>
</span><span class="line">    <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">items</span><span class="p">:</span>
</span><span class="line">        <span class="n">index</span><span class="p">,</span> <span class="n">weight</span> <span class="o">=</span> <span class="n">item</span>
</span><span class="line">        <span class="k">if</span> <span class="n">weight</span> <span class="o">&gt;=</span> <span class="n">cutoff</span><span class="p">:</span>
</span><span class="line">            <span class="n">large</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">item</span><span class="p">)</span>
</span><span class="line">        <span class="k">else</span><span class="p">:</span>
</span><span class="line">            <span class="n">next_sample</span> <span class="o">-=</span> <span class="n">weight</span>
</span><span class="line">            <span class="k">while</span> <span class="n">next_sample</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
</span><span class="line">                <span class="n">sample</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">index</span><span class="p">)</span>
</span><span class="line">                <span class="n">next_sample</span> <span class="o">+=</span> <span class="n">random</span><span class="o">.</span><span class="n">expovariate</span><span class="p">(</span><span class="n">rate</span><span class="p">)</span>
</span><span class="line">    <span class="k">return</span> <span class="n">sample</span><span class="p">,</span> <span class="n">large</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>We can assemble the resulting sample (and list of “large” elements) to
compute a lower bound on the weight of items that satisfy any
predicate that’s independent of the sampling decisions.  The value for
large elements is trivial: we have a list of all large elements.
We can subtract the weight of all large elements from the total item
weight, and determine how much we have to extrapolate up.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span>extrapolate.py </span></figcaption>
<div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
<span class="line-number">18</span>
<span class="line-number">19</span>
<span class="line-number">20</span>
<span class="line-number">21</span>
<span class="line-number">22</span>
<span class="line-number">23</span>
<span class="line-number">24</span>
<span class="line-number">25</span>
<span class="line-number">26</span>
<span class="line-number">27</span>
<span class="line-number">28</span>
<span class="line-number">29</span>
<span class="line-number">30</span>
<span class="line-number">31</span>
<span class="line-number">32</span>
<span class="line-number">33</span>
<span class="line-number">34</span>
<span class="line-number">35</span>
<span class="line-number">36</span>
<span class="line-number">37</span>
<span class="line-number">38</span>
<span class="line-number">39</span>
<span class="line-number">40</span>
<span class="line-number">41</span>
<span class="line-number">42</span>
<span class="line-number">43</span>
</pre></td><td class="code"><pre><code class="py"><span class="line"><span></span><span class="k">def</span> <span class="nf">hoeffding</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">alpha</span><span class="p">):</span>
</span><span class="line">    <span class="sd">&quot;&quot;&quot;Determines how much we can expect a sample of n i.i.d. values</span>
</span><span class="line"><span class="sd">    sampled from a Bernouli to differ, given an error rate of alpha.</span>
</span><span class="line">
</span><span class="line"><span class="sd">    Given a sample X of n i.i.d. values from a Bernoulli distribution,</span>
</span><span class="line"><span class="sd">    let delta be \bar{X} - E[\bar{X}], the one-sided difference</span>
</span><span class="line"><span class="sd">    between the sample average value and the expected sample average.</span>
</span><span class="line">
</span><span class="line"><span class="sd">    Hoeffding&#39;s upper bound (see below) is conservative when the</span>
</span><span class="line"><span class="sd">    empirical probability is close to 0 or 1 (trivially, it can yield</span>
</span><span class="line"><span class="sd">    confidence bounds that are outside [0, 1]!), but simple, and in</span>
</span><span class="line"><span class="sd">    general not much worse than tighter confidence interval.</span>
</span><span class="line">
</span><span class="line"><span class="sd">    P(delta &gt;= eps) &lt;= exp(-2 eps^2 n) = alpha</span>
</span><span class="line"><span class="sd">      -&gt; -2 eps^2 n = ln alpha</span>
</span><span class="line"><span class="sd">     &lt;-&gt;        eps = sqrt[-(ln alpha) / 2n ]</span>
</span><span class="line">
</span><span class="line"><span class="sd">    &quot;&quot;&quot;</span>
</span><span class="line">    <span class="k">return</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="o">-</span> <span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">alpha</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">n</span><span class="p">))</span>
</span><span class="line">
</span><span class="line">
</span><span class="line"><span class="k">def</span> <span class="nf">eval_weight</span><span class="p">(</span><span class="n">total_weight</span><span class="p">,</span> <span class="n">sample</span><span class="p">,</span> <span class="n">large</span><span class="p">,</span> <span class="n">predicate</span><span class="p">,</span> <span class="n">alpha</span><span class="p">):</span>
</span><span class="line">    <span class="sd">&quot;&quot;&quot;Given a population&#39;s total weight, a memoryless sample (by weight)</span>
</span><span class="line"><span class="sd">    from the population&#39;s items, and large items that were</span>
</span><span class="line"><span class="sd">    deterministically picked, evaluates a lower bound for the sum of</span>
</span><span class="line"><span class="sd">    weights for items in the population that satisfy predicate.</span>
</span><span class="line"><span class="sd">    </span>
</span><span class="line"><span class="sd">    The lower bound is taken with error rate &lt;= alpha.</span>
</span><span class="line"><span class="sd">    &quot;&quot;&quot;</span>
</span><span class="line">    <span class="n">large_sum</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">weight</span> <span class="k">for</span> <span class="p">(</span><span class="n">index</span><span class="p">,</span> <span class="n">weight</span><span class="p">)</span> <span class="ow">in</span> <span class="n">large</span> <span class="k">if</span> <span class="n">predicate</span><span class="p">(</span><span class="n">index</span><span class="p">))</span>
</span><span class="line">    <span class="c1"># The remainder was up for sampling, unit of weight at a time.</span>
</span><span class="line">    <span class="n">sampled_weight</span> <span class="o">=</span> <span class="n">total_weight</span> <span class="o">-</span> <span class="nb">sum</span><span class="p">(</span><span class="n">weight</span> <span class="k">for</span> <span class="p">(</span><span class="n">_</span><span class="p">,</span> <span class="n">weight</span><span class="p">)</span> <span class="ow">in</span> <span class="n">large</span><span class="p">)</span>
</span><span class="line">    <span class="k">if</span> <span class="n">sampled_weight</span> <span class="o">&lt;=</span> <span class="mi">0</span> <span class="ow">or</span> <span class="ow">not</span> <span class="n">sample</span><span class="p">:</span>
</span><span class="line">        <span class="k">return</span> <span class="n">large_sum</span>
</span><span class="line">    <span class="c1"># Estimate the Binomial success rate with a Beta</span>
</span><span class="line">    <span class="n">successes</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="mi">1</span> <span class="k">if</span> <span class="n">predicate</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">else</span> <span class="mi">0</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">sample</span><span class="p">)</span>
</span><span class="line">    <span class="n">failures</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span> <span class="o">-</span> <span class="n">successes</span>
</span><span class="line">    <span class="c1"># We want a lower bound, and the uniform prior can result in a</span>
</span><span class="line">    <span class="c1"># (valid) bound that&#39;s higher than the empirical rate, so take the</span>
</span><span class="line">    <span class="c1"># min of the two.</span>
</span><span class="line">    <span class="n">empirical_rate</span> <span class="o">=</span> <span class="n">successes</span> <span class="o">/</span> <span class="n">sampled_weight</span>
</span><span class="line">    <span class="n">delta</span> <span class="o">=</span> <span class="n">hoeffding</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">sample</span><span class="p">),</span> <span class="n">alpha</span><span class="p">)</span>
</span><span class="line">    <span class="k">return</span> <span class="n">large_sum</span> <span class="o">+</span> <span class="n">sampled_weight</span> <span class="o">*</span> <span class="nb">max</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">empirical_rate</span> <span class="o">-</span> <span class="n">delta</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>And finally, here’s how we can sample from an arbitrary list of items,
compure a lower bound on the weight of items that satisfy a predicate,
and compare that with the real lower bound.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span>lower_bound.py </span></figcaption>
<div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
</pre></td><td class="code"><pre><code class="py"><span class="line"><span></span><span class="k">def</span> <span class="nf">compare_bounds</span><span class="p">(</span><span class="n">items</span><span class="p">,</span> <span class="n">rate</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">predicate</span><span class="p">):</span>
</span><span class="line">    <span class="n">total</span> <span class="o">=</span> <span class="n">total_weight</span><span class="p">(</span><span class="n">items</span><span class="p">)</span>
</span><span class="line">    <span class="c1"># We expect a sample size of roughly rate * len(items), and</span>
</span><span class="line">    <span class="c1"># at most rate * len(items) large items.</span>
</span><span class="line">    <span class="n">sample</span><span class="p">,</span> <span class="n">large</span> <span class="o">=</span> <span class="n">sample_by_weight</span><span class="p">(</span><span class="n">items</span><span class="p">,</span> <span class="n">rate</span><span class="p">,</span> <span class="n">rate</span> <span class="o">*</span> <span class="n">total</span><span class="p">)</span>
</span><span class="line">    <span class="n">lower_bound</span> <span class="o">=</span> <span class="n">eval_weight</span><span class="p">(</span><span class="n">total</span><span class="p">,</span> <span class="n">sample</span><span class="p">,</span> <span class="n">large</span><span class="p">,</span> <span class="n">predicate</span><span class="p">,</span> <span class="n">alpha</span><span class="p">)</span>
</span><span class="line">    <span class="c1"># Check if the lower bound is valid.</span>
</span><span class="line">    <span class="n">actual</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">weight</span> <span class="k">for</span> <span class="p">(</span><span class="n">index</span><span class="p">,</span> <span class="n">weight</span><span class="p">)</span> <span class="ow">in</span> <span class="n">items</span> <span class="k">if</span> <span class="n">predicate</span><span class="p">(</span><span class="n">index</span><span class="p">))</span>
</span><span class="line">    <span class="k">return</span> <span class="n">lower_bound</span> <span class="o">&lt;=</span> <span class="n">actual</span> <span class="o">+</span> <span class="mf">1e-8</span><span class="p">,</span> <span class="n">lower_bound</span><span class="p">,</span> <span class="n">actual</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>How do we test that? Far too often, I see tests for randomised
algorithms where the success rate is computed over randomly generated
inputs.  That’s too weak!  For example, this approach could lead us to accept
that the identity function is a randomised sort function, with success
probability \(\frac{1}{n!}.\)</p>

<p>The property we’re looking for is that, for any input, the success
rate (with the expectation over the pseudorandom sampling decisions)
is as high as requested.</p>

<p>For a given input (list of items and predicate), we can use the <a href="http://pvk.ca/Blog/2018/07/06/testing-slo-type-properties-with-the-confidence-sequence-method/">Confidence sequence method (CSM)</a>
to confirm that the lower bound is valid at least
\(1 - \alpha\) of the time.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span>csm_test.py </span></figcaption>
<div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
<span class="line-number">18</span>
<span class="line-number">19</span>
<span class="line-number">20</span>
<span class="line-number">21</span>
<span class="line-number">22</span>
<span class="line-number">23</span>
</pre></td><td class="code"><pre><code class="py"><span class="line"><span></span><span class="k">def</span> <span class="nf">compare_bounds_generator</span><span class="p">(</span><span class="n">test_case</span><span class="p">,</span> <span class="n">rate</span><span class="p">,</span> <span class="n">alpha</span><span class="p">):</span>
</span><span class="line">    <span class="n">items</span> <span class="o">=</span> <span class="p">[(</span><span class="n">i</span><span class="p">,</span> <span class="n">w</span><span class="p">)</span> <span class="k">for</span> <span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">_</span><span class="p">))</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">test_case</span><span class="p">)]</span>
</span><span class="line">    <span class="n">chosen</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">i</span> <span class="k">for</span> <span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">_</span><span class="p">,</span> <span class="n">p</span><span class="p">))</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">test_case</span><span class="p">)</span> <span class="k">if</span> <span class="n">p</span><span class="p">)</span>
</span><span class="line">    <span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
</span><span class="line">        <span class="k">yield</span> <span class="n">compare_bounds</span><span class="p">(</span><span class="n">items</span><span class="p">,</span> <span class="n">rate</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">chosen</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
</span><span class="line">
</span><span class="line">
</span><span class="line"><span class="k">def</span> <span class="nf">check_bounds</span><span class="p">(</span><span class="n">test_case</span><span class="p">,</span> <span class="n">rate</span><span class="p">,</span> <span class="n">alpha</span><span class="p">):</span>
</span><span class="line">    <span class="sd">&quot;&quot;&quot;Test case is a list of pairs of weight and predicate value</span>
</span><span class="line"><span class="sd">       rate is the sample rate</span>
</span><span class="line"><span class="sd">       alpha is the confidence parameter for the lower bound.</span>
</span><span class="line"><span class="sd">    &quot;&quot;&quot;</span>
</span><span class="line">    <span class="n">wanted</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">alpha</span>  <span class="c1"># The Hoeffding bound is conservative, so</span>
</span><span class="line">                        <span class="c1"># this should let csm_driver stop quickly.</span>
</span><span class="line">    <span class="n">result</span> <span class="o">=</span> <span class="n">csm</span><span class="o">.</span><span class="n">csm_driver</span><span class="p">(</span><span class="n">compare_bounds_generator</span><span class="p">(</span><span class="n">test_case</span><span class="p">,</span>
</span><span class="line">                                                     <span class="n">rate</span><span class="p">,</span>
</span><span class="line">                                                     <span class="n">alpha</span><span class="p">),</span>
</span><span class="line">                            <span class="n">wanted</span><span class="p">,</span>
</span><span class="line">                            <span class="mf">1e-6</span><span class="p">,</span>  <span class="c1"># Wrong conclusion with p &lt; 1e-6.</span>
</span><span class="line">                            <span class="nb">file</span><span class="o">=</span><span class="n">sys</span><span class="o">.</span><span class="n">stderr</span>
</span><span class="line">                            <span class="p">)</span>
</span><span class="line">    <span class="n">stop</span><span class="p">,</span> <span class="n">actual</span><span class="p">,</span> <span class="o">*</span><span class="n">_</span> <span class="o">=</span> <span class="n">result</span>
</span><span class="line">    <span class="k">assert</span> <span class="n">actual</span> <span class="o">&gt;=</span> <span class="n">wanted</span><span class="p">,</span> <span class="s2">&quot;Result: </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="nb">str</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>With a false positive rate of at most one in a million,<sup id="fnref:lotta-errors"><a href="#fn:lotta-errors" class="footnote">5</a></sup> we can
run automated tests against <code>check_bounds</code>.  I’ll use
<a href="https://hypothesis.works/">Hypothesis</a> to generate list of pairs of weight and predicate value:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span>test_bounds.py </span></figcaption>
<div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
</pre></td><td class="code"><pre><code class="py"><span class="line"><span></span><span class="kn">from</span> <span class="nn">hypothesis</span> <span class="kn">import</span> <span class="n">given</span><span class="p">,</span> <span class="n">settings</span><span class="p">,</span> <span class="n">Verbosity</span>
</span><span class="line"><span class="kn">import</span> <span class="nn">hypothesis.strategies</span> <span class="kn">as</span> <span class="nn">st</span>
</span><span class="line">
</span><span class="line"><span class="nd">@given</span><span class="p">(</span><span class="n">test_case</span><span class="o">=</span><span class="n">st</span><span class="o">.</span><span class="n">lists</span><span class="p">(</span><span class="n">st</span><span class="o">.</span><span class="n">tuples</span><span class="p">(</span><span class="n">st</span><span class="o">.</span><span class="n">floats</span><span class="p">(</span><span class="n">min_value</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">max_value</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
</span><span class="line">                                    <span class="n">st</span><span class="o">.</span><span class="n">booleans</span><span class="p">())),</span>
</span><span class="line">       <span class="n">rate</span><span class="o">=</span><span class="n">st</span><span class="o">.</span><span class="n">floats</span><span class="p">(</span><span class="n">min_value</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">,</span> <span class="n">max_value</span><span class="o">=</span><span class="mf">0.5</span><span class="p">),</span>
</span><span class="line">       <span class="n">alpha</span><span class="o">=</span><span class="n">st</span><span class="o">.</span><span class="n">floats</span><span class="p">(</span><span class="n">min_value</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span> <span class="n">max_value</span><span class="o">=</span><span class="mf">0.25</span><span class="p">))</span>
</span><span class="line"><span class="k">def</span> <span class="nf">test_bounds</span><span class="p">(</span><span class="n">test_case</span><span class="p">,</span> <span class="n">rate</span><span class="p">,</span> <span class="n">alpha</span><span class="p">):</span>
</span><span class="line">    <span class="n">check_bounds</span><span class="p">(</span><span class="n">test_case</span><span class="p">,</span> <span class="n">rate</span><span class="p">,</span> <span class="n">alpha</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Bimodal inputs tend to be harder, so we can add a specialised test
generator.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span>test_bimodal_bounds.py </span></figcaption>
<div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
</pre></td><td class="code"><pre><code class="py"><span class="line"><span></span><span class="nd">@given</span><span class="p">(</span><span class="n">test_case</span><span class="o">=</span><span class="n">st</span><span class="o">.</span><span class="n">lists</span><span class="p">(</span><span class="n">st</span><span class="o">.</span><span class="n">tuples</span><span class="p">(</span><span class="n">st</span><span class="o">.</span><span class="n">one_of</span><span class="p">(</span><span class="n">st</span><span class="o">.</span><span class="n">just</span><span class="p">(</span><span class="mf">0.1</span><span class="p">),</span> <span class="n">st</span><span class="o">.</span><span class="n">just</span><span class="p">(</span><span class="mi">1</span><span class="p">)),</span>
</span><span class="line">                                    <span class="n">st</span><span class="o">.</span><span class="n">booleans</span><span class="p">())),</span>
</span><span class="line">       <span class="n">rate</span><span class="o">=</span><span class="n">st</span><span class="o">.</span><span class="n">floats</span><span class="p">(</span><span class="n">min_value</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">,</span> <span class="n">max_value</span><span class="o">=</span><span class="mf">0.5</span><span class="p">),</span>
</span><span class="line">       <span class="n">alpha</span><span class="o">=</span><span class="n">st</span><span class="o">.</span><span class="n">floats</span><span class="p">(</span><span class="n">min_value</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span> <span class="n">max_value</span><span class="o">=</span><span class="mf">0.25</span><span class="p">))</span>
</span><span class="line"><span class="k">def</span> <span class="nf">test_bimodal_bounds</span><span class="p">(</span><span class="n">test_case</span><span class="p">,</span> <span class="n">rate</span><span class="p">,</span> <span class="n">alpha</span><span class="p">):</span>
</span><span class="line">    <span class="n">check_bounds</span><span class="p">(</span><span class="n">test_case</span><span class="p">,</span> <span class="n">rate</span><span class="p">,</span> <span class="n">alpha</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Again, we use <a href="https://hypothesis.readthedocs.io/en/latest/data.html">Hypothesis</a> to generate inputs, and
the <a href="https://github.com/pkhuong/csm">Confidence sequence method (available in C, Common Lisp, and Python)</a> to check that the lower bound is
valid with probability at least \(1 - \alpha\).  The CSM tests
for this statistical property with power 1 and adjustable error rate
(in our case, one in a million): we only provide a generator
for success values, and the driver adaptively determines when it makes
sense to make a call and stop generating more data, while accounting
for multiple hypothesis testing.</p>

<p>TL;DR: the estimation algorithm for individual sampling passes works,
and the combination of <a href="https://hypothesis.works/">Hypothesis</a> and <a href="https://github.com/pkhuong/csm">Confidence Sequence Method</a>
lets us painlessly test for a statistical property.</p>

<p>We can iteratively use this sampling procedure to derive lower and
(symmetrically) upper bounds for the optimal Lagrange multiplier
\(\lambda^\star,\) and Hoeffding’s inequality lets us control the
probability that the lower and upper bounds are valid.  Typically,
we’d use a tolerance of \(\sqrt{\log(n) / n},\) for an error
rate of \(1 / n^2.\) I prefer to simply use something like \(7 /
\sqrt{n}:\) the error rate is then less than \(10^{-42},\)
orders of manitude smaller than the probability of hardware failure in any given
nanosecond.<sup id="fnref:memory-error"><a href="#fn:memory-error" class="footnote">6</a></sup>
We can still check for failure of our Las Vegas algorithm,
but if something went wrong, it’s much more likely that we detected
a hardware failure than anything else.  It’s like running <a href="https://en.wikipedia.org/wiki/Super_PI">SuperPi</a>
to stress test a computer, except the work is useful. 😉</p>

<h2 id="repeat-as-necessary-to-solve-a-knapsack">Repeat as necessary to solve a knapsack</h2>

<p>How many sampling passes do we need? Our bounds are in terms of the
sum of item weight: if we let our sample size be in
\(\Theta(\sqrt{n}),\) the sum of weights \(\sum_i |w_i|\) for
unfathomed items (that may or may not be chosen depending on the exact
optimal multiplier \(\lambda^\star\) in the current range) will very
probably shrink by a factor of \(\Omega(n^{1/4}).\) The initial sum can, in
the worst case, be exponentially larger than the bitlength of the
input, so even a division by \(n^{1/4}\) isn’t necessarily that
great.</p>

<p>I intend to apply this Lazy Linear Knapsack algorithm on subproblems in
a more interesting solver, and I know that the sum of weights is
bounded by the size of the initial problem, so that’s good enough for
me!  After a constant (\(\approx 4\)) number of passes, the
difference in item weight between the lower and upper bound on
\(\lambda^\star\) should also be at most 1.  One or two additional
passes will get me near optimality (e.g., within \(10^{-4}\)),
and the lower bound on \(\lambda^\star\) should thus yield
a super-optimal solution that’s infeasible by at most \(10^{-4},\)
which is, for my intended usage (again), good enough.</p>

<p>Given an optimal enough \(\lambda^\star,\) we can construct an
explicit solution in one pass, plus a simple fixup for critical items.
This Lazy Knapsack seems pretty reasonable for parallel or GPU
computing: each sampling pass only needs to read the items (i.e., no
partitioning-like shuffling) before writing a fraction of the data to
a sample buffer, and we only need a constant number of passes (around
6 or 7) in the worst case.</p>

<p><hr style="width: 50%" /></p>
<div class="footnotes">
  <ol>
    <li id="fn:abuse-of-language">
      <p>It’s more like a fractional percentile, but you know what I mean: the value such that the distribution function at that point equals \(k / n\). <a href="#fnref:abuse-of-language" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:binomial">
      <p>Binomial bounds offer even stronger confidence intervals when the estimate is close to 0 or 1 (where Hoeffding’s bound would yield a confidence interval that juts outside \([0, 1]\)), but don’t impact worst-case performance. <a href="#fnref:binomial" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:same-bounds">
      <p>Thanks to Hoeffding’s inequality, again. <a href="#fnref:same-bounds" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:pigeonhole">
      <p>That’s a troll. I think any self-respecting computer person would rather see it as a sort of pigeonhole argument. <a href="#fnref:pigeonhole" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:lotta-errors">
      <p>We’re juggling a handful of error rates here. We’re checking whether the success rate for the Lazy Knapsack sampling subroutine is at least as high as \(1 - \alpha,\) as requested in the test parameters, and we’re doing so with another randomised procedure that will give an incorrect conclusion at most once every one million invocation. <a href="#fnref:lotta-errors" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:memory-error">
      <p><a href="http://www.cs.toronto.edu/~bianca/papers/sigmetrics09.pdf">This classic Google study</a> found 8% of DIMMs hit at least one error per year; that’s more than one single-bit error every \(10^9\) DIMM-second, and they’re mostly hard errors.  <a href="https://users.ece.cmu.edu/~omutlu/pub/memory-errors-at-facebook_dsn15.pdf">More recently, Facebook</a> reported that uncorrectable errors affect 0.03% of servers each month; that’s more than one uncorrectable error every \(10^{10}\) server-second.  If we performed one statistical test every nanosecond, the probability of memory failure alone would still dominate statistical errors by \(10^{20}!\) <a href="#fnref:memory-error" class="reversefootnote">&#8617;</a></p>
    </li>
  </ol>
</div>
]]></content>
  </entry>
  
</feed>
