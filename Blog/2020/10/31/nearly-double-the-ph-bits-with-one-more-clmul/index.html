
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>1.5x the PH bits for one more CLMUL - Paul Khuong: some Lisp</title>
  <meta name="author" content="Paul Khuong">
  <meta name="description" content="Paul Khuong's personal blog. Some Lisp, some optimisation, mathematical or computer.">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="https://www.pvk.ca/Blog/2020/10/31/nearly-double-the-ph-bits-with-one-more-clmul/">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="/atom.xml" rel="alternate" title="Paul Khuong: some Lisp" type="application/atom+xml">
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link rel="preconnect" href="https://fonts.gstatic.com/" crossorigin>
<link href="//fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic&display=fallback" rel="stylesheet" type="text/css">
<link href="//fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic&display=fallback" rel="stylesheet" type="text/css">
<link href="//fonts.googleapis.com/css?family=Poller+One&display=fallback" rel="stylesheet" type="text/css">
<link href="//fonts.googleapis.com/css?family=Germania+One&display=fallback" rel="stylesheet" type="text/css">
<link href="//fonts.googleapis.com/css?family=Fontdiner+Swanky&display=fallback" rel="stylesheet" type="text/css">
<link href="//fonts.googleapis.com/css?family=Lato&subset=latin-ext&display=fallback" rel="stylesheet" type="text/css">
<link href="//fonts.googleapis.com/css?family=Cardo&subset=latin-ext&display=fallback" rel="stylesheet" type="text/css">
<link href="//fonts.googleapis.com/css?family=Sorts+Mill+Goudy&display=fallback" rel="stylesheet" type="text/css">
<link href="//fonts.googleapis.com/css?family=EB+Garamond&display=fallback" rel="stylesheet" type="text/css">
<link href="//fonts.googleapis.com/css?family=Della+Respira&display=fallback" rel="stylesheet" type="text/css">
<link href="//fonts.googleapis.com/css?family=UnifrakturMaguntia&subset=all&display=fallback" rel="stylesheet" type="text/css">
<link href='//fonts.googleapis.com/css?family=Arimo|EB+Garamond|PT+Sans+Caption&subset=latin,cyrillic&display=fallback' rel='stylesheet' type='text/css'>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
  TeX: {
    Macros: {
     sp: "^",
     sb: "_"
    }
  }});
</script>
<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<meta name="twitter:dnt" content="on">

</head>

<body >
  <header role="banner"><hgroup>
  <h1><a href="/">Paul Khuong: some Lisp</a></h1>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/Blog/archives">Archives</a></li>
  <li><a href="/atom.xml" title="subscribe via RSS">RSS</a></li>
</ul>

<br>

      
        <form action="https://google.com/search" method="get">
          <fieldset role="search">
            <input type="hidden" name="q" value="site:https://www.pvk.ca" />
      
      
            <input class="search" type="text" name="q" results="0" placeholder="Search" aria-label="Search"/>
          </fieldset>
        </form>
  
</nav>
  <div id="main">
    <div id="content">
      
      <div>
<article class="hentry" role="article">
  
  <header>
    
      
        <h1 class="entry-title" style="font-family: ">1.5x the PH bits for one more CLMUL</h1>
      
    
    
      <p class="meta">
        





Oct
  
31st, 
2020




        
         | <a href="#disqus_thread"
              data-disqus-identifier="https://www.pvk.ca/Blog/2020/10/31/nearly-double-the-ph-bits-with-one-more-clmul/"
	      >Comments</a>
        
        
      </p>
    
  </header>


<div class="entry-content" style="font-family: ; font-size: "><p><small>Turns out the part where I simply asserted a probability was slightly off üòâ. I had to go back to an older proof with weaker bounds, but that‚Äôs fine, since we still collide way more rarely than \(2^{-70}\).</small></p>

<p>The core of <a href="https://github.com/backtrace-labs/umash">UMASH</a> is a
hybrid <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.105.9929&amp;rep=rep1&amp;type=pdf#page=3">PH</a>/<a href="https://eprint.iacr.org/2004/319.pdf#page=4">(E)NH</a>
block compression function.
That function is fast
(it needs one multiplication for each 16-byte ‚Äúchunk‚Äù in a block),
but relatively weak:
even with a 128-bit output, the worst-case probability of collision is
\(2^{-64}\).</p>

<p>For a <a href="https://en.wikipedia.org/wiki/Fingerprint_(computing)">fingerprinting</a>
application, we want collision probability less than \(\approx 2^{-70},\)
so that‚Äôs already too weak,
before we even consider merging a variable-length string of compressed
block values.</p>

<p>The <a href="https://pvk.ca/Blog/2020/08/24/umash-fast-enough-almost-universal-fingerprinting/">initial UMASH proposal</a>
compresses each block with two independent compression functions.
Krovetz showed that we could do so while reusing most of the key material
(random parameters), with a <a href="http://krovetz.net/csus/papers/thesis.pdf#page=50">Toeplitz extension</a>,
and I simply recycled the proof for UMASH‚Äôs hybrid compressor.</p>

<p>That‚Äôs good for the memory footprint of the random parameters, but
doesn‚Äôt help performance: we still have to do double the work to get
double the hash bits.</p>

<p>Earlier this month, <a href="https://github.com/jbapple">Jim Apple</a> pointed me at
a <a href="https://link.springer.com/chapter/10.1007/978-3-662-46706-0_25">promising alternative that doubles the hash bit with only one more multiplication</a>.
The construction adds finite field operations that aren‚Äôt particularly
efficient in software, on top of the additional 64x64 -&gt; 128
(carryless) multiplication, so isn‚Äôt a slam dunk win over a
straightforward Toeplitz extension.
However, Jim felt like we could ‚Äúspend‚Äù some of the bits we don‚Äôt need
for fingerprinting (\(2^{-128}\) collision probability is overkill
when we only need \(2^{-70}\)) in order to make do with faster operations.</p>

<p>Turns out he was right! We can use carryless multiplications by sparse
constants (concretely, xor-shift and one more shift) without any
reducing polynomial, <em>on independent 64-bit halves</em>‚Ä¶ and still
collide with probability at most <s>2^{-126}</s> \(2^{-98}\).</p>

<p>The proof is fairly simple, but relies on a bit of notation for clarity.
Let‚Äôs start by re-stating UMASH‚Äôs hybrid PH/ENH block compressor in
that notation.</p>

<h2 id="how-does-umash-currently-work">How does UMASH currently work?</h2>

<p>The current block compressor in UMASH splits a 256-byte block \(m\)
in 16 chunks \(m_i\, i\in [0, 15]\) of 128 bits each, and processes
all but the last chunk with a PH loop,</p>

<p>\[ \bigoplus_{i=0}^{14} \mathtt{PH}(k_i, m_i), \]</p>

<p>where</p>

<p>\[ \mathtt{PH}(k_i, m_i) = (k_i \bmod 2^{64}) \oplus (m_i \bmod 2^{64})) \odot (\lfloor k_i / 2^{64} \rfloor \oplus \lfloor m_i / 2^{64} \rfloor) \]</p>

<p>and each \(k_i\) is a randomly generated 128-bit parameter.</p>

<p>The compression loop in UMASH handles the last chunk, along with a
size tag (to protect against extension attacks) with
<a href="https://eprint.iacr.org/2004/319.pdf#page=4">ENH</a>:</p>

<p>\[ \mathtt{ENH}(k, x, y) = ((k + x) \bmod 2^{64}) \cdot (\lfloor k / 2^{64}\rfloor + \lfloor x / 2^{64} \rfloor \bmod 2^{64}) + y \mod 2^{128}. \]</p>

<p>The core operation in ENH is a full (64x64 -&gt; 128) integer
multiplication, which has lower latency than PH‚Äôs carryless
multiplication on x86-64.  That‚Äôs why UMASH switches to ENH for the
last chunk.  We use ENH for only one chunk because combining multiple
NH values calls for 128-bit additions, and that‚Äôs slower than PH‚Äôs
xors.  Once we have mixed the last chunk and the size tag with ENH,
the result is simply xored in with the previous chunks‚Äô PH values:</p>

<p>\[ \left(\bigoplus_{i=0}^{14} \mathtt{PH}(k_i, m_i)\right)  \oplus \mathtt{ENH}(m_{15}, k_{15}, \mathit{tag}). \]</p>

<p>This function is annoying to analyse directly, because we end up
having to manipulate different proofs of almost-universality.  Let‚Äôs
abstract this a bit, and reduce the ENH/PH to the bare minimum we need
to find our collision bounds.</p>

<p>Let‚Äôs split our message blocks in \(n\) (\(n = 16\) for
UMASH) ‚Äúchunks‚Äù, and apply an independently sampled mixing function
to each chunk.  Let‚Äôs say we have two messages \(m\) and
\(m^\prime\) with chunks \(m_i\) and \(m^\prime_i\), for \(i\in
[0, n)\), and let \(h_i\) be the result of mixing chunk \(m_i,\)
and \(h^\prime_i\) that of mixing \(m^\prime_i.\)</p>

<p>We‚Äôll assume that the first chunk is mixed with a
\(2^{-w}\)-almost-universal (\(2^{-64}\) for UMASH) hash function:
if \(m_0 \neq m^\prime_0,\) \(\mathrm{P}[h_0 = h^\prime_0] \leq 2^{-w},\)
(where the probability is taken over the set of randomly chosen
parameters for the mixer).
Otherwise, \(m_0 = m^\prime_0 \Rightarrow h_i = h^\prime_i\).</p>

<p>This first chunks stands for the ENH iteration in UMASH.</p>

<p>Every other chunk will instead be mixed with a
\(2^{-w}\)-XOR-almost-universal hash function:
if \(m_i \neq m^\prime_i\) (\(0 &lt; i &lt; n\)),
\(\mathrm{P}[h_i \oplus h^\prime_i = y] \leq 2^{-w}\)
for any \(y,\)
where the probability is taken over the randomly chosen
parameter for the mixer.</p>

<p>This stronger condition represents the PH iterations in UMASH.</p>

<p>We hash a full block by xoring all the mixed chunks together:</p>

<p>\[ H = \bigoplus_{i = 0}^{n - 1} h_i, \]</p>

<p>and</p>

<p>\[ H^\prime = \bigoplus_{i = 0}^{n - 1} h^\prime_i. \]</p>

<p>We want to bound the probability that \(H = H^\prime \Leftrightarrow
H \oplus H^\prime = 0,\) assuming that the messages differ
(i.e., there is at least one index \(i\) such that
\(m_i \neq m^\prime_i\)).</p>

<p>If the two messages only differ in \(m_0 \neq n^\prime_0\) (and thus
\(m_i = m^\prime_i,\,\forall i \in [1, n)\)),</p>

<p>\[ \bigoplus_{i = 1}^{n - 1} h_i = \bigoplus_{i = 1}^{n - 1} h^\prime_i, \]</p>

<p>and thus \(H = H^\prime \Leftrightarrow h_0 = h^\prime_0\).</p>

<p>By hypothesis, the 0th chunks are mixed with a
\(2^{-w}\)-almost-universal hash, so this happens with probability
at most \(2^{-w}\).</p>

<p>Otherwise, assume that \(m_j \neq m^\prime_j\), for some \(j \in
[1, n)\).
We can rearrange the expression</p>

<p>\[ H \oplus H^\prime = h_j \oplus h^\prime_j \oplus \left(\bigoplus_{i\in [0, n) \setminus \{ j \}} h_i \oplus h^\prime_i\right). \]</p>

<p>Let‚Äôs conservatively replace that unwieldly sum with an adversarially
chosen value \(y\):</p>

<p>\[ H \oplus H^\prime = h_j \oplus h^\prime_j \oplus y, \]</p>

<p>and thus \(H = H^\prime\) iff \(h_j \oplus h^\prime_j = y.\)
By hypothesis, the \(j\)th chunk (every chunk but the 0th),
is mixed with a \(2^{-w}\)-almost-XOR-universal hash, and
this thus happens with probability at most \(2^{-w}\).</p>

<p>In both cases, we find a collision probability at most \(2^{-w}\)
with a simple analysis, despite combining mixing functions from
different families over different rings.</p>

<h2 id="wringing-more-bits-out-of-the-same-mixers">Wringing more bits out of the same mixers</h2>

<p>We combined strong mixers (each is \(2^{-w}\)-almost-universal),
and only get a \(2^{-w}\)-almost-universal output.
It seems like we should be able to do better when two or
more chunks differ.</p>

<p>As <a href="https://link.springer.com/chapter/10.1007/978-3-662-46706-0_25">Nandi</a>
points outs, we can apply erasure codes to derive additional
chunks from the original messages‚Äô contents.  We only need
one more chunk, so we can simply xor together all the original
chunks:</p>

<p>\[m_n = \bigoplus_{i=0}^{n - 1} m_i,\]</p>

<p>and similarly for \(m^\prime_n\).
If \(m\) and \(m^\prime\) differ in only one chunk, \(m_n \neq
m^\prime_n\).  It‚Äôs definitely possible for \(m_n = m^\prime_n\)
when \(m \neq m^\prime\), but only if two or more chunks differ.</p>

<p>We will again mix \(m_n\) and \(m^\prime_n\) with a fresh
\(2^{-w}\)-almost-XOR-universal hash function to yield \(h_n\) and
\(h^\prime_n\).</p>

<p>We want to xor the result \(h_n\) and \(h^\prime_n\) with the second
(still undefined) hash values \(H_2\) and \(H^\prime_2\); if
\(m_n \neq m^\prime_n\), the final xored values are equal with
probability at most \(2^{-w}\), regardless of \(H_2\) and
\(H^\prime_2\ldots\) and, crucially, independently of \(H \neq
H^\prime\).</p>

<p>When the two messages \(m\) and \(m^\prime\) only differ in a
single (initial) chunk, mixing a <a href="https://en.wikipedia.org/wiki/Longitudinal_redundancy_check">LRC checksum</a>
gives us an independent hash function, which
squares the collision probability to \(2^{-2w}\).</p>

<p>Now to the interesting bit: we must define a second hash function for
chunks 0 to \(n - 1\) such that its hash values \(H_2\) and \(H^\prime_2\) collide
independently enough of \(H\) and \(H^\prime\).
That‚Äôs a tall order, but we do have one additional assumption to work
with: we only care about collisions in this second hash function if the
additional checksum chunks are equal, which means that the two messages
differ in two or more chunks (or they‚Äôre identical).</p>

<p>For each index \(0 &lt; i &lt; n\), we‚Äôll fix a <em>public</em> linear (with
xor as the addition) function \(\overline{xs}_i(x)\), with two
properties:</p>

<ol>
  <li>\(f(x) = x \oplus \overline{xs}_i(x)\) is invertible for \(i &gt; 0\)</li>
  <li>For any two distinct \(0 &lt; i &lt; j &lt; n\), xoring the two functions
together into \(g(x) = \overline{xs}_i(x) \oplus \overline{xs}_j(x)\)
yields a function with a small null space.  In other words, while
\(g\) may not be invertible, it must be ‚Äúpretty close.‚Äù</li>
</ol>

<p>For regularity, we will also define \(\overline{xs}_0(x) = x\).</p>

<p>Concretely, let \(\overline{xs}_1(x) = x \mathtt{¬´} 1\), where the
bitshift is computed for the two 64-bit halves independently, and
\(\overline{xs}_i(x) = (x  \mathtt{¬´} 1) \oplus (x \mathtt{¬´} i)\)
for \(i &gt; 1\), again with all the bitshifts computed independently
over the two 64-bit halves.</p>

<p>To see that these satisfy our requirements, we can represent the
functions as carryless multiplication by distinct ‚Äúeven‚Äù constants
(the least significant bit is 0) on each 64-bit half:</p>

<ol>
  <li>Once we xor in \(x\), we get a multiplication by an odd constant,
and that‚Äôs invertible.</li>
  <li>Combining \(\overline{xs}_i\) and \(\overline{xs}_j\) with xor
yields \(x \mathtt{¬´} j\), or \((x \mathtt{¬´} i) \oplus (x \mathtt{¬´} j)\).  In the worst case, we lose \(j\) bits in each 64-bit half,
and there are thus \(2^{2j}\) values in \(g^{-1}(0)\).</li>
</ol>

<p>To recapitulate, we defined the first hash function as</p>

<p>\[ H = \bigoplus_{i = 0}^{n - 1} h_i, \]</p>

<p>the (xor) sum of the mixed value \(h_i\) for each chunk \(m_i\) in
the message block \(m\), and similarly for \(H^\prime\) and
\(h^\prime_i\).</p>

<p>We‚Äôll let the second hash function be</p>

<p>\[ H_2 \oplus h_n = \left(\bigoplus_{i = 0}^{n - 1} \overline{xs}_i(h_i)\right) \oplus h_n, \]</p>

<p>and</p>

<p>\[ H^\prime_2 \oplus h^\prime_n = \left(\bigoplus_{i = 0}^{n - 1} \overline{xs}_i(h^\prime_i)\right) \oplus h^\prime_n. \]</p>

<p>We can finally get down to business and find some collision bounds.
We‚Äôve already shown that both \(H = H^\prime\) <em>and</em> \(H_2 \oplus_n =
H^\prime_2 \oplus h^\prime_n\) collide simultaneously with probability at most \(2^{-2w}\)
when the checksum chunks differ, i.e., when \(m_n \neq m^\prime_n\).</p>

<p>Let‚Äôs now focus on the case when \(m \neq m^\prime\), but \(m_n =
m^\prime_n\).
In that case, we know that at least two chunks \(0 \leq i &lt; j &lt; n\)
differ: \(m_i \neq m^\prime_i\) and \(m_j \neq m^\prime_j\).</p>

<p>If only two chunks \(i\) and \(j\) differ, and one of them is the
\(i = 0\)th chunk, we want to bound the probability that</p>

<p>\[ h_0 \oplus h_j = h^\prime_0 \oplus h^\prime_j \]</p>

<p>and</p>

<p>\[ h_0 \oplus \overline{xs}_j(h_j) = h^\prime_0 \oplus \overline{xs}_j(h^\prime_j) = 0, \]</p>

<p>both at the same time.</p>

<p>Letting \(\Delta_i = h_i \oplus h^\prime_i\), we can reformulate the
two conditions as</p>

<p>\[ \Delta_0 = \Delta_j \]
and
\[ \Delta_0 = \overline{xs}_j(\Delta_j). \]</p>

<p>Taking the xor of the two conditions yields</p>

<p>\[ \Delta_j \oplus \overline{xs}_j(\Delta_j) = 0, \]</p>

<p>which is only satisfied for \(\Delta_j = 0\), since \(f(x) = x
\oplus \overline{xs}_j(x)\) is an invertible linear function.
That also forces \(\Delta_0 = 0\).</p>

<p>By hypothesis, \(\mathrm{P}[\Delta_j = 0] \leq 2^{-w}\), and
\(\mathrm{P}[\Delta_0 = 0] \leq 2^{-w}\) as well.  These two
probabilities are independent, so we get a probability that both
hash collide less than or equal to \(2^{-2w}\) (\(2^{-128}\)).</p>

<p>In the other case, we have messages that differ in at least two chunks
\(0 &lt; i &lt; j &lt; n\): \(m_i \neq m^\prime_i\) and \(m_j \neq
m^\prime_j\).</p>

<p>We can simplify the collision conditions to</p>

<p>\[ h_i \oplus h_j = h^\prime_i \oplus h^\prime_j \oplus y \]</p>

<p>and</p>

<p>\[ \overline{xs}_i(h_i) \oplus \overline{xs}_j(h_j) = \overline{xs}_i(h^\prime_i) \oplus \overline{xs}_j(h^\prime_j) \oplus z, \]</p>

<p>for \(y\) and \(z\) generated arbitrarily (adversarially), but
without knowledge of the parameters that generated \(h_i, h_j, h^\prime_i,
h^\prime_j\).</p>

<p>Again, let \(\Delta_i = h_i \oplus h^\prime_i\) and \(\Delta_j = h_j \oplus h^\prime_j\), and reformulate the conditions into</p>

<p>\[ \Delta_i \oplus \Delta_j = y \]
and
\[ \overline{xs}_i(\Delta_i) \oplus \overline{xs}_j(\Delta_j) = z. \]</p>

<p>Let‚Äôs apply the linear function \(\overline{xs}_i\) to the first
condition; since \(\overline{xs}_i\) isn‚Äôt invertible, the result
isn‚Äôt equivalent, but is a necessary weaker version.</p>

<p>\[ \overline{xs}_i(\Delta_i) \oplus \overline{xs}_i(\Delta_j) = y^\prime, \]</p>

<p>where \(y^\prime\) is some adversarially generated constant.</p>

<p>After xoring that with the second condition</p>

<p>\[ \overline{xs}_i(\Delta_i) \oplus \overline{xs}_j(\Delta_j) = z, \]</p>

<p>we find</p>

<p>\[ \overline{xs}_i(\Delta_j) \oplus \overline{xs}_j(\Delta_j) = y^\prime \oplus z. \]</p>

<p>By hypothesis, the null space of \(\overline{xs}_i \oplus \overline{xs}_j\)
is ‚Äúsmall.‚Äù  For our concrete definition of \(\overline{xs}\), there
are \(2^{2j}\) values in that null space, which means that \(\Delta_j\)
can only satisfy the condition by taking one of at most \(2^{2j}\) values;
otherwise, the two hashes definitely can‚Äôt both collide.</p>

<p>Since \(j &lt; n\), this happens with probability at most \(2^{2(n -
1) - w}\), or \(2^{-34}\) since we let \(w = 64\) and \(n =
16\).</p>

<p>Finally, for any given \(\Delta_j\), there is at most one
\(\Delta_i\) that satisfies</p>

<p>\[ \Delta_i \oplus \Delta_j = y,\]</p>

<p>and so <em>both</em> hashes collide with probability at most \(2^{-98}\),
with \(w = 64\).</p>

<p>Astute readers will notice that we could let
\(\overline{xs}_i(x) = x \mathtt{¬´} i\),
and find the same combined collision probability.
However, this results in a much weaker secondary hash, since a chunk
could lose up to \(2n - 2\) bits (\(n - 1\) in each 64-bit half)
of hash information in that shift.</p>

<p>The shifted xor-shifts might be a bit slower to compute, but
guarantees that we only lose at most 2 bits of information per chunk.
This feels like a safer interface that‚Äôs harder to misuse.</p>

<h2 id="what-does-this-look-like-in-code">What does this look like in code?</h2>

<p>The base <a href="https://github.com/backtrace-labs/umash/blob/8fd6287617f41e236bfb679e8d29a8b32f82c0e9/umash.c#L336">UMASH block compressor</a>
mixes all but the last of the message block‚Äôs 16-byte chunks with
<code>PH</code>: xor the chunk with the corresponding bytes in the parameter
array, computes a carryless multiplication of the xored chunks‚Äô half
with the other half.  The last chunk goes through <a href="https://github.com/backtrace-labs/umash/blob/8fd6287617f41e236bfb679e8d29a8b32f82c0e9/umash.c#L358">ENH</a>,
a little bit of mixing to improve the hash‚Äôs distribution (remember,
we only rely on \(\varepsilon\)-almost-universality),
and everything is xored in the accumulator.</p>

<p>The collision proofs above preserved the same structure for the first hash.</p>

<p>The second hash reuses so much work from the first that it mostly
makes sense to consider a combined loop that computes both (regular
UMASH and this new xor-shifted variant) block compression functions at
the same time.</p>

<p>The first change for this combined loop is that we need to xor
together all 16-bytes chunk in the message, and mix the resulting
checksum with a fresh <code>PH</code> function.  That‚Äôs equivalent to xoring
everything in a new accumulator (or two accumulators when working with
256-bit vectors) initialised with the <code>PH</code> parameters, and <code>CLMUL</code>ing
together the accumulator‚Äôs two 64-bit halves at the end.</p>

<p>We also have to apply the \(\overline{xs}_i\) quasi-xor-shift
functions to each \(h_i\).  The trick is to accumulate the shifted
values in two variables: one is the regular UMASH accumulator without
\(h_0\) (i.e., \(h_1 \oplus h_2 \ldots\)), and the other shifts
the current accumulator before xoring in a new value, i.e.,
\(\mathtt{acc}^\prime = (\mathtt{acc} \mathtt{¬´} 1) \oplus h_i\),
where the left shift on parallel 64-bit halves simply adds <code>acc</code>
to itself.</p>

<p>This additional shifted accumulator includes another special case to
skip the one \(\overline{xs}_1(x) = x \mathtt{¬´} 1\); that‚Äôs not a
big deal for the code, since we already have to special case the last
iteration for the <code>ENH</code> mixer.</p>

<p>Armed with \(\mathtt{UMASH} = \bigoplus_{i=1}^{n - 1} h_i\) and
\(\mathtt{acc} = \bigoplus_{i=2}^{n - 1} h_i \mathtt{¬´} (i - 1),\)
we have
\[\bigoplus_{i=1}^{n - 1} \overline{xs}_i(h_i) = (\mathtt{UMASH} \oplus \mathtt{acc}) \mathtt{¬´} 1.\]</p>

<p>We just have to xor in the <code>PH</code>-mixed checksum \(h_n\), and finally
\(h_0\) (which naturally goes in GPRs, so can be computed while we
extract values out of vector registers).</p>

<p>We added two vector xors and one addition for each chunk in a block,
and, at the end, one CLMUL plus a couple more xors and adds again.</p>

<p>This should most definitely be faster than computing two UMASH at the
same time, which incurred two vector xors and a CLMUL (or full integer
multiplication) for each chunk: even when CLMUL can pipeline one
instruction per cycle, vector additions can dispatch to more
execution units, so the combined throughput is still higher.</p>

<h2 id="one-last-thing-what-if-we-have-blocks-of-different-length">One last thing: what if we have blocks of different length?</h2>

<p>It‚Äôs easy to show that UMASH is relatively safe when one block is
shorter than the other, and we simply xor together fewer mixed chunks.
Without loss of generality, we can assume the longer block has \(n\)
chunks; that block‚Äôs final <code>ENH</code> is independent of the shorter block‚Äôs
UMASH, and any specific value occurs with probability at most
\(2^{-63}\) (the probability of a multiplication by zero).</p>

<p>A similar argument seems more complex to defend for the shifted UMASH.</p>

<p>Luckily, we can tweak the <a href="https://en.wikipedia.org/wiki/Longitudinal_redundancy_check">LRC checksum</a>
we use to generate an additional chunk in the block: rather than xoring
together the raw message chunks, we‚Äôll xor them <em>after</em> xoring them
with the <code>PH</code> key, i.e.,</p>

<p>\[m_n = \bigoplus_{i=0}^{n - 1} m_i \oplus k_i, \]</p>

<p>where \(k_i\) are the PH parameters for each chunk.</p>

<p>When checksumming blocks of the same size, this is a no-op with respect
to collision probabilities.  Implementations might however benefit
from the ability to use a fused <code>xor</code> with load from memory<sup id="fnref:latency" role="doc-noteref"><a href="#fn:latency" class="footnote">1</a></sup>
to compute \(m_i \oplus k_i\), and feed that both into the checksum
and into CLMUL for <code>PH</code>.</p>

<p>Unless we‚Äôre extremely unlucky (\(m_{n - 1} = k_{n - 1}\), with
probability \(2^{-2w}\)), the long block‚Äôs LRC will differ from the
shorter block‚Äôs.  As long as we always xor in the same <code>PH</code> parameters
when mixing the artificial LRC, the secondary hashes collide with
probability at most \(2^{-64}\).</p>

<p>With a small tweak to the checksum function, we can easily guarantee
that blocks with a different number of chunks collide with probability
less than \(2^{-126}\).<sup id="fnref:tag" role="doc-noteref"><a href="#fn:tag" class="footnote">2</a></sup></p>

<p><small>Thank you Joonas for helping me rubber duck the presentation, and Jim for pointing me in the right direction, and for the fruitful discussion!</small></p>

<p><hr style="width: 50%" /></p>

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:latency" role="doc-endnote">
      <p>This might also come with a small latency hit, which is unfortunate since PH-ing \(m_n\) is likely to be on the critical path‚Ä¶ but one cycle doesn‚Äôt seem that bad.¬†<a href="#fnref:latency" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:tag" role="doc-endnote">
      <p>The algorithm to expand any input message to a sequence of full 16-byte chunks is fixed.  That‚Äôs why we incorporate a size tag in ENH; that makes it impossible for two messages of different lengths to collide when they are otherwise identical after expansion.¬†<a href="#fnref:tag" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>
</div>


  <footer class="page-footer">
    <p class="meta">
      
<span class="byline author vcard">Text authored by <span class="fn">Paul Khuong</span></span>


      





Oct
  
31st, 
2020




      
      


    </p>
    
      <div class="sharing">
  
  
  
</div>

    
    <p class="meta">
      
        <a class="basic-alignment left" href="/Blog/2020/08/24/umash-fast-enough-almost-universal-fingerprinting/" title="Previous Post: UMASH: a fast and universal enough hash">&laquo; UMASH: a fast and universal enough hash</a>
      
      
    </p>
  </footer>
</article>

  <section>
    <h1>Comments</h1>
    <div id="disqus_thread" aria-live="polite"><noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</div>
  </section>


</div>

    </div>
  </div>
  <footer role="contentinfo"><p>
  Website copyright &copy; 2020 - <a href="mailto:pvk@pvk.ca">Paul Khuong</a> | <span class="credit">Powered by <a href="http://octopress.org">Octopress</a> | Themed with <a href="https://github.com/TheChymera/Koenigspress">K√∂nigspress</a></span>
</p>

</footer>
  

<script id="dsq-count-scr" src="//pvk.disqus.com/count.js" async></script>

  
<script type="text/javascript">
  var disqus_config = function () {
      this.page.url = 'https://www.pvk.ca/Blog/2020/10/31/nearly-double-the-ph-bits-with-one-more-clmul/';
      this.page.identifier = 'https://www.pvk.ca/Blog/2020/10/31/nearly-double-the-ph-bits-with-one-more-clmul/';
      this.page.title = '1.5x the PH bits for one more CLMUL';
  };

  (function() {
      var d = document, s = d.createElement('script');

      s.src = '//pvk.disqus.com/embed.js';

      s.setAttribute('data-timestamp', +new Date());
      (d.head || d.body).appendChild(s);
  })();
</script>












<script type="text/javascript">
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-20468541-1', 'auto');
  ga('send', 'pageview');
</script>



</body>
</html>
